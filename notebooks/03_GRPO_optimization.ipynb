{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMocDFioD7kM+lsP9OXrop5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Step 1: Mounting Google Drive and Importing Libraries"],"metadata":{"id":"L637dg8aVl1t"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qzxre_ImVbHp","executionInfo":{"status":"ok","timestamp":1766641905823,"user_tz":360,"elapsed":16616,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"b0fbb8d4-91b5-4ed4-db30-6070554790d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/grpo-verified-reasoner\n","data\t\t\t      notebooks  unsloth_compiled_cache\n","huggingface_tokenizers_cache  outputs\t _unsloth_sentencepiece_temp\n","LICENSE\t\t\t      README.md\n","models\t\t\t      src\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","%cd /content/drive/MyDrive/grpo-verified-reasoner\n","!ls"]},{"cell_type":"code","source":["# Install UV (Faster pip)\n","!pip install --upgrade -qqq uv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P3IoN0USiBmR","executionInfo":{"status":"ok","timestamp":1766641922975,"user_tz":360,"elapsed":5778,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"c5b9a138-fc2b-4806-d2f5-45e42123a418"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/22.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/22.2 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/22.2 MB\u001b[0m \u001b[31m121.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m17.2/22.2 MB\u001b[0m \u001b[31m253.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m274.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m274.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["!pip -q install -U evalplus"],"metadata":{"id":"y8iXM_15a_mn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import subprocess"],"metadata":{"id":"Oq8Azhmyiu6E","executionInfo":{"status":"ok","timestamp":1766641922985,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:False\""],"metadata":{"id":"lv-Ki6Vcrntd","executionInfo":{"status":"ok","timestamp":1766641924709,"user_tz":360,"elapsed":4,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["os.environ[\"UNSLOTH_VLLM_STANDBY\"] = \"1\""],"metadata":{"id":"NeqIAhUsd5Dg","executionInfo":{"status":"ok","timestamp":1766641924869,"user_tz":360,"elapsed":41,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Environment Logic (Colab vs Local)\n","if \"COLAB_\" not in \"\".join(os.environ.keys()):\n","    !pip install unsloth vllm\n","else:\n","    # Version Matching\n","    try: import numpy, PIL; get_numpy = f\"numpy=={numpy.__version__}\"; get_pil = f\"pillow=={PIL.__version__}\"\n","    except: get_numpy = \"numpy\"; get_pil = \"pillow\"\n","    try: is_t4 = \"Tesla T4\" in str(subprocess.check_output([\"nvidia-smi\"]))\n","    except: is_t4 = False\n","\n","    # A100 gets vllm 0.10.2 (Fast), T4 gets 0.9.2 (Stable)\n","    get_vllm, get_triton = (\"vllm==0.9.2\", \"triton==3.2.0\") if is_t4 else (\"vllm==0.10.2\", \"triton\")\n","\n","    # Install Everything\n","    !uv pip install -qqq --upgrade \\\n","        unsloth {get_vllm} {get_numpy} {get_pil} torchvision bitsandbytes xformers\n","    !uv pip install -qqq {get_triton}\n","\n","# Install TRL\n","!uv pip install transformers==4.56.2\n","!uv pip install --no-deps trl==0.22.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZuucNkH5imSg","executionInfo":{"status":"ok","timestamp":1766641978185,"user_tz":360,"elapsed":52207,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"9ecb44de-a21a-4400-ca64-a14c161746ca"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n","\u001b[2K\u001b[2mResolved \u001b[1m18 packages\u001b[0m \u001b[2min 469ms\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 557ms\u001b[0m\u001b[0m\n","\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 348ms\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 47ms\u001b[0m\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.57.3\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.56.2\u001b[0m\n","\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n","\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 122ms\u001b[0m\u001b[0m\n","\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 10ms\u001b[0m\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mtrl\u001b[0m\u001b[2m==0.24.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtrl\u001b[0m\u001b[2m==0.22.2\u001b[0m\n"]}]},{"cell_type":"code","source":["import re\n","import ast\n","import torch\n","import random\n","import evalplus\n","import traceback\n","import numpy as np\n","import multiprocessing as mp\n","from unsloth import FastLanguageModel\n","from evalplus.data import get_mbpp_plus"],"metadata":{"id":"HPDizgKUc3Fx","executionInfo":{"status":"ok","timestamp":1766648149647,"user_tz":360,"elapsed":4,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":["# Step 2: Verifying GPU and Environment"],"metadata":{"id":"0bFALRzXVpfD"}},{"cell_type":"code","source":["print(\"Torch version:\", torch.__version__)\n","print(\"CUDA available:\", torch.cuda.is_available())\n","if torch.cuda.is_available():\n","    print(\"GPU:\", torch.cuda.get_device_name(0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j6gsvZOiavZf","executionInfo":{"status":"ok","timestamp":1766642039913,"user_tz":360,"elapsed":64,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"7914a04c-5d48-4bd9-d233-27a753c7185b"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Torch version: 2.7.0+cu126\n","CUDA available: True\n","GPU: Tesla T4\n"]}]},{"cell_type":"markdown","source":["# Step 3: Loading Base Model and LoRA Adapters"],"metadata":{"id":"l-PeyUR5dE0m"}},{"cell_type":"code","source":["MODEL_PATH = \"models/qwen3-4b-sft\""],"metadata":{"id":"OGf88PMBdN3B","executionInfo":{"status":"ok","timestamp":1766642054009,"user_tz":360,"elapsed":2,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Load the model\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = MODEL_PATH,\n","    max_seq_length = 3072,\n","    load_in_4bit = True,        # TRUE for T4 (Crucial for memory)\n","    fast_inference = True,      # TRUE to test vLLM\n","    gpu_memory_utilization = 0.6, # Conservative for T4\n",")"],"metadata":{"id":"PLoe3PBmsHXz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3wgYFoDcv283","executionInfo":{"status":"ok","timestamp":1766654421556,"user_tz":360,"elapsed":10,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"3cc34494-05fe-4ab2-ecea-d3605ffcf3f6"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): Qwen3ForCausalLM(\n","      (model): Qwen3Model(\n","        (embed_tokens): Embedding(151936, 2560, padding_idx=151654)\n","        (layers): ModuleList(\n","          (0-1): 2 x Qwen3DecoderLayer(\n","            (self_attn): Qwen3Attention(\n","              (q_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear(\n","                (base_layer): Linear(in_features=4096, out_features=2560, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): Qwen3MLP(\n","              (gate_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9728, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9728, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear(\n","                (base_layer): Linear(in_features=9728, out_features=2560, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=9728, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","          )\n","          (2): Qwen3DecoderLayer(\n","            (self_attn): Qwen3Attention(\n","              (q_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=2560, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=4096, out_features=2560, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): Qwen3MLP(\n","              (gate_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9728, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9728, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear(\n","                (base_layer): Linear(in_features=9728, out_features=2560, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=9728, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","          )\n","          (3): Qwen3DecoderLayer(\n","            (self_attn): Qwen3Attention(\n","              (q_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear(\n","                (base_layer): Linear(in_features=4096, out_features=2560, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): Qwen3MLP(\n","              (gate_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=2560, out_features=9728, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9728, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=2560, out_features=9728, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9728, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=9728, out_features=2560, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=9728, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","          )\n","          (4): Qwen3DecoderLayer(\n","            (self_attn): Qwen3Attention(\n","              (q_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=2560, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=4096, out_features=2560, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): Qwen3MLP(\n","              (gate_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9728, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9728, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear(\n","                (base_layer): Linear(in_features=9728, out_features=2560, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=9728, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","          )\n","          (5): Qwen3DecoderLayer(\n","            (self_attn): Qwen3Attention(\n","              (q_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=2560, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=4096, out_features=2560, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): Qwen3MLP(\n","              (gate_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=2560, out_features=9728, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9728, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=2560, out_features=9728, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9728, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=9728, out_features=2560, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=9728, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","          )\n","          (6): Qwen3DecoderLayer(\n","            (self_attn): Qwen3Attention(\n","              (q_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=2560, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=4096, out_features=2560, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): Qwen3MLP(\n","              (gate_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9728, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9728, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear(\n","                (base_layer): Linear(in_features=9728, out_features=2560, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=9728, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","          )\n","          (7-35): 29 x Qwen3DecoderLayer(\n","            (self_attn): Qwen3Attention(\n","              (q_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=2560, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=4096, out_features=2560, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): Qwen3MLP(\n","              (gate_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=2560, out_features=9728, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9728, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=2560, out_features=9728, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9728, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear(\n","                (base_layer): Linear4bit(in_features=9728, out_features=2560, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=9728, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","          )\n","        )\n","        (norm): Qwen3RMSNorm((2560,), eps=1e-06)\n","        (rotary_emb): LlamaRotaryEmbedding()\n","      )\n","      (lm_head): Linear(in_features=2560, out_features=151936, bias=False)\n","    )\n","  )\n",")\n"]}]},{"cell_type":"markdown","source":["# Step 4: Sanity Check"],"metadata":{"id":"8AtswtDWt3T4"}},{"cell_type":"code","source":["# This is the same prompt that we used during SFT\n","system_prompt = \"\"\"You are a code-generation engine.\n","You must output your response in the following exact format:\n","<START_WORKING_OUT>\n","Concise reasoning steps required to solve the problem.\n","</END_WORKING_OUT>\n","<SOLUTION>\n","Valid Python code only.\n","</SOLUTION>\n","Do not output anything outside these tags.\"\"\""],"metadata":{"id":"pt0hmcEetnJ7","executionInfo":{"status":"ok","timestamp":1766647206682,"user_tz":360,"elapsed":6,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["user_prompt = \"Write a Python function that returns the factorial of a number.\"\n","\n","messages = [\n","    {\"role\": \"system\", \"content\": system_prompt},\n","    {\"role\": \"user\", \"content\": user_prompt},\n","]\n","inputs = tokenizer.apply_chat_template(\n","    messages,\n","    tokenize=True,\n","    add_generation_prompt=True,\n","    return_tensors=\"pt\",\n","    return_dict=True,\n",")"],"metadata":{"id":"FnsS5mubtnGM","executionInfo":{"status":"ok","timestamp":1766647228951,"user_tz":360,"elapsed":49,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["# Move the dictionary to GPU manually\n","inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}"],"metadata":{"id":"9buanb82vgtZ","executionInfo":{"status":"ok","timestamp":1766643977521,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["FastLanguageModel.for_inference(model) # Temporarily enable inference mode for the test\n","with torch.no_grad():\n","    output = model.generate(\n","        **inputs,\n","        max_new_tokens=256,\n","        temperature=0.0, # Deterministic check\n","    )"],"metadata":{"id":"m1gvTQsdtnEa","executionInfo":{"status":"ok","timestamp":1766643991448,"user_tz":360,"elapsed":13038,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["decoded = tokenizer.decode(output[0], skip_special_tokens=True)"],"metadata":{"id":"xglp4DortnCS","executionInfo":{"status":"ok","timestamp":1766643991479,"user_tz":360,"elapsed":14,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["print(\"\\n--- MODEL OUTPUT ---\")\n","input_len = inputs[\"input_ids\"].shape[1]\n","print(tokenizer.decode(output[0][input_len:], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zxb_myK-tnAO","executionInfo":{"status":"ok","timestamp":1766643991486,"user_tz":360,"elapsed":16,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"0ba803e6-09ac-4b30-916c-5f0c3e77f740"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- MODEL OUTPUT ---\n","<START_WORKING_OUT>\n","Define a function factorial that takes an integer n.\n","Handle non-positive input by returning 1 (factorial of 0 or negative is 1).\n","Initialize result to 1.\n","Multiply result by each integer i from 1 to n.\n","Return result.\n","</END_WORKING_OUT>\n","<SOLUTION>\n","def factorial(n):\n","    if n <= 0:\n","        return 1\n","    result = 1\n","    for i in range(1, n + 1):\n","        result *= i\n","    return result\n","</SOLUTION>\n"]}]},{"cell_type":"markdown","source":["Comment:  No schema check, extractor, or reward function ever sees the full decoded sequence. They only ever see generated_text."],"metadata":{"id":"Z8MkD65mYBx5"}},{"cell_type":"markdown","source":["# Step 6: Defining Output Schema"],"metadata":{"id":"z_hw6md1LSm3"}},{"cell_type":"code","source":["# Regular expressions for tag validation (case-insensitive)\n","RE_START = re.compile(r\"<START_WORKING_OUT>\", re.IGNORECASE)\n","RE_END   = re.compile(r\"</END_WORKING_OUT>\", re.IGNORECASE)\n","RE_SOL   = re.compile(r\"<SOLUTION>\", re.IGNORECASE)\n","RE_SOL_END = re.compile(r\"</SOLUTION>\", re.IGNORECASE)"],"metadata":{"id":"O3zR1mkFtm-N","executionInfo":{"status":"ok","timestamp":1766643995473,"user_tz":360,"elapsed":13,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["def validate_schema(text: str) -> tuple[bool, str]:\n","    \"\"\"\n","    Checks whether the model output follows the exact required schema.\n","    Returns (is_valid, reason).\n","    \"\"\"\n","    if not RE_START.search(text):\n","        return False, \"Missing <START_WORKING_OUT>\"\n","    if not RE_END.search(text):\n","        return False, \"Missing </END_WORKING_OUT>\"\n","    if not RE_SOL.search(text):\n","        return False, \"Missing <SOLUTION>\"\n","    if not RE_SOL_END.search(text):\n","        return False, \"Missing </SOLUTION>\"\n","\n","    # Optional: check order consistency\n","    start_idx = RE_START.search(text).start()\n","    sol_idx   = RE_SOL.search(text).start()\n","    if sol_idx < start_idx:\n","        return False, \"Tag order incorrect (<SOLUTION> before reasoning block).\"\n","\n","    return True, \"Schema valid\""],"metadata":{"id":"5oxttpUDtm0G","executionInfo":{"status":"ok","timestamp":1766643995662,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# Run a sanity test using the previous decoded output\n","is_valid, reason = validate_schema(decoded)\n","print(\"Schema Check:\", is_valid, \"|\", reason)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YA_UNFQgLrF0","executionInfo":{"status":"ok","timestamp":1766643995944,"user_tz":360,"elapsed":9,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"80ce744d-8243-461d-fcad-6a180a0cb842"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Schema Check: True | Schema valid\n"]}]},{"cell_type":"markdown","source":["# Step 7: Solution Extraction"],"metadata":{"id":"_EN-nTksMUff"}},{"cell_type":"code","source":["# Regex to extract the code block between <SOLUTION> ... </SOLUTION>\n","RE_SOLUTION = re.compile(r\"<SOLUTION>\\s*(.*?)\\s*</SOLUTION>\", re.IGNORECASE | re.DOTALL)"],"metadata":{"id":"Iv-5aUVNL3aC","executionInfo":{"status":"ok","timestamp":1766644134146,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["def extract_solution(text: str) -> tuple[str | None, str]:\n","    \"\"\"\n","    Extracts the Python code inside <SOLUTION> tags.\n","    Returns (code, status) where:\n","        code   -> the extracted string or None if failed\n","        status -> textual reason (for debugging)\n","    \"\"\"\n","    match = RE_SOLUTION.search(text)\n","    if not match:\n","        return None, \"No <SOLUTION> block found.\"\n","\n","    code = match.group(1).strip()\n","    if not code:\n","        return None, \"Empty <SOLUTION> block.\"\n","\n","    # Syntax check via Python's AST parser\n","    try:\n","        ast.parse(code)\n","    except SyntaxError as e:\n","        return None, f\"Syntax error in code: {e}\"\n","\n","    return code, \"Valid Python code extracted.\""],"metadata":{"id":"nlcNKSrIMjBy","executionInfo":{"status":"ok","timestamp":1766644157656,"user_tz":360,"elapsed":4,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["# Calculate where the prompt ends\n","input_len = inputs[\"input_ids\"].shape[1]"],"metadata":{"id":"hgaK_ceNV4Le","executionInfo":{"status":"ok","timestamp":1766646592732,"user_tz":360,"elapsed":8,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["# Decode ONLY the new tokens (The Assistant's reply)\n","generated_text = tokenizer.decode(output[0][input_len:], skip_special_tokens=True)"],"metadata":{"id":"8hwepazlV-Ho","executionInfo":{"status":"ok","timestamp":1766646606356,"user_tz":360,"elapsed":41,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["# Now run the check on ONLY the generated text\n","code, status = extract_solution(generated_text) # Use the new variable\n","print(\"Status:\", status)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CKKZsiDRMnKy","executionInfo":{"status":"ok","timestamp":1766646693875,"user_tz":360,"elapsed":9,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"c59fb93d-5265-4f60-8da1-655adab0f9e6"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Status: Valid Python code extracted.\n"]}]},{"cell_type":"code","source":["# Show snippet of the extracted code\n","if code:\n","    print(\"\\n--- Extracted Python Code ---\\n\")\n","    print(code)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G8DcMGzTMtQ0","executionInfo":{"status":"ok","timestamp":1766646707096,"user_tz":360,"elapsed":11,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"08955341-5526-4bf6-ff52-07a66ab0217b"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Extracted Python Code ---\n","\n","def factorial(n):\n","    if n <= 0:\n","        return 1\n","    result = 1\n","    for i in range(1, n + 1):\n","        result *= i\n","    return result\n"]}]},{"cell_type":"markdown","source":["# Step 8: Section 5 — Verifier Integration (EvalPlus MBPP+)"],"metadata":{"id":"-1urFQMgaulu"}},{"cell_type":"code","source":["# Load MBPP+ tasks as a dict: {task_id: problem_dict}\n","MBPP_TASKS = get_mbpp_plus()\n","\n","print(f\"Loaded MBPP+ tasks: {len(MBPP_TASKS)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dYJ4b4wiN-PR","executionInfo":{"status":"ok","timestamp":1766648015640,"user_tz":360,"elapsed":134,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"c7a1f5c0-858e-4831-c559-747492acb537"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded MBPP+ tasks: 378\n"]}]},{"cell_type":"code","source":["# Quick peek at one task to confirm fields & shape\n","sample_task_id = next(iter(MBPP_TASKS.keys()))\n","sample_task = MBPP_TASKS[sample_task_id]\n","\n","print(\"\\nSample Task ID:\", sample_task_id)\n","print(\"Keys:\", list(sample_task.keys()))\n","print(\"\\nPrompt (first 400 chars):\\n\", sample_task[\"prompt\"][:400])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A3fpg80PbTlc","executionInfo":{"status":"ok","timestamp":1766648043115,"user_tz":360,"elapsed":51,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"5c6f1f61-fc7c-4116-9885-c44cb5f29df5"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Sample Task ID: Mbpp/2\n","Keys: ['task_id', 'prompt', 'entry_point', 'canonical_solution', 'base_input', 'atol', 'plus_input', 'contract', 'assertion']\n","\n","Prompt (first 400 chars):\n"," \"\"\"\n","Write a function to find the shared elements from the given two lists.\n","assert set(similar_elements((3, 4, 5, 6),(5, 7, 4, 10))) == set((4, 5))\n","\"\"\"\n","\n"]}]},{"cell_type":"code","source":["# Different EvalPlus versions may store tests under slightly different keys,\n","# so we normalize via a helper (used later in reward function).\n","def get_tests_from_task(task: dict) -> list[str]:\n","    \"\"\"\n","    Extracts MBPP test assertions from a task.\n","    Supports both list-based and string-based formats.\n","    \"\"\"\n","    # Case 1: already a list of assertions\n","    for k in (\"test_list\", \"tests\", \"plus_tests\", \"base_tests\"):\n","        if k in task and task[k]:\n","            return list(task[k])\n","\n","    # Case 2: single multiline assertion string (MBPP+ common case)\n","    if \"assertion\" in task and task[\"assertion\"]:\n","        lines = task[\"assertion\"].strip().splitlines()\n","        return [line for line in lines if line.strip()]\n","\n","    raise KeyError(f\"No tests found in task keys: {list(task.keys())}\")"],"metadata":{"id":"RZsHYa9wbdUH","executionInfo":{"status":"ok","timestamp":1766650266874,"user_tz":360,"elapsed":14,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":["# Step 9: Defining Reward Function"],"metadata":{"id":"O6wcAKaBfVwn"}},{"cell_type":"code","source":["\n","def _exec_code_and_tests_worker(code: str, tests: list[str], queue: mp.Queue) -> None:\n","    \"\"\"\n","    Runs inside a subprocess. Executes model code + MBPP tests.\n","    Reports (passed: bool, error: str|None) via queue.\n","    \"\"\"\n","    try:\n","        # Restrict environment (keep it minimal; MBPP doesn't need much)\n","        g = {\"__builtins__\": __builtins__}\n","        l = {}\n","\n","        # 1) Define user's solution\n","        exec(code, g, l)\n","\n","        # 2) Run tests (assert statements)\n","        for t in tests:\n","            exec(t, g, l)\n","\n","        queue.put((True, None))\n","    except Exception:\n","        queue.put((False, traceback.format_exc()))"],"metadata":{"id":"Qq-ErSFRbsWl","executionInfo":{"status":"ok","timestamp":1766650268820,"user_tz":360,"elapsed":11,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["def run_mbpp_tests(code: str, task: dict, timeout_s: float = 2.0) -> tuple[bool, str | None]:\n","    \"\"\"\n","    Executes MBPP tests for a given task in a subprocess with timeout.\n","    Returns (passed, error_str).\n","    \"\"\"\n","    tests = get_tests_from_task(task)\n","\n","    ctx = mp.get_context(\"fork\")  # Colab/Linux: fork is fastest & simplest\n","    q = ctx.Queue()\n","    p = ctx.Process(target=_exec_code_and_tests_worker, args=(code, tests, q))\n","    p.start()\n","    p.join(timeout_s)\n","\n","    if p.is_alive():\n","        p.terminate()\n","        p.join()\n","        return False, f\"Timeout after {timeout_s:.1f}s\"\n","\n","    if q.empty():\n","        return False, \"No result returned from worker.\"\n","\n","    passed, err = q.get()\n","    return passed, err"],"metadata":{"id":"7qvlGFIjfpRV","executionInfo":{"status":"ok","timestamp":1766650269504,"user_tz":360,"elapsed":10,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["\n","def compute_mbpp_reward(generated_text: str, task: dict) -> tuple[float, dict]:\n","    \"\"\"\n","    Main reward function (GRPO-compatible later).\n","    Input must be ONLY the model completion (sliced), not full prompt+completion.\n","    Returns:\n","      reward: float\n","      info: dict (diagnostics for debugging)\n","    \"\"\"\n","    # 1) Schema gate\n","    ok, reason = validate_schema(generated_text)\n","    if not ok:\n","        return 0.0, {\"stage\": \"schema\", \"ok\": False, \"reason\": reason}\n","\n","    # 2) Extract + syntax gate\n","    code, status = extract_solution(generated_text)\n","    if code is None:\n","        return 0.0, {\"stage\": \"extract\", \"ok\": False, \"reason\": status}\n","\n","    # 3) Semantic gate (MBPP tests)\n","    passed, err = run_mbpp_tests(code, task, timeout_s=2.0)\n","    if not passed:\n","        return 0.0, {\"stage\": \"eval\", \"ok\": False, \"reason\": err, \"extract_status\": status}\n","\n","    return 1.0, {\"stage\": \"eval\", \"ok\": True, \"reason\": \"passed\", \"extract_status\": status}"],"metadata":{"id":"NThgOBSIfynM","executionInfo":{"status":"ok","timestamp":1766650270654,"user_tz":360,"elapsed":6,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","source":["# Select a specific MBPP task (for deterministic debugging)\n","task_ids = list(MBPP_TASKS.keys())\n","\n","task_id = task_ids[1]   # try the second task\n","task = MBPP_TASKS[task_id]\n","\n","print(\"Task ID:\", task_id)\n","print(\"\\n--- TASK PROMPT ---\\n\")\n","print(task[\"prompt\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I8dEvYUUf074","executionInfo":{"status":"ok","timestamp":1766652789835,"user_tz":360,"elapsed":9,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"53ac39d2-c5a1-48f9-bc04-3ac767bff524"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["Task ID: Mbpp/3\n","\n","--- TASK PROMPT ---\n","\n","\"\"\"\n","Write a python function to identify non-prime numbers.\n","assert is_not_prime(2) == False\n","\"\"\"\n","\n"]}]},{"cell_type":"code","source":["# Build messages for THIS task (not the earlier sanity check)\n","messages = [\n","    {\"role\": \"system\", \"content\": system_prompt},\n","    {\"role\": \"user\", \"content\": task[\"prompt\"]},\n","]\n","\n","inputs = tokenizer.apply_chat_template(\n","    messages,\n","    tokenize=True,\n","    add_generation_prompt=True,\n","    return_tensors=\"pt\",\n","    return_dict=True,\n",")"],"metadata":{"id":"FjJc952mpYWh","executionInfo":{"status":"ok","timestamp":1766652799876,"user_tz":360,"elapsed":4,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","source":["# Move to GPU\n","inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n","\n","# Generate\n","FastLanguageModel.for_inference(model)\n","with torch.no_grad():\n","    output = model.generate(\n","        **inputs,\n","        max_new_tokens=512,\n","        temperature=0.0,  # deterministic for debugging\n","    )"],"metadata":{"id":"h3GxAMkOpYUw","executionInfo":{"status":"ok","timestamp":1766652813297,"user_tz":360,"elapsed":12372,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":77,"outputs":[]},{"cell_type":"code","source":["# CRITICAL: slice off prompt tokens\n","input_len = inputs[\"input_ids\"].shape[1]\n","generated_text = tokenizer.decode(\n","    output[0][input_len:],\n","    skip_special_tokens=True\n",")"],"metadata":{"id":"dk8zMJRBpYSu","executionInfo":{"status":"ok","timestamp":1766652813322,"user_tz":360,"elapsed":12,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","source":["print(\"\\n--- GENERATED TEXT ---\\n\")\n","print(generated_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-nM2Y38jpYOP","executionInfo":{"status":"ok","timestamp":1766652813339,"user_tz":360,"elapsed":19,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"27b06093-e839-44ae-989e-de2173fe4fca"},"execution_count":79,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- GENERATED TEXT ---\n","\n","<START_WORKING_OUT>\n","Define a function is_not_prime that takes an integer n.\n","If n <= 1, return False (1 and numbers below are prime by definition).\n","Check divisibility from 2 to sqrt(n). If divisible by any, return True.\n","Otherwise, return False.\n","</END_WORKING_OUT>\n","<SOLUTION>\n","import math\n","\n","def is_not_prime(n: int) -> bool:\n","    \"\"\"Return True if n is not a prime number.\"\"\"\n","    if n <= 1:\n","        return False\n","    for i in range(2, math.isqrt(n) + 1):\n","        if n % i == 0:\n","            return True\n","    return False\n","</SOLUTION>\n"]}]},{"cell_type":"code","source":["reward, info = compute_mbpp_reward(generated_text, task)\n","\n","print(\"\\n--- REWARD RESULT ---\")\n","print(\"Reward:\", reward)\n","print(\"Info:\", info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w2Pnn5hkp2Re","executionInfo":{"status":"ok","timestamp":1766652817125,"user_tz":360,"elapsed":100,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"34892f98-2b7a-4a6a-9057-9b4ab12b2b75"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- REWARD RESULT ---\n","Reward: 0.0\n","Info: {'stage': 'eval', 'ok': False, 'reason': 'Traceback (most recent call last):\\n  File \"/tmp/ipython-input-90596588.py\", line 16, in _exec_code_and_tests_worker\\n    exec(t, g, l)\\n  File \"<string>\", line 1, in <module>\\nAssertionError\\n', 'extract_status': 'Valid Python code extracted.'}\n"]}]}]}