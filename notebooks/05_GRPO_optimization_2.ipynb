{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"H100","machine_shape":"hm","authorship_tag":"ABX9TyM0233NXl609H4brWGN7Sgg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Notebook: GRPO Reinforcement Learning (Run 2 â€“ Stabilized Partial-Credit Training)\n","\n","This notebook performs the **second GRPO reinforcement learning run** on top of the **SFT warm-start model**: `models/qwen3-4b-sft`.\n","\n","The focus of this run is **controlled performance improvement** on MBPP-style coding tasks while explicitly preventing reward hacking, verbosity collapse, and masking failures observed in the initial GRPO attempt.\n","\n","---\n","\n","## Objective\n","\n","The goal of this stage is to **improve pass@1 correctness** beyond the SFT baseline by applying **GRPO with dense, verifiable rewards**, while maintaining:\n","\n","- Concise, efficient reasoning traces  \n","- Stable output formatting  \n","- Controlled policy drift (no degeneration into rambling or schema exploitation)\n","\n","---\n","\n","## Key Changes from the First GRPO Run\n","\n","### 1. Dense Correctness Reward (Partial Credit)\n","- Replaced binary pass/fail correctness with **fractional credit**:\n","  - Reward = `passed_tests / total_tests`\n","- Added a small **victory bonus** for passing all tests to preserve a global optimum.\n","- Prevents flat reward landscapes where near-miss solutions receive no gradient.\n","\n","### 2. Anti-Filibuster Reasoning Reward\n","- Replaced linear length-based reward with a **capped + penalized profile**:\n","  - Linear ascent up to 400 characters\n","  - Flat reward plateau from 400â€“800 characters\n","  - Aggressive negative slope beyond 800 characters\n","- Explicitly disincentivizes infinite rambling while still encouraging meaningful reasoning.\n","\n","### 3. Format Reward Demotion\n","- Reduced format reward to a **small hygiene incentive** (0.02 max).\n","- Ensures schema compliance without allowing formatting to dominate learning.\n","\n","### 4. Stop Condition Correction\n","- Reverted to `stop = [tokenizer.eos_token]`.\n","- Removed string-based stop conditions that caused masking failures, padding leakage, and clipped-ratio explosions.\n","- Restores correct termination detection and loss masking.\n","\n","### 5. KL Term Removal (Default GRPO Behavior)\n","- Explicitly **did not use a KL penalty** (`beta` omitted / default 0.0).\n","- Aligns with modern GRPO practice and avoids unnecessary instability.\n","- KL metrics are monitored diagnostically only.\n","\n","### 6. Stability-Oriented Training Setup\n","- Higher exploration via `num_generations = 16`\n","- Gradient accumulation for variance reduction\n","\n","- Two-epoch training with early-stop awareness\n","- Careful learning-rate selection for short-horizon RL\n","\n","---\n","\n","## Training Procedure Summary\n","\n","- Load the **SFT warm-start model**: `models/qwen3-4b-sft`\n","- Apply ChatML-style prompt formatting\n","- Generate multiple rollouts per prompt via vLLM\n","- Compute rewards using:\n","  - Schema validation\n","  - Reasoning length shaping\n","  - Partial-credit unit test execution\n","- Optimize policy using GRPO with clipped ratios\n","- Monitor reward decomposition, KL drift, and generation length\n","- Save checkpoints for post-hoc evaluation"],"metadata":{"id":"OlKrZ4W3YkZm"}},{"cell_type":"markdown","source":["# Step 1: Mounting Google Drive and Importing Libraries\n"],"metadata":{"id":"L637dg8aVl1t"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qzxre_ImVbHp","executionInfo":{"status":"ok","timestamp":1767579100219,"user_tz":360,"elapsed":26318,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"2165ab9e-2313-4c9f-959c-f0580cd30887"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/grpo-verified-reasoner\n","data\t\t\t      LICENSE\t outputs    unsloth_compiled_cache\n","grpo_trainer_lora_model       models\t README.md  _unsloth_sentencepiece_temp\n","huggingface_tokenizers_cache  notebooks  src\t    wandb\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","%cd /content/drive/MyDrive/grpo-verified-reasoner\n","!ls"]},{"cell_type":"code","source":["\n","# Install UV (Faster pip)\n","!pip install --upgrade -qqq uv"],"metadata":{"id":"P3IoN0USiBmR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","!pip -q install -U evalplus"],"metadata":{"id":"y8iXM_15a_mn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import subprocess"],"metadata":{"id":"Oq8Azhmyiu6E","executionInfo":{"status":"ok","timestamp":1767579109531,"user_tz":360,"elapsed":5,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["\n","os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:False\""],"metadata":{"id":"lv-Ki6Vcrntd","executionInfo":{"status":"ok","timestamp":1767579109534,"user_tz":360,"elapsed":1,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["os.environ[\"UNSLOTH_VLLM_STANDBY\"] = \"1\""],"metadata":{"id":"NeqIAhUsd5Dg","executionInfo":{"status":"ok","timestamp":1767579109539,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["os.environ[\"WANDB_PROJECT\"] = \"mbpp-rl-project\""],"metadata":{"id":"kTXAQ4pB0NsE","executionInfo":{"status":"ok","timestamp":1767579109562,"user_tz":360,"elapsed":21,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Environment Logic (Colab vs Local)\n","if \"COLAB_\" not in \"\".join(os.environ.keys()):\n","    !pip install unsloth vllm\n","else:\n","    # Version Matching\n","    try: import numpy, PIL; get_numpy = f\"numpy=={numpy.__version__}\"; get_pil = f\"pillow=={PIL.__version__}\"\n","    except: get_numpy = \"numpy\"; get_pil = \"pillow\"\n","    try: is_t4 = \"Tesla T4\" in str(subprocess.check_output([\"nvidia-smi\"]))\n","    except: is_t4 = False\n","\n","    # A100 gets vllm 0.10.2 (Fast), T4 gets 0.9.2 (Stable)\n","    get_vllm, get_triton = (\"vllm==0.9.2\", \"triton==3.2.0\") if is_t4 else (\"vllm==0.10.2\", \"triton\")\n","\n","    # Install Everything\n","    !uv pip install -qqq --upgrade \\\n","        unsloth {get_vllm} {get_numpy} {get_pil} torchvision bitsandbytes xformers\n","    !uv pip install -qqq {get_triton}\n","\n","# Install TRL\n","!uv pip install transformers==4.56.2\n","!uv pip install --no-deps trl==0.22.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZuucNkH5imSg","executionInfo":{"status":"ok","timestamp":1767579143909,"user_tz":360,"elapsed":34344,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"da4fc281-51f3-4674-e3cb-fa892a65fe52"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n","\u001b[2K\u001b[2mResolved \u001b[1m18 packages\u001b[0m \u001b[2min 20ms\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 296ms\u001b[0m\u001b[0m\n","\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 188ms\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 36ms\u001b[0m\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.57.3\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.56.2\u001b[0m\n","\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n","\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 24ms\u001b[0m\u001b[0m\n","\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mtrl\u001b[0m\u001b[2m==0.24.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtrl\u001b[0m\u001b[2m==0.22.2\u001b[0m\n"]}]},{"cell_type":"code","source":["import re\n","import ast\n","import torch\n","import wandb\n","import random\n","import evalplus\n","import traceback\n","import numpy as np\n","import multiprocessing as mp\n","from datasets import Dataset\n","from unsloth import FastLanguageModel\n","from evalplus.data import get_mbpp_plus\n","from trl import GRPOConfig, GRPOTrainer\n","from vllm import SamplingParams"],"metadata":{"id":"HPDizgKUc3Fx","executionInfo":{"status":"ok","timestamp":1767579243990,"user_tz":360,"elapsed":100069,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"33bdce6b-862b-4f0e-cfab-64f5e90c8114"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","INFO 01-05 02:12:48 [__init__.py:216] Automatically detected platform cuda.\n","ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"]}]},{"cell_type":"code","source":["wandb.login()"],"metadata":{"id":"wiKxGqbQx_r6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Step 2: Verifying GPU and Environment"],"metadata":{"id":"0bFALRzXVpfD"}},{"cell_type":"code","source":["print(\"Torch version:\", torch.__version__)\n","print(\"CUDA available:\", torch.cuda.is_available())\n","if torch.cuda.is_available():\n","    print(\"GPU:\", torch.cuda.get_device_name(0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j6gsvZOiavZf","executionInfo":{"status":"ok","timestamp":1767579263181,"user_tz":360,"elapsed":7,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"c3c3a845-f152-4847-c2dc-0fed592e3e17"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Torch version: 2.8.0+cu128\n","CUDA available: True\n","GPU: NVIDIA H100 80GB HBM3\n"]}]},{"cell_type":"markdown","source":["# Step 3: Loading Base Model and LoRA Adapters"],"metadata":{"id":"l-PeyUR5dE0m"}},{"cell_type":"code","source":["\n","MODEL_PATH = \"models/qwen3-4b-sft\""],"metadata":{"id":"OGf88PMBdN3B","executionInfo":{"status":"ok","timestamp":1767579264383,"user_tz":360,"elapsed":4,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Load the model\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = MODEL_PATH,\n","    max_seq_length = 3072,      # Aligned with GRPO + schema\n","    load_in_4bit = False,       # Full precision for RL stability\n","    fast_inference = True,      # Required for vLLM\n","    gpu_memory_utilization = 0.8,\n",")"],"metadata":{"id":"PLoe3PBmsHXz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainable = 0\n","total = 0\n","trainable_names = []\n","for name, p in model.named_parameters():\n","    n = p.numel()\n","    total += n\n","    if p.requires_grad:\n","        trainable += n\n","        trainable_names.append(name)\n","\n","print(f\"Trainable params: {trainable:,} / {total:,} = {100*trainable/total:.4f}%\")\n","print(\"Example trainable params:\", trainable_names[:20])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o4dnSm0bIHz5","executionInfo":{"status":"ok","timestamp":1767579432578,"user_tz":360,"elapsed":9,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"b295c6f6-5d48-474b-e0a5-6d0b4e47acde"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Trainable params: 66,060,288 / 4,088,528,384 = 1.6157%\n","Example trainable params: ['base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight']\n"]}]},{"cell_type":"code","source":["print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3wgYFoDcv283","executionInfo":{"status":"ok","timestamp":1767579434324,"user_tz":360,"elapsed":8,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"7d609867-aa61-4be9-c664-f1ec98399c9e"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): Qwen3ForCausalLM(\n","      (model): Qwen3Model(\n","        (embed_tokens): Embedding(151936, 2560, padding_idx=151654)\n","        (layers): ModuleList(\n","          (0-35): 36 x Qwen3DecoderLayer(\n","            (self_attn): Qwen3Attention(\n","              (q_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear(\n","                (base_layer): Linear(in_features=4096, out_features=2560, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): Qwen3MLP(\n","              (gate_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9728, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9728, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear(\n","                (base_layer): Linear(in_features=9728, out_features=2560, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=9728, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","          )\n","        )\n","        (norm): Qwen3RMSNorm((2560,), eps=1e-06)\n","        (rotary_emb): LlamaRotaryEmbedding()\n","      )\n","      (lm_head): Linear(in_features=2560, out_features=151936, bias=False)\n","    )\n","  )\n",")\n"]}]},{"cell_type":"markdown","source":["# Step 4: Sanity Check"],"metadata":{"id":"8AtswtDWt3T4"}},{"cell_type":"code","source":["# This is the same prompt that we used during SFT\n","system_prompt = \"\"\"You are a code-generation engine.\n","You must output your response in the following exact format:\n","<START_WORKING_OUT>\n","Concise reasoning steps required to solve the problem.\n","</END_WORKING_OUT>\n","<SOLUTION>\n","Valid Python code only.\n","</SOLUTION>\n","Do not output anything outside these tags.\"\"\""],"metadata":{"id":"pt0hmcEetnJ7","executionInfo":{"status":"ok","timestamp":1767579434807,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["user_prompt = \"Write a Python function that returns the factorial of a number.\"\n","\n","messages = [\n","    {\"role\": \"system\", \"content\": system_prompt},\n","    {\"role\": \"user\", \"content\": user_prompt},\n","]\n","inputs = tokenizer.apply_chat_template(\n","    messages,\n","    tokenize=True,\n","    add_generation_prompt=True,\n","    return_tensors=\"pt\",\n","    return_dict=True,\n",")"],"metadata":{"id":"FnsS5mubtnGM","executionInfo":{"status":"ok","timestamp":1767579434952,"user_tz":360,"elapsed":1,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Move the dictionary to GPU manually\n","inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}"],"metadata":{"id":"9buanb82vgtZ","executionInfo":{"status":"ok","timestamp":1767579435204,"user_tz":360,"elapsed":1,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["FastLanguageModel.for_inference(model) # Temporarily enable inference mode for the test\n","with torch.no_grad():\n","    output = model.generate(\n","        **inputs,\n","        max_new_tokens=256,\n","        temperature=0.0, # Deterministic check\n","    )"],"metadata":{"id":"m1gvTQsdtnEa","executionInfo":{"status":"ok","timestamp":1767579439992,"user_tz":360,"elapsed":4594,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["\n","decoded = tokenizer.decode(output[0], skip_special_tokens=True)"],"metadata":{"id":"xglp4DortnCS","executionInfo":{"status":"ok","timestamp":1767579440005,"user_tz":360,"elapsed":5,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["print(\"\\n--- MODEL OUTPUT ---\")\n","input_len = inputs[\"input_ids\"].shape[1]\n","print(tokenizer.decode(output[0][input_len:], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zxb_myK-tnAO","executionInfo":{"status":"ok","timestamp":1767579440012,"user_tz":360,"elapsed":4,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"e77d9b09-4c46-4cb2-d997-648d19bbde35"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- MODEL OUTPUT ---\n","<START_WORKING_OUT>\n","Define a function factorial(n) that calculates the product of all positive integers up to n.\n","Handle non-positive integers by returning 1 (factorial of 0 and negative is 1).\n","Implement iterative approach for efficiency.\n","Return the computed factorial.\n","</END_WORKING_OUT>\n","<SOLUTION>\n","def factorial(n):\n","    if n <= 0:\n","        return 1\n","    result = 1\n","    for i in range(2, n + 1):\n","        result *= i\n","    return result\n","</SOLUTION>\n"]}]},{"cell_type":"markdown","source":["Comment:  No schema check, extractor, or reward function ever sees the full decoded sequence. They only ever see generated_text."],"metadata":{"id":"Z8MkD65mYBx5"}},{"cell_type":"markdown","source":["\n","# Step 6: Defining Output Schema"],"metadata":{"id":"z_hw6md1LSm3"}},{"cell_type":"code","source":["# Regular expressions for tag validation (case-insensitive)\n","RE_START = re.compile(r\"<START_WORKING_OUT>\", re.IGNORECASE)\n","RE_END   = re.compile(r\"</END_WORKING_OUT>\", re.IGNORECASE)\n","RE_SOL   = re.compile(r\"<SOLUTION>\", re.IGNORECASE)\n","RE_SOL_END = re.compile(r\"</SOLUTION>\", re.IGNORECASE)"],"metadata":{"id":"O3zR1mkFtm-N","executionInfo":{"status":"ok","timestamp":1767579440014,"user_tz":360,"elapsed":1,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def validate_schema(text: str) -> tuple[bool, str]:\n","    \"\"\"\n","    Checks whether the model output follows the exact required schema.\n","    Returns (is_valid, reason).\n","    \"\"\"\n","    if not RE_START.search(text):\n","        return False, \"Missing <START_WORKING_OUT>\"\n","    if not RE_END.search(text):\n","        return False, \"Missing </END_WORKING_OUT>\"\n","    if not RE_SOL.search(text):\n","        return False, \"Missing <SOLUTION>\"\n","    if not RE_SOL_END.search(text):\n","        return False, \"Missing </SOLUTION>\"\n","\n","    # Optional: check order consistency\n","    start_idx = RE_START.search(text).start()\n","    sol_idx   = RE_SOL.search(text).start()\n","    if sol_idx < start_idx:\n","        return False, \"Tag order incorrect (<SOLUTION> before reasoning block).\"\n","\n","    return True, \"Schema valid\""],"metadata":{"id":"5oxttpUDtm0G","executionInfo":{"status":"ok","timestamp":1767579440020,"user_tz":360,"elapsed":2,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# Run a sanity test using the previous decoded output\n","is_valid, reason = validate_schema(decoded)\n","print(\"Schema Check:\", is_valid, \"|\", reason)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YA_UNFQgLrF0","executionInfo":{"status":"ok","timestamp":1767579440064,"user_tz":360,"elapsed":6,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"41172f46-60a8-48cc-de29-354cc8d8ecb0"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Schema Check: True | Schema valid\n"]}]},{"cell_type":"markdown","source":["# Step 7: Solution Extraction"],"metadata":{"id":"_EN-nTksMUff"}},{"cell_type":"code","source":["# Regex to extract the code block between <SOLUTION> ... </SOLUTION>\n","RE_SOLUTION = re.compile(r\"<SOLUTION>\\s*(.*?)\\s*</SOLUTION>\", re.IGNORECASE | re.DOTALL)"],"metadata":{"id":"Iv-5aUVNL3aC","executionInfo":{"status":"ok","timestamp":1767579440068,"user_tz":360,"elapsed":2,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def extract_solution(text: str) -> tuple[str | None, str]:\n","    \"\"\"\n","    Extracts the Python code inside <SOLUTION> tags.\n","    Returns (code, status) where:\n","        code   -> the extracted string or None if failed\n","        status -> textual reason (for debugging)\n","    \"\"\"\n","    match = RE_SOLUTION.search(text)\n","    if not match:\n","        return None, \"No <SOLUTION> block found.\"\n","\n","    code = match.group(1).strip()\n","    if not code:\n","        return None, \"Empty <SOLUTION> block.\"\n","\n","    # Syntax check via Python's AST parser\n","    try:\n","        ast.parse(code)\n","    except SyntaxError as e:\n","        return None, f\"Syntax error in code: {e}\"\n","\n","    return code, \"Valid Python code extracted.\""],"metadata":{"id":"nlcNKSrIMjBy","executionInfo":{"status":"ok","timestamp":1767579440069,"user_tz":360,"elapsed":0,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["# Calculate where the prompt ends\n","input_len = inputs[\"input_ids\"].shape[1]"],"metadata":{"id":"hgaK_ceNV4Le","executionInfo":{"status":"ok","timestamp":1767579440070,"user_tz":360,"elapsed":0,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# Decode ONLY the new tokens (The Assistant's reply)\n","generated_text = tokenizer.decode(output[0][input_len:], skip_special_tokens=True)"],"metadata":{"id":"8hwepazlV-Ho","executionInfo":{"status":"ok","timestamp":1767579440071,"user_tz":360,"elapsed":0,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# Now run the check on ONLY the generated text\n","code, status = extract_solution(generated_text) # Use the new variable\n","print(\"Status:\", status)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CKKZsiDRMnKy","executionInfo":{"status":"ok","timestamp":1767579440074,"user_tz":360,"elapsed":2,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"af6ddfe2-2ac5-4709-de3f-fedc3faf9e68"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Status: Valid Python code extracted.\n"]}]},{"cell_type":"code","source":["\n","# Show snippet of the extracted code\n","if code:\n","    print(\"\\n--- Extracted Python Code ---\\n\")\n","    print(code)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G8DcMGzTMtQ0","executionInfo":{"status":"ok","timestamp":1767579440102,"user_tz":360,"elapsed":7,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"c2857aa3-ca71-495c-c594-9fbfc9c6f483"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Extracted Python Code ---\n","\n","def factorial(n):\n","    if n <= 0:\n","        return 1\n","    result = 1\n","    for i in range(2, n + 1):\n","        result *= i\n","    return result\n"]}]},{"cell_type":"markdown","source":["# Step 8: Verifier Integration (EvalPlus MBPP+)"],"metadata":{"id":"-1urFQMgaulu"}},{"cell_type":"code","source":["# Load MBPP+ tasks as a dict: {task_id: problem_dict}\n","MBPP_TASKS = get_mbpp_plus()\n","\n","print(f\"Loaded MBPP+ tasks: {len(MBPP_TASKS)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dYJ4b4wiN-PR","executionInfo":{"status":"ok","timestamp":1767579441835,"user_tz":360,"elapsed":1186,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"7e2e7fa9-751c-4e65-a99d-9fb6a5051015"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading dataset from https://github.com/evalplus/mbppplus_release/releases/download/v0.2.0/MbppPlus.jsonl.gz\n","Loaded MBPP+ tasks: 378\n"]}]},{"cell_type":"code","source":["# Quick peek at one task to confirm fields & shape\n","sample_task_id = next(iter(MBPP_TASKS.keys()))\n","sample_task = MBPP_TASKS[sample_task_id]\n","\n","print(\"\\nSample Task ID:\", sample_task_id)\n","print(\"Keys:\", list(sample_task.keys()))\n","print(\"\\nPrompt (first 400 chars):\\n\", sample_task[\"prompt\"][:400])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A3fpg80PbTlc","executionInfo":{"status":"ok","timestamp":1767579441839,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"4c2a30ea-c510-4b96-bd46-15929df49cc0"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Sample Task ID: Mbpp/2\n","Keys: ['task_id', 'prompt', 'entry_point', 'canonical_solution', 'base_input', 'atol', 'plus_input', 'contract', 'assertion']\n","\n","Prompt (first 400 chars):\n"," \"\"\"\n","Write a function to find the shared elements from the given two lists.\n","assert set(similar_elements((3, 4, 5, 6),(5, 7, 4, 10))) == set((4, 5))\n","\"\"\"\n","\n"]}]},{"cell_type":"code","source":["# Different EvalPlus versions may store tests under slightly different keys,\n","# so we normalize via a helper (used later in reward function).\n","def get_tests_from_task(task: dict) -> list[str]:\n","    \"\"\"\n","    Extracts MBPP test assertions from a task.\n","    Supports both list-based and string-based formats.\n","    \"\"\"\n","    # Case 1: already a list of assertions\n","    for k in (\"test_list\", \"tests\", \"plus_tests\", \"base_tests\"):\n","        if k in task and task[k]:\n","            return list(task[k])\n","\n","    # Case 2: single multiline assertion string (MBPP+ common case)\n","    if \"assertion\" in task and task[\"assertion\"]:\n","        lines = task[\"assertion\"].strip().splitlines()\n","        return [line for line in lines if line.strip()]\n","\n","    raise KeyError(f\"No tests found in task keys: {list(task.keys())}\")"],"metadata":{"id":"RZsHYa9wbdUH","executionInfo":{"status":"ok","timestamp":1767579441841,"user_tz":360,"elapsed":2,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["# Step 9: Defining Helper Functions"],"metadata":{"id":"O6wcAKaBfVwn"}},{"cell_type":"code","source":["def _exec_code_and_tests_worker(code: str, tests: list[str], queue: mp.Queue) -> None:\n","    \"\"\"\n","    Runs model code + tests.\n","    CRITICAL FEATURES:\n","    1. Runs ALL tests (Partial Credit).\n","    2. Catches ALL exceptions (Robustness).\n","    3. Truncates error logs (IPC Safety).\n","    \"\"\"\n","    try:\n","        # Create the \"Main Desk\" (Environment)\n","        env = {\"__builtins__\": __builtins__}\n","\n","        # Run the User's Code into 'env'\n","        exec(code, env, env)\n","\n","        passed_count = 0\n","        total_tests = len(tests)\n","        first_error = None\n","\n","        # Run ALL Test Cases\n","        for t in tests:\n","            try:\n","                exec(t, env, env)\n","                passed_count += 1\n","            except Exception:\n","                # Capture only the FIRST error to save bandwidth\n","                if first_error is None:\n","                    # Get the full traceback\n","                    tb = traceback.format_exc()\n","                    # SOPHIA'S FIX: Truncate to 500 chars to prevent IPC deadlock\n","                    first_error = tb[:500] + \"\\n...[TRUNCATED]...\" if len(tb) > 500 else tb\n","                # Continue to the next test!\n","                continue\n","\n","        # Mission Complete: Return the score\n","        queue.put((passed_count, total_tests, first_error))\n","\n","    except Exception:\n","        # Catch syntax errors or crashes in the main code body\n","        tb = traceback.format_exc()\n","        truncated_error = tb[:500] + \"\\n...[TRUNCATED]...\" if len(tb) > 500 else tb\n","        queue.put((0, len(tests), truncated_error))"],"metadata":{"id":"ugV0PZjq6WS0","executionInfo":{"status":"ok","timestamp":1767579441861,"user_tz":360,"elapsed":2,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["def run_mbpp_tests(code: str, task: dict, timeout_s: float = 2.0) -> tuple[int, int, str | None]:\n","    \"\"\"\n","    Executes tests and returns (passed_count, total_count, first_error).\n","    \"\"\"\n","    tests = get_tests_from_task(task)\n","    if not tests:\n","        return 0, 0, \"No tests found.\"\n","\n","    ctx = mp.get_context(\"fork\")\n","    q = ctx.Queue()\n","    p = ctx.Process(target=_exec_code_and_tests_worker, args=(code, tests, q))\n","    p.start()\n","    p.join(timeout_s)\n","\n","    if p.is_alive():\n","        p.terminate()\n","        p.join()\n","        return 0, len(tests), f\"Timeout after {timeout_s:.1f}s\"\n","\n","    if q.empty():\n","        return 0, len(tests), \"No result returned from worker.\"\n","\n","    passed_count, total_count, err = q.get()\n","    return passed_count, total_count, err"],"metadata":{"id":"7qvlGFIjfpRV","executionInfo":{"status":"ok","timestamp":1767579441863,"user_tz":360,"elapsed":1,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":["# Step 10: Defining Reward Functions"],"metadata":{"id":"nlE3bAZ3LjwO"}},{"cell_type":"code","source":["def format_reward_func(completions, **kwargs) -> list[float]:\n","    \"\"\"\n","    Rewards the model for strictly following the XML schema.\n","    Args:\n","        completions: List of generated strings from the model.\n","    Returns:\n","        List of rewards (0.02 for valid schema, 0.0 for invalid).\n","    \"\"\"\n","    rewards = []\n","    for completion in completions:\n","        # Uses your existing validator from Step 6\n","        is_valid, _ = validate_schema(completion)\n","        rewards.append(0.02 if is_valid else 0.0)\n","    return rewards"],"metadata":{"id":"q5SEd65CLneK","executionInfo":{"status":"ok","timestamp":1767579443336,"user_tz":360,"elapsed":7,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["def reasoning_reward_func(completions, **kwargs) -> list[float]:\n","    \"\"\"\n","    - Ascent: Linear 0-400 chars.\n","    - Plateau: 400-800 chars (Max Reward 0.1).\n","    - Penalty: Aggressive slope (0.03) starts > 800.\n","    - Zero Point: Reward hits 0.0 at ~1133 chars.\n","    \"\"\"\n","    rewards = []\n","    for completion in completions:\n","        match = re.search(r\"<START_WORKING_OUT>(.*?)</END_WORKING_OUT>\", completion, re.DOTALL | re.IGNORECASE)\n","\n","        if match:\n","            content = match.group(1).strip()\n","            length = len(content)\n","\n","            if length < 50:\n","                rewards.append(0.0)\n","\n","            elif length <= 400:\n","                # LINEAR ASCENT\n","                score = (length / 400.0) * 0.1\n","                rewards.append(score)\n","\n","            elif length <= 800:\n","                # PLATEAU: 0.1 (The \"Thinking Room\")\n","                rewards.append(0.1)\n","\n","            else:\n","                # AGGRESSIVE PENALTY (Slope 0.03)\n","                overage = length - 800\n","                penalty = (overage / 100.0) * 0.03\n","                score = 0.1 - penalty\n","                rewards.append(max(-0.1, score))\n","\n","        else:\n","            rewards.append(0.0)\n","\n","    return rewards"],"metadata":{"id":"bfVxKTg9L6cd","executionInfo":{"status":"ok","timestamp":1767579443510,"user_tz":360,"elapsed":1,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n","    \"\"\"\n","    Rewards the model based on the PERCENTAGE of tests passed.\n","    Includes a \"Clean Sweep Bonus\" for 100% completion.\n","    \"\"\"\n","    rewards = []\n","    for prompt, completion, task_data in zip(prompts, completions, answer):\n","        code, status = extract_solution(completion)\n","        if not code:\n","            rewards.append(0.0)\n","            continue\n","\n","        passed, total, err = run_mbpp_tests(code, task_data)\n","\n","        if total == 0:\n","            rewards.append(0.0)\n","            continue\n","\n","        # CALCULATE SCORE: Fraction of tests passed\n","        score = passed / total\n","\n","        # VICTORY BONUS: If 100% passed, add +0.1 bonus\n","        # This differentiates \"perfect\" from \"lucky\" and prevents settling\n","        if passed == total:\n","            score += 0.1\n","\n","        rewards.append(score)\n","\n","    return rewards"],"metadata":{"id":"hLNU6pML0gqN","executionInfo":{"status":"ok","timestamp":1767579444067,"user_tz":360,"elapsed":2,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["# Step 11: Dataset Formatting and Unit Testing"],"metadata":{"id":"OI6Eut_JXUZW"}},{"cell_type":"code","source":["# Clean the Data\n","# The raw MBPP+ dataset has inconsistent schemas (some fields are lists, some are None).\n","# We fix this by extracting ONLY what we need: the test cases.\n","dict_data = []"],"metadata":{"id":"jJF74XFesHNc","executionInfo":{"status":"ok","timestamp":1767579447152,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["for task_id, task_data in MBPP_TASKS.items():\n","    # Extract the test cases using our helper from Step 8\n","    # This handles the \"messy\" parsing right now, so the Dataset is clean.\n","    try:\n","        tests = get_tests_from_task(task_data)\n","    except KeyError:\n","        # If a task is broken/empty, skip it to prevent crashes\n","        print(f\"Skipping task {task_id}: No tests found.\")\n","        continue\n","\n","    # Create a CLEAN 'answer' dictionary\n","    # This guarantees every row has the exact same structure.\n","    # This prevents the \"ArrowInvalid\" error.\n","    clean_answer = {\n","        \"task_id\": str(task_id),\n","        \"test_list\": tests  # Always a List of Strings\n","    }\n","\n","    # Append to our list\n","    dict_data.append({\n","        \"prompt\": task_data[\"prompt\"],\n","        \"answer\": clean_answer\n","    })"],"metadata":{"id":"Fx2h97Kfp9sf","executionInfo":{"status":"ok","timestamp":1767579447341,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["# Creating a Hugging Face compatible dataset\n","dataset = Dataset.from_list(dict_data)"],"metadata":{"id":"O3VW7urjp9qi","executionInfo":{"status":"ok","timestamp":1767579447590,"user_tz":360,"elapsed":1,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["print(\"Dataset Features:\", dataset.features)\n","print(\"Sample Row Answer Keys:\", dataset[0][\"answer\"].keys())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IZsJGtmHp9oL","executionInfo":{"status":"ok","timestamp":1767579447751,"user_tz":360,"elapsed":5,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"117c2c71-a1e6-43a0-9199-71589f38ba8d"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset Features: {'prompt': Value('string'), 'answer': {'task_id': Value('string'), 'test_list': List(Value('string'))}}\n","Sample Row Answer Keys: dict_keys(['task_id', 'test_list'])\n"]}]},{"cell_type":"code","source":["\n","# Pick the 2nd task again for consistency\n","task = dataset[2][\"answer\"] # We grab it from our NEW dataset column\n","prompt = dataset[2][\"prompt\"]"],"metadata":{"id":"pv2zGhEauI7Y","executionInfo":{"status":"ok","timestamp":1767579447976,"user_tz":360,"elapsed":38,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["prompt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":42},"id":"THY3eewTxW9T","executionInfo":{"status":"ok","timestamp":1767579448117,"user_tz":360,"elapsed":4,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"bec8d082-a1a8-490f-ec2f-fd519f4e34f8"},"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\"\"\"\\nWrite a function to find the n largest integers from a given list of numbers, returned in descending order.\\nassert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],3)==[85, 75, 65]\\n\"\"\"\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["# Build the prompt structure\n","messages = [\n","    {\"role\": \"system\", \"content\": system_prompt},\n","    {\"role\": \"user\", \"content\": prompt},\n","]"],"metadata":{"id":"J5qx7l6duI5A","executionInfo":{"status":"ok","timestamp":1767579448348,"user_tz":360,"elapsed":30,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["inputs = tokenizer.apply_chat_template(\n","    messages,\n","    tokenize=True,\n","    add_generation_prompt=True,\n","    return_tensors=\"pt\",\n","    return_dict=True,\n",")\n","inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}"],"metadata":{"id":"zp95CUQouI25","executionInfo":{"status":"ok","timestamp":1767579448554,"user_tz":360,"elapsed":1,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["# Generate\n","FastLanguageModel.for_inference(model)\n","with torch.no_grad():\n","    output = model.generate(\n","        **inputs,\n","        max_new_tokens=512,\n","        temperature=0.0,\n","    )"],"metadata":{"id":"zB24zGc3uI0m","executionInfo":{"status":"ok","timestamp":1767579454697,"user_tz":360,"elapsed":6083,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["# Slice to get only the generated text\n","input_len = inputs[\"input_ids\"].shape[1]\n","generated_text = tokenizer.decode(output[0][input_len:], skip_special_tokens=True)"],"metadata":{"id":"yEa1OUdJuIxm","executionInfo":{"status":"ok","timestamp":1767579454737,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["print(generated_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1-hJ_d1-p9j3","executionInfo":{"status":"ok","timestamp":1767579454746,"user_tz":360,"elapsed":7,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"692c123d-b979-474b-8676-ea44caa003a4"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["<START_WORKING_OUT>\n","Problem: Find n largest integers from a list, return in descending order.\n","Approach: Use heapq.nlargest which returns n largest elements in order from largest to smallest.\n","Parameters: List of numbers, integer n.\n","Return: List of n largest numbers in descending order.\n","</END_WORKING_OUT>\n","<SOLUTION>\n","import heapq\n","\n","def heap_queue_largest(nums, n):\n","    \"\"\"\n","    Return the n largest numbers from nums in descending order.\n","    \n","    Args:\n","        nums: List of numbers (integers or floats)\n","        n: Number of largest elements to return\n","        \n","    Returns:\n","        List of n largest numbers in descending order\n","    \"\"\"\n","    if n <= 0:\n","        return []\n","    if n >= len(nums):\n","        nums_sorted = sorted(nums, reverse=True)\n","        return nums_sorted[:n]\n","    return heapq.nlargest(n, nums)\n","</SOLUTION>\n"]}]},{"cell_type":"code","source":["# CRITICAL PART: Testing the Reward Functions\n","# The Reward Functions expect LISTS (Batches), so we wrap our single item in a list.\n","# This simulates a batch size of 1.\n","batch_prompts = [prompt]\n","batch_completions = [generated_text]\n","batch_answers = [task] # This is the \"answer\" column data"],"metadata":{"id":"mGvSjCOcun8N","executionInfo":{"status":"ok","timestamp":1767579454748,"user_tz":360,"elapsed":1,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["# 1. Test Format Reward\n","r_format = format_reward_func(completions=batch_completions)\n","print(f\"Format Reward (Expect 0.1): {r_format[0]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QKcwBYWcun5J","executionInfo":{"status":"ok","timestamp":1767579454783,"user_tz":360,"elapsed":34,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"29cac1f3-a25b-4bf7-c4e9-2824bacc6929"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Format Reward (Expect 0.1): 0.02\n"]}]},{"cell_type":"code","source":["# 2. Test Reasoning Reward\n","r_reason = reasoning_reward_func(completions=batch_completions)\n","print(f\"Reasoning Reward (Expect 0.0-0.15): {r_reason[0]:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h8Mo1AnZun3L","executionInfo":{"status":"ok","timestamp":1767579454790,"user_tz":360,"elapsed":5,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"d23bb222-5039-4be5-9dee-636755c526ee"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Reasoning Reward (Expect 0.0-0.15): 0.0663\n"]}]},{"cell_type":"code","source":["\n","# 3. Test Correctness Reward (The complex one)\n","# Note: We pass 'answer' explicitly, just like the Trainer will.\n","r_correct = correctness_reward_func(\n","    prompts=batch_prompts,\n","    completions=batch_completions,\n","    answer=batch_answers\n",")\n","print(f\"Correctness Reward (Expect 1.0 or 0.0): {r_correct[0]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"07ZCMGfIun08","executionInfo":{"status":"ok","timestamp":1767579454804,"user_tz":360,"elapsed":13,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"ee3f0248-eaeb-4b58-869b-d11fb091a7e9"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["Correctness Reward (Expect 1.0 or 0.0): 1.1\n"]}]},{"cell_type":"code","source":["if r_format[0] > 0 and (r_correct[0] == 0.0 or r_correct[0] == 1.1):\n","    print(\" SUCCESS: All reward functions accepted the inputs and returned scores.\")\n","    print(\" The plumbing is connected correctly.\")\n","else:\n","    print(\" FAIL: Something returned an unexpected format.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fADybjDeunyh","executionInfo":{"status":"ok","timestamp":1767579454807,"user_tz":360,"elapsed":2,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"46906e1b-ddb4-41e8-d7d9-bf78b3009371"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":[" SUCCESS: All reward functions accepted the inputs and returned scores.\n"," The plumbing is connected correctly.\n"]}]},{"cell_type":"markdown","source":["# Step 12: Apply Chat Template"],"metadata":{"id":"24UBloc4drcX"}},{"cell_type":"code","source":["def apply_chat_template(row):\n","    messages = [\n","        {\"role\": \"system\", \"content\": system_prompt},\n","        {\"role\": \"user\", \"content\": row[\"prompt\"]}\n","    ]\n","\n","    # \"tokenize=False\" gives us the raw text string (e.g. \"<|system|>...<|user|>...\")\n","    # This is exactly what the GRPOTrainer expects in the 'prompt' column.\n","    row[\"prompt\"] = tokenizer.apply_chat_template(\n","        messages,\n","        tokenize=False,\n","        add_generation_prompt=True\n","    )\n","    return row"],"metadata":{"id":"RO2L3cPMdG0H","executionInfo":{"status":"ok","timestamp":1767579455837,"user_tz":360,"elapsed":9,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["# Apply it to the whole dataset\n","original_prompt = dataset[0][\"prompt\"]\n","dataset = dataset.map(apply_chat_template)\n","\n","print(\"\\n--- BEFORE ---\")\n","print(original_prompt)\n","print(\"\\n--- AFTER (What the Model Sees) ---\")\n","print(dataset[0][\"prompt\"])"],"metadata":{"id":"VBJ_nPqWdzC-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Step 13: Setting up GRPO Configurations"],"metadata":{"id":"SX_1Z2XBgGJk"}},{"cell_type":"code","source":["# We give the model ample room so it never gets cut off\n","max_prompt_length = 512\n","max_completion_length = 2048  # doubled from T4 config"],"metadata":{"id":"HArFazRbd3w5","executionInfo":{"status":"ok","timestamp":1767579496389,"user_tz":360,"elapsed":4,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["vllm_sampling_params = SamplingParams(\n","    min_p = 0.1,\n","    top_p = 0.95,\n","    top_k = -1,\n","    seed = 3407,\n","    temperature = 0.8, # High enough to get diverse answers for GRPO\n","    stop = [tokenizer.eos_token],\n","    include_stop_str_in_output = True,\n",")"],"metadata":{"id":"s3bSpC1ngg_K","executionInfo":{"status":"ok","timestamp":1767579496880,"user_tz":360,"elapsed":5,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["# 3. The Trainer Config\n","training_args = GRPOConfig(\n","    # Integration\n","    vllm_sampling_params = vllm_sampling_params, # We use vLLM for speed\n","    output_dir = \"outputs\",\n","    report_to = \"wandb\",\n","    run_name = \"mbpp-grpo-h100-run4-full\",\n","\n","    # Optimization\n","    learning_rate = 5e-6,\n","    weight_decay = 0.1,\n","    warmup_ratio = 0.1,\n","    lr_scheduler_type = \"cosine\",\n","    optim = \"adamw_8bit\",\n","\n","    # A100 POWER SETTINGS\n","    per_device_train_batch_size = 1,\n","    gradient_accumulation_steps = 4,\n","    num_generations = 16,             # G=8: Much better stability than G=4\n","\n","    # Lengths\n","    max_prompt_length = max_prompt_length,\n","    max_completion_length = max_completion_length,\n","\n","    # Duration\n","    num_train_epochs = 2,            # 2 Epoch is safest for RL on small data\n","    #max_steps = 5,\n","\n","    # Logging\n","    logging_steps = 5,\n","    save_steps = 30,                 # Save more frequently\n","    use_vllm = True,                 # Explicitly enable vLLM\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IfEtXGoIgrEV","executionInfo":{"status":"ok","timestamp":1767579507381,"user_tz":360,"elapsed":21,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"e5d2a5c5-ecc9-4e8c-9cc8-0fd600433874"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Unsloth: We now expect `per_device_train_batch_size` * `gradient_accumulation_steps` * `world_size` to be a multiple of `num_generations`.\n","We will change the batch size of 1 to the `num_generations` of 16\n"]}]},{"cell_type":"markdown","source":["# Step 14: Initialize and Run GRPO Trainer"],"metadata":{"id":"Cz18F7NsrHPI"}},{"cell_type":"code","source":["# Select the Reward Functions we defined in Step 10\n","# These are the \"Judges\" that will score the model's outputs.\n","reward_functions = [\n","    format_reward_func,       # Did it use <START_WORKING_OUT> and <SOLUTION>? (0.1)\n","    reasoning_reward_func,    # Did it write ~500 chars of thought? (0.2)\n","    correctness_reward_func   # Did the code actually pass the tests? (1.0)\n","]"],"metadata":{"id":"bDJjRr2srGn1","executionInfo":{"status":"ok","timestamp":1767579507709,"user_tz":360,"elapsed":1,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["# Initialize the Trainer\n","trainer = GRPOTrainer(\n","    model = model,\n","    processing_class = tokenizer,\n","    reward_funcs = reward_functions,\n","    args = training_args,         # The A100 Config we just built\n","    train_dataset = dataset,      # The dataset with the Chat Template applied\n",")"],"metadata":{"id":"cpXKD9MYhJaI","executionInfo":{"status":"ok","timestamp":1767579508035,"user_tz":360,"elapsed":82,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"TRNxA8IKraoK","outputId":"60382391-6d7d-4bf6-ca85-bd1c130262ac","executionInfo":{"status":"ok","timestamp":1767584956418,"user_tz":360,"elapsed":5448239,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":62,"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n","   \\\\   /|    Num examples = 378 | Num Epochs = 2 | Total steps = 188\n","O^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 4\n","\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 4 x 1) = 64\n"," \"-____-\"     Trainable parameters = 66,060,288 of 4,088,528,384 (1.62% trained)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/grpo-verified-reasoner/wandb/run-20260105_021832-x0n9lpib</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/samyakshrestha-university-of-texas-at-dallas/mbpp-rl-project/runs/x0n9lpib' target=\"_blank\">mbpp-grpo-h100-run4-full</a></strong> to <a href='https://wandb.ai/samyakshrestha-university-of-texas-at-dallas/mbpp-rl-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/samyakshrestha-university-of-texas-at-dallas/mbpp-rl-project' target=\"_blank\">https://wandb.ai/samyakshrestha-university-of-texas-at-dallas/mbpp-rl-project</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/samyakshrestha-university-of-texas-at-dallas/mbpp-rl-project/runs/x0n9lpib' target=\"_blank\">https://wandb.ai/samyakshrestha-university-of-texas-at-dallas/mbpp-rl-project/runs/x0n9lpib</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["wandb: Detected [huggingface_hub.inference, openai] in use.\n","wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n","wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Will smartly offload gradients to save VRAM!\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='188' max='188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [188/188 1:29:34, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>reward</th>\n","      <th>reward_std</th>\n","      <th>completions / mean_length</th>\n","      <th>completions / min_length</th>\n","      <th>completions / max_length</th>\n","      <th>completions / clipped_ratio</th>\n","      <th>completions / mean_terminated_length</th>\n","      <th>completions / min_terminated_length</th>\n","      <th>completions / max_terminated_length</th>\n","      <th>kl</th>\n","      <th>rewards / format_reward_func / mean</th>\n","      <th>rewards / format_reward_func / std</th>\n","      <th>rewards / reasoning_reward_func / mean</th>\n","      <th>rewards / reasoning_reward_func / std</th>\n","      <th>rewards / correctness_reward_func / mean</th>\n","      <th>rewards / correctness_reward_func / std</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>5</td>\n","      <td>0.008300</td>\n","      <td>0.917053</td>\n","      <td>0.175341</td>\n","      <td>145.737500</td>\n","      <td>59.000000</td>\n","      <td>739.800000</td>\n","      <td>0.003125</td>\n","      <td>139.805557</td>\n","      <td>59.000000</td>\n","      <td>399.200000</td>\n","      <td>8.317562</td>\n","      <td>0.019937</td>\n","      <td>0.000500</td>\n","      <td>0.060240</td>\n","      <td>0.024401</td>\n","      <td>0.836875</td>\n","      <td>0.407541</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.003900</td>\n","      <td>1.014248</td>\n","      <td>0.223273</td>\n","      <td>193.525000</td>\n","      <td>69.200000</td>\n","      <td>1280.200000</td>\n","      <td>0.009375</td>\n","      <td>176.250284</td>\n","      <td>69.200000</td>\n","      <td>780.400000</td>\n","      <td>3.859137</td>\n","      <td>0.019875</td>\n","      <td>0.000701</td>\n","      <td>0.065154</td>\n","      <td>0.023300</td>\n","      <td>0.929219</td>\n","      <td>0.368260</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.000500</td>\n","      <td>0.901061</td>\n","      <td>0.330024</td>\n","      <td>183.212500</td>\n","      <td>79.600000</td>\n","      <td>892.200000</td>\n","      <td>0.003125</td>\n","      <td>177.288196</td>\n","      <td>79.600000</td>\n","      <td>557.400000</td>\n","      <td>0.542674</td>\n","      <td>0.020000</td>\n","      <td>0.000000</td>\n","      <td>0.068978</td>\n","      <td>0.026858</td>\n","      <td>0.812083</td>\n","      <td>0.442199</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.000600</td>\n","      <td>0.910160</td>\n","      <td>0.261300</td>\n","      <td>244.290625</td>\n","      <td>63.600000</td>\n","      <td>1946.000000</td>\n","      <td>0.012500</td>\n","      <td>221.132184</td>\n","      <td>63.600000</td>\n","      <td>1173.800000</td>\n","      <td>0.637628</td>\n","      <td>0.019812</td>\n","      <td>0.001201</td>\n","      <td>0.066649</td>\n","      <td>0.034955</td>\n","      <td>0.823698</td>\n","      <td>0.437160</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.001100</td>\n","      <td>1.048846</td>\n","      <td>0.212669</td>\n","      <td>197.840625</td>\n","      <td>59.200000</td>\n","      <td>1055.400000</td>\n","      <td>0.009375</td>\n","      <td>180.495294</td>\n","      <td>59.200000</td>\n","      <td>522.000000</td>\n","      <td>1.120589</td>\n","      <td>0.019937</td>\n","      <td>0.000500</td>\n","      <td>0.071929</td>\n","      <td>0.023150</td>\n","      <td>0.956979</td>\n","      <td>0.299423</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.000600</td>\n","      <td>0.752737</td>\n","      <td>0.221269</td>\n","      <td>256.506250</td>\n","      <td>68.800000</td>\n","      <td>1627.800000</td>\n","      <td>0.012500</td>\n","      <td>233.955322</td>\n","      <td>68.800000</td>\n","      <td>1139.000000</td>\n","      <td>0.649474</td>\n","      <td>0.019750</td>\n","      <td>0.001352</td>\n","      <td>0.071581</td>\n","      <td>0.036045</td>\n","      <td>0.661406</td>\n","      <td>0.447654</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.045000</td>\n","      <td>0.903331</td>\n","      <td>0.243252</td>\n","      <td>190.984375</td>\n","      <td>63.600000</td>\n","      <td>1123.400000</td>\n","      <td>0.003125</td>\n","      <td>185.278128</td>\n","      <td>63.600000</td>\n","      <td>907.200000</td>\n","      <td>45.043564</td>\n","      <td>0.020000</td>\n","      <td>0.000000</td>\n","      <td>0.073904</td>\n","      <td>0.027420</td>\n","      <td>0.809427</td>\n","      <td>0.451101</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.005700</td>\n","      <td>0.713682</td>\n","      <td>0.328387</td>\n","      <td>274.953125</td>\n","      <td>73.600000</td>\n","      <td>1341.600000</td>\n","      <td>0.015625</td>\n","      <td>247.035092</td>\n","      <td>73.600000</td>\n","      <td>1007.000000</td>\n","      <td>5.703990</td>\n","      <td>0.019750</td>\n","      <td>0.001352</td>\n","      <td>0.074870</td>\n","      <td>0.037124</td>\n","      <td>0.619063</td>\n","      <td>0.497398</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.000900</td>\n","      <td>0.891254</td>\n","      <td>0.210045</td>\n","      <td>262.625000</td>\n","      <td>75.000000</td>\n","      <td>1604.200000</td>\n","      <td>0.012500</td>\n","      <td>240.103711</td>\n","      <td>75.000000</td>\n","      <td>998.000000</td>\n","      <td>0.860802</td>\n","      <td>0.019875</td>\n","      <td>0.001000</td>\n","      <td>0.073462</td>\n","      <td>0.035464</td>\n","      <td>0.797917</td>\n","      <td>0.463865</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.000400</td>\n","      <td>0.999469</td>\n","      <td>0.299818</td>\n","      <td>237.096875</td>\n","      <td>90.800000</td>\n","      <td>1051.200000</td>\n","      <td>0.003125</td>\n","      <td>231.536609</td>\n","      <td>90.800000</td>\n","      <td>772.400000</td>\n","      <td>0.425752</td>\n","      <td>0.019937</td>\n","      <td>0.000500</td>\n","      <td>0.080990</td>\n","      <td>0.032890</td>\n","      <td>0.898542</td>\n","      <td>0.357206</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.000500</td>\n","      <td>1.048051</td>\n","      <td>0.162779</td>\n","      <td>251.765625</td>\n","      <td>69.200000</td>\n","      <td>1416.600000</td>\n","      <td>0.015625</td>\n","      <td>223.593784</td>\n","      <td>69.200000</td>\n","      <td>938.600000</td>\n","      <td>0.539351</td>\n","      <td>0.019812</td>\n","      <td>0.000852</td>\n","      <td>0.076989</td>\n","      <td>0.036684</td>\n","      <td>0.951250</td>\n","      <td>0.290710</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.000600</td>\n","      <td>0.908891</td>\n","      <td>0.286242</td>\n","      <td>295.306250</td>\n","      <td>85.800000</td>\n","      <td>1829.200000</td>\n","      <td>0.021875</td>\n","      <td>256.510431</td>\n","      <td>85.800000</td>\n","      <td>1015.600000</td>\n","      <td>0.635492</td>\n","      <td>0.019750</td>\n","      <td>0.001701</td>\n","      <td>0.069766</td>\n","      <td>0.045317</td>\n","      <td>0.819375</td>\n","      <td>0.397898</td>\n","    </tr>\n","    <tr>\n","      <td>65</td>\n","      <td>0.000700</td>\n","      <td>0.802528</td>\n","      <td>0.309861</td>\n","      <td>243.418750</td>\n","      <td>77.000000</td>\n","      <td>977.800000</td>\n","      <td>0.000000</td>\n","      <td>243.418750</td>\n","      <td>77.000000</td>\n","      <td>977.800000</td>\n","      <td>0.658965</td>\n","      <td>0.020000</td>\n","      <td>0.000000</td>\n","      <td>0.074611</td>\n","      <td>0.042932</td>\n","      <td>0.707917</td>\n","      <td>0.494022</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.000400</td>\n","      <td>0.819935</td>\n","      <td>0.254476</td>\n","      <td>303.312500</td>\n","      <td>84.400000</td>\n","      <td>1825.000000</td>\n","      <td>0.012500</td>\n","      <td>281.155670</td>\n","      <td>84.400000</td>\n","      <td>1072.000000</td>\n","      <td>0.419592</td>\n","      <td>0.019937</td>\n","      <td>0.000500</td>\n","      <td>0.076196</td>\n","      <td>0.042867</td>\n","      <td>0.723802</td>\n","      <td>0.479978</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.002700</td>\n","      <td>0.836737</td>\n","      <td>0.235765</td>\n","      <td>331.793750</td>\n","      <td>103.200000</td>\n","      <td>2048.000000</td>\n","      <td>0.031250</td>\n","      <td>277.537939</td>\n","      <td>103.200000</td>\n","      <td>948.600000</td>\n","      <td>2.738034</td>\n","      <td>0.019625</td>\n","      <td>0.002054</td>\n","      <td>0.078154</td>\n","      <td>0.041262</td>\n","      <td>0.738958</td>\n","      <td>0.490608</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.000600</td>\n","      <td>0.798150</td>\n","      <td>0.298776</td>\n","      <td>291.103125</td>\n","      <td>82.400000</td>\n","      <td>2048.000000</td>\n","      <td>0.021875</td>\n","      <td>251.866513</td>\n","      <td>82.400000</td>\n","      <td>955.800000</td>\n","      <td>0.562828</td>\n","      <td>0.019625</td>\n","      <td>0.002701</td>\n","      <td>0.078369</td>\n","      <td>0.036578</td>\n","      <td>0.700156</td>\n","      <td>0.469152</td>\n","    </tr>\n","    <tr>\n","      <td>85</td>\n","      <td>0.002000</td>\n","      <td>0.944133</td>\n","      <td>0.316302</td>\n","      <td>257.209375</td>\n","      <td>96.800000</td>\n","      <td>1413.600000</td>\n","      <td>0.012500</td>\n","      <td>234.629800</td>\n","      <td>96.800000</td>\n","      <td>567.800000</td>\n","      <td>2.042440</td>\n","      <td>0.019875</td>\n","      <td>0.001000</td>\n","      <td>0.083112</td>\n","      <td>0.033568</td>\n","      <td>0.841146</td>\n","      <td>0.420335</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.000800</td>\n","      <td>0.937997</td>\n","      <td>0.260665</td>\n","      <td>248.696875</td>\n","      <td>81.200000</td>\n","      <td>1181.800000</td>\n","      <td>0.003125</td>\n","      <td>243.095688</td>\n","      <td>81.200000</td>\n","      <td>1019.000000</td>\n","      <td>0.795987</td>\n","      <td>0.020000</td>\n","      <td>0.000000</td>\n","      <td>0.078413</td>\n","      <td>0.030928</td>\n","      <td>0.839583</td>\n","      <td>0.410716</td>\n","    </tr>\n","    <tr>\n","      <td>95</td>\n","      <td>0.000600</td>\n","      <td>0.934665</td>\n","      <td>0.223424</td>\n","      <td>215.234375</td>\n","      <td>86.200000</td>\n","      <td>864.600000</td>\n","      <td>0.003125</td>\n","      <td>209.480161</td>\n","      <td>86.200000</td>\n","      <td>541.800000</td>\n","      <td>0.613555</td>\n","      <td>0.020000</td>\n","      <td>0.000000</td>\n","      <td>0.081800</td>\n","      <td>0.032668</td>\n","      <td>0.832865</td>\n","      <td>0.383025</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.000500</td>\n","      <td>1.070177</td>\n","      <td>0.246393</td>\n","      <td>274.712500</td>\n","      <td>103.800000</td>\n","      <td>1427.400000</td>\n","      <td>0.009375</td>\n","      <td>257.763547</td>\n","      <td>103.800000</td>\n","      <td>940.000000</td>\n","      <td>0.451052</td>\n","      <td>0.019937</td>\n","      <td>0.000500</td>\n","      <td>0.081490</td>\n","      <td>0.042297</td>\n","      <td>0.968750</td>\n","      <td>0.349872</td>\n","    </tr>\n","    <tr>\n","      <td>105</td>\n","      <td>0.000700</td>\n","      <td>0.819020</td>\n","      <td>0.276125</td>\n","      <td>293.884375</td>\n","      <td>100.800000</td>\n","      <td>1767.200000</td>\n","      <td>0.018750</td>\n","      <td>260.729630</td>\n","      <td>100.800000</td>\n","      <td>1196.800000</td>\n","      <td>0.709320</td>\n","      <td>0.019750</td>\n","      <td>0.001352</td>\n","      <td>0.082499</td>\n","      <td>0.036711</td>\n","      <td>0.716771</td>\n","      <td>0.481464</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.000500</td>\n","      <td>0.783876</td>\n","      <td>0.297969</td>\n","      <td>308.765625</td>\n","      <td>108.600000</td>\n","      <td>1504.800000</td>\n","      <td>0.009375</td>\n","      <td>292.608466</td>\n","      <td>108.600000</td>\n","      <td>1254.400000</td>\n","      <td>0.505704</td>\n","      <td>0.019812</td>\n","      <td>0.001201</td>\n","      <td>0.079220</td>\n","      <td>0.038706</td>\n","      <td>0.684844</td>\n","      <td>0.404036</td>\n","    </tr>\n","    <tr>\n","      <td>115</td>\n","      <td>0.000500</td>\n","      <td>0.880284</td>\n","      <td>0.289017</td>\n","      <td>302.606250</td>\n","      <td>80.800000</td>\n","      <td>1789.600000</td>\n","      <td>0.025000</td>\n","      <td>258.028439</td>\n","      <td>80.800000</td>\n","      <td>1015.600000</td>\n","      <td>0.508625</td>\n","      <td>0.019687</td>\n","      <td>0.001852</td>\n","      <td>0.077680</td>\n","      <td>0.043298</td>\n","      <td>0.782917</td>\n","      <td>0.418157</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.000500</td>\n","      <td>0.963055</td>\n","      <td>0.261982</td>\n","      <td>236.534375</td>\n","      <td>88.600000</td>\n","      <td>1059.800000</td>\n","      <td>0.003125</td>\n","      <td>230.865778</td>\n","      <td>88.600000</td>\n","      <td>828.600000</td>\n","      <td>0.528580</td>\n","      <td>0.020000</td>\n","      <td>0.000000</td>\n","      <td>0.083420</td>\n","      <td>0.032172</td>\n","      <td>0.859635</td>\n","      <td>0.405787</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.000400</td>\n","      <td>1.010831</td>\n","      <td>0.280232</td>\n","      <td>272.809375</td>\n","      <td>89.800000</td>\n","      <td>1010.800000</td>\n","      <td>0.003125</td>\n","      <td>267.418256</td>\n","      <td>89.800000</td>\n","      <td>856.400000</td>\n","      <td>0.405537</td>\n","      <td>0.019937</td>\n","      <td>0.000500</td>\n","      <td>0.082144</td>\n","      <td>0.035214</td>\n","      <td>0.908750</td>\n","      <td>0.378931</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.000600</td>\n","      <td>0.926139</td>\n","      <td>0.261707</td>\n","      <td>327.412500</td>\n","      <td>103.600000</td>\n","      <td>2048.000000</td>\n","      <td>0.040625</td>\n","      <td>255.344666</td>\n","      <td>103.600000</td>\n","      <td>1179.600000</td>\n","      <td>0.564745</td>\n","      <td>0.019437</td>\n","      <td>0.002783</td>\n","      <td>0.075712</td>\n","      <td>0.043390</td>\n","      <td>0.830990</td>\n","      <td>0.397211</td>\n","    </tr>\n","    <tr>\n","      <td>135</td>\n","      <td>0.000500</td>\n","      <td>1.074616</td>\n","      <td>0.195279</td>\n","      <td>245.215625</td>\n","      <td>88.400000</td>\n","      <td>1431.200000</td>\n","      <td>0.012500</td>\n","      <td>222.586249</td>\n","      <td>88.400000</td>\n","      <td>552.600000</td>\n","      <td>0.495118</td>\n","      <td>0.019937</td>\n","      <td>0.000500</td>\n","      <td>0.084158</td>\n","      <td>0.036635</td>\n","      <td>0.970521</td>\n","      <td>0.296879</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.000500</td>\n","      <td>0.938030</td>\n","      <td>0.295756</td>\n","      <td>302.740625</td>\n","      <td>113.400000</td>\n","      <td>1806.200000</td>\n","      <td>0.015625</td>\n","      <td>274.819766</td>\n","      <td>113.400000</td>\n","      <td>1062.600000</td>\n","      <td>0.544476</td>\n","      <td>0.019937</td>\n","      <td>0.000500</td>\n","      <td>0.076321</td>\n","      <td>0.050234</td>\n","      <td>0.841771</td>\n","      <td>0.414048</td>\n","    </tr>\n","    <tr>\n","      <td>145</td>\n","      <td>0.000400</td>\n","      <td>0.982933</td>\n","      <td>0.223077</td>\n","      <td>277.481250</td>\n","      <td>108.800000</td>\n","      <td>1649.200000</td>\n","      <td>0.006250</td>\n","      <td>266.526495</td>\n","      <td>108.800000</td>\n","      <td>1278.200000</td>\n","      <td>0.440563</td>\n","      <td>0.019875</td>\n","      <td>0.001000</td>\n","      <td>0.080662</td>\n","      <td>0.039247</td>\n","      <td>0.882396</td>\n","      <td>0.403316</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.000500</td>\n","      <td>0.869949</td>\n","      <td>0.267323</td>\n","      <td>330.546875</td>\n","      <td>97.400000</td>\n","      <td>1458.000000</td>\n","      <td>0.006250</td>\n","      <td>319.904919</td>\n","      <td>97.400000</td>\n","      <td>1169.600000</td>\n","      <td>0.524577</td>\n","      <td>0.019750</td>\n","      <td>0.001701</td>\n","      <td>0.067438</td>\n","      <td>0.054461</td>\n","      <td>0.782760</td>\n","      <td>0.444609</td>\n","    </tr>\n","    <tr>\n","      <td>155</td>\n","      <td>0.000500</td>\n","      <td>0.698878</td>\n","      <td>0.301432</td>\n","      <td>343.440625</td>\n","      <td>118.800000</td>\n","      <td>1582.200000</td>\n","      <td>0.015625</td>\n","      <td>316.882776</td>\n","      <td>118.800000</td>\n","      <td>1069.000000</td>\n","      <td>0.480214</td>\n","      <td>0.019750</td>\n","      <td>0.001403</td>\n","      <td>0.076940</td>\n","      <td>0.045368</td>\n","      <td>0.602188</td>\n","      <td>0.522861</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.000700</td>\n","      <td>1.022698</td>\n","      <td>0.196326</td>\n","      <td>256.506250</td>\n","      <td>93.800000</td>\n","      <td>1350.200000</td>\n","      <td>0.003125</td>\n","      <td>251.194647</td>\n","      <td>93.800000</td>\n","      <td>1155.200000</td>\n","      <td>0.747510</td>\n","      <td>0.019937</td>\n","      <td>0.000500</td>\n","      <td>0.082240</td>\n","      <td>0.031849</td>\n","      <td>0.920521</td>\n","      <td>0.294702</td>\n","    </tr>\n","    <tr>\n","      <td>165</td>\n","      <td>0.000600</td>\n","      <td>0.991776</td>\n","      <td>0.258878</td>\n","      <td>320.156250</td>\n","      <td>85.800000</td>\n","      <td>1815.800000</td>\n","      <td>0.021875</td>\n","      <td>281.685196</td>\n","      <td>85.800000</td>\n","      <td>1137.000000</td>\n","      <td>0.602839</td>\n","      <td>0.019562</td>\n","      <td>0.002554</td>\n","      <td>0.074870</td>\n","      <td>0.047406</td>\n","      <td>0.897344</td>\n","      <td>0.332155</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.000400</td>\n","      <td>0.848510</td>\n","      <td>0.291594</td>\n","      <td>314.265625</td>\n","      <td>114.200000</td>\n","      <td>1802.000000</td>\n","      <td>0.012500</td>\n","      <td>292.660333</td>\n","      <td>114.200000</td>\n","      <td>1161.200000</td>\n","      <td>0.444122</td>\n","      <td>0.019812</td>\n","      <td>0.001500</td>\n","      <td>0.075885</td>\n","      <td>0.043752</td>\n","      <td>0.752813</td>\n","      <td>0.409131</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.000800</td>\n","      <td>1.002514</td>\n","      <td>0.255594</td>\n","      <td>296.990625</td>\n","      <td>102.600000</td>\n","      <td>1737.200000</td>\n","      <td>0.015625</td>\n","      <td>268.868008</td>\n","      <td>102.600000</td>\n","      <td>1006.000000</td>\n","      <td>0.753369</td>\n","      <td>0.019812</td>\n","      <td>0.000852</td>\n","      <td>0.081660</td>\n","      <td>0.038570</td>\n","      <td>0.901042</td>\n","      <td>0.364280</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.000500</td>\n","      <td>0.782033</td>\n","      <td>0.267435</td>\n","      <td>391.437500</td>\n","      <td>131.800000</td>\n","      <td>1737.200000</td>\n","      <td>0.021875</td>\n","      <td>354.767572</td>\n","      <td>131.800000</td>\n","      <td>1513.600000</td>\n","      <td>0.546412</td>\n","      <td>0.019438</td>\n","      <td>0.002783</td>\n","      <td>0.071762</td>\n","      <td>0.054369</td>\n","      <td>0.690833</td>\n","      <td>0.489857</td>\n","    </tr>\n","    <tr>\n","      <td>185</td>\n","      <td>0.000500</td>\n","      <td>0.907148</td>\n","      <td>0.248970</td>\n","      <td>271.646875</td>\n","      <td>100.800000</td>\n","      <td>1374.000000</td>\n","      <td>0.009375</td>\n","      <td>254.726657</td>\n","      <td>100.800000</td>\n","      <td>950.200000</td>\n","      <td>0.473860</td>\n","      <td>0.019812</td>\n","      <td>0.001201</td>\n","      <td>0.080095</td>\n","      <td>0.036991</td>\n","      <td>0.807240</td>\n","      <td>0.413769</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["90\n","True\n","True\n","True\n","True\n","False\n","-inf\n","20\n","13\n","1\n","12\n","64\n","[('Social sciences', 82), ('English', 88), ('Science', 90), ('Maths', 97)]\n","(0, 0, '')\n","[3, 4, 5, 6, 7, 10]\n","30\n","[(6, 24, 12)]\n","[1, 4, 9, 16, 25]\n","Computed angle: 1.5707963267948966\n","[('Red',), ('Green',), ('Blue',)]\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]},{"output_type":"stream","name":"stdout","text":["204.20352248333654\n","243\n","345\n","513\n","243\n","243\n","345\n","513\n","243\n","243\n","345\n","513\n","243\n","345\n","513\n","16.0\n","106\n","1256.6370614359173\n","7\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>profiling/Time taken: UnslothGRPOTrainer._calculate_rewards</td><td>â–ˆâ–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–â–‚â–‚â–â–â–‚â–â–‚â–‚â–ˆâ–‚â–‚â–â–ˆâ–‚â–‚â–ƒâ–‚â–ƒâ–â–â–‚</td></tr><tr><td>profiling/Time taken: UnslothGRPOTrainer._prepare_inputs</td><td>â–â–â–â–†â–â–†â–â–â–ˆâ–ˆâ–…â–â–ˆâ–â–â–â–ˆâ–ˆâ–â–ˆâ–â–â–â–…â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–ˆâ–â–ˆâ–â–</td></tr><tr><td>profiling/Time taken: UnslothGRPOTrainer.correctness_reward_func</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>profiling/Time taken: UnslothGRPOTrainer.format_reward_func</td><td>â–‚â–‚â–‚â–â–â–…â–‚â–‚â–†â–„â–ƒâ–ƒâ–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–†â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–…â–†â–‡â–…â–†â–‚â–…</td></tr><tr><td>profiling/Time taken: UnslothGRPOTrainer.reasoning_reward_func</td><td>â–â–‚â–â–‚â–‚â–ƒâ–ƒâ–ˆâ–„â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–ˆâ–ƒâ–„â–…â–ƒâ–ƒâ–†â–ƒâ–„â–„â–„â–ƒâ–„â–„â–‡â–„â–†â–†â–‡â–„â–„â–…â–ƒâ–†</td></tr><tr><td>profiling/Time taken: UnslothGRPOTrainer.vLLM.generate</td><td>â–ˆâ–„â–‡â–â–â–â–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ƒâ–„â–ƒâ–ˆâ–ˆâ–ƒâ–„â–‡â–„â–‡â–ˆâ–ˆâ–ˆâ–…â–‚â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–‡â–ˆâ–ˆâ–‚â–†â–ˆ</td></tr><tr><td>train/completion_length</td><td>â–â–‚â–‚â–„â–‚â–„â–‚â–…â–„â–„â–„â–…â–„â–…â–†â–…â–„â–„â–ƒâ–…â–…â–†â–…â–„â–…â–†â–„â–…â–…â–†â–‡â–„â–†â–†â–…â–ˆâ–…â–†</td></tr><tr><td>train/completions/clipped_ratio</td><td>â–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–„â–…â–â–ƒâ–†â–…â–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–…â–‚â–‚â–ˆâ–ƒâ–„â–‚â–‚â–„â–‚â–…â–ƒâ–„â–…â–ƒâ–„</td></tr><tr><td>train/completions/max_length</td><td>â–â–„â–‚â–‡â–ƒâ–†â–ƒâ–„â–†â–ƒâ–…â–‡â–‚â–‡â–ˆâ–ˆâ–…â–ƒâ–‚â–…â–†â–…â–‡â–ƒâ–‚â–ˆâ–…â–‡â–†â–…â–†â–„â–‡â–‡â–†â–†â–„â–†</td></tr><tr><td>train/completions/max_terminated_length</td><td>â–â–ƒâ–‚â–†â–‚â–†â–„â–…â–…â–ƒâ–„â–…â–…â–…â–„â–„â–‚â–…â–‚â–„â–†â–†â–…â–„â–„â–†â–‚â–…â–‡â–†â–…â–†â–†â–†â–…â–ˆâ–„â–‡</td></tr><tr><td>+20</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>profiling/Time taken: UnslothGRPOTrainer._calculate_rewards</td><td>5.18347</td></tr><tr><td>profiling/Time taken: UnslothGRPOTrainer._prepare_inputs</td><td>1e-05</td></tr><tr><td>profiling/Time taken: UnslothGRPOTrainer.correctness_reward_func</td><td>5.18033</td></tr><tr><td>profiling/Time taken: UnslothGRPOTrainer.format_reward_func</td><td>0.00032</td></tr><tr><td>profiling/Time taken: UnslothGRPOTrainer.reasoning_reward_func</td><td>0.0006</td></tr><tr><td>profiling/Time taken: UnslothGRPOTrainer.vLLM.generate</td><td>11.72052</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/completion_length</td><td>317.44271</td></tr><tr><td>train/completions/clipped_ratio</td><td>0.01562</td></tr><tr><td>train/completions/max_length</td><td>1581.66667</td></tr><tr><td>+25</td><td>...</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">mbpp-grpo-h100-run4-full</strong> at: <a href='https://wandb.ai/samyakshrestha-university-of-texas-at-dallas/mbpp-rl-project/runs/x0n9lpib' target=\"_blank\">https://wandb.ai/samyakshrestha-university-of-texas-at-dallas/mbpp-rl-project/runs/x0n9lpib</a><br> View project at: <a href='https://wandb.ai/samyakshrestha-university-of-texas-at-dallas/mbpp-rl-project' target=\"_blank\">https://wandb.ai/samyakshrestha-university-of-texas-at-dallas/mbpp-rl-project</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20260105_021832-x0n9lpib/logs</code>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=188, training_loss=0.0022916886509653737, metrics={'train_runtime': 5441.8689, 'train_samples_per_second': 0.139, 'train_steps_per_second': 0.035, 'total_flos': 0.0, 'train_loss': 0.0022916886509653737})"]},"metadata":{},"execution_count":62}]},{"cell_type":"markdown","source":["# Step 15: Sanity Check\n","\n","Let us now check the model that we just trained!"],"metadata":{"id":"pbb39NqiB9E8"}},{"cell_type":"code","source":["# Switch to Inference Mode\n","FastLanguageModel.for_inference(model)"],"metadata":{"id":"6rXx16M4-i8j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767585024455,"user_tz":360,"elapsed":18,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"0f86134c-9419-4548-9429-c8a01f552357"},"execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): Qwen3ForCausalLM(\n","      (model): Qwen3Model(\n","        (embed_tokens): Embedding(151936, 2560, padding_idx=151654)\n","        (layers): ModuleList(\n","          (0-35): 36 x Qwen3DecoderLayer(\n","            (self_attn): Qwen3Attention(\n","              (q_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear(\n","                (base_layer): Linear(in_features=4096, out_features=2560, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): Qwen3MLP(\n","              (gate_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9728, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9728, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear(\n","                (base_layer): Linear(in_features=9728, out_features=2560, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=9728, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","          )\n","        )\n","        (norm): Qwen3RMSNorm((2560,), eps=1e-06)\n","        (rotary_emb): LlamaRotaryEmbedding()\n","      )\n","      (lm_head): Linear(in_features=2560, out_features=151936, bias=False)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["test_question = \"Write a function to find the volume of a sphere given its radius.\""],"metadata":{"id":"KDUXcF5WCVAQ","executionInfo":{"status":"ok","timestamp":1767585026530,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["messages = [\n","    {\"role\": \"system\", \"content\": system_prompt},\n","    {\"role\": \"user\", \"content\": test_question},\n","]"],"metadata":{"id":"pheP84NQCZ0U","executionInfo":{"status":"ok","timestamp":1767585026733,"user_tz":360,"elapsed":2,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["# Tokenize (Exactly as before)\n","inputs = tokenizer.apply_chat_template(\n","    messages,\n","    tokenize=True,\n","    add_generation_prompt=True,\n","    return_tensors=\"pt\",\n","    return_dict=True,\n",")\n","inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}"],"metadata":{"id":"yzUBfniDCdY2","executionInfo":{"status":"ok","timestamp":1767585027283,"user_tz":360,"elapsed":1,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["# Generate\n","with torch.no_grad():\n","    output = model.generate(\n","        **inputs,\n","        max_new_tokens=512,\n","        temperature=0.8, # Slight creativity to encourage reasoning\n","    )"],"metadata":{"id":"Ypr3vQCmCevo","executionInfo":{"status":"ok","timestamp":1767585033556,"user_tz":360,"elapsed":6064,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["# 5. Decode (Slicing input_len just like before)\n","input_len = inputs[\"input_ids\"].shape[1]\n","generated_text = tokenizer.decode(output[0][input_len:], skip_special_tokens=True)\n","\n","print(\"\\n=== FINAL MODEL OUTPUT ===\")\n","print(generated_text)"],"metadata":{"id":"TkVWR8DUCkV2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767585033579,"user_tz":360,"elapsed":10,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"b6d0856d-2c5d-4b09-cc8a-01ac6f6521cd"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== FINAL MODEL OUTPUT ===\n","<START_WORKING_OUT>\n","The formula for the volume of a sphere is V = (4/3) * Ï€ * rÂ³.\n","We need a function that takes the radius r as input and returns the volume.\n","We can use the math module for the value of Ï€.\n","The function should handle positive radius values.\n","We'll return the calculated volume as a float.\n","</END_WORKING_OUT>\n","<SOLUTION>\n","import math\n","\n","def sphere_volume(radius):\n","    \"\"\"\n","    Calculate the volume of a sphere given its radius.\n","    \n","    Parameters:\n","    radius (float): The radius of the sphere.\n","    \n","    Returns:\n","    float: The volume of the sphere.\n","    \"\"\"\n","    if radius < 0:\n","        raise ValueError(\"Radius must be non-negative\")\n","    return (4/3) * math.pi * (radius ** 3)\n","</SOLUTION>\n"]}]},{"cell_type":"markdown","source":["# Step 16: Saving the Model"],"metadata":{"id":"KycC-7u-DdY9"}},{"cell_type":"code","source":["MODEL_OUT = \"models/qwen3-4b-grpo-final-2\""],"metadata":{"id":"AwIpGowdDfgG","executionInfo":{"status":"ok","timestamp":1767585112526,"user_tz":360,"elapsed":233,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["model.save_lora(MODEL_OUT)"],"metadata":{"id":"Hxf16u_-DtKQ","executionInfo":{"status":"ok","timestamp":1767585113319,"user_tz":360,"elapsed":781,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["tokenizer.save_pretrained(MODEL_OUT)"],"metadata":{"id":"HKiRos6BDych","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767585113478,"user_tz":360,"elapsed":149,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"a8a8ef52-ae50-4ba8-fe9f-a2eb5dcca989"},"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('models/qwen3-4b-grpo-final-2/tokenizer_config.json',\n"," 'models/qwen3-4b-grpo-final-2/special_tokens_map.json',\n"," 'models/qwen3-4b-grpo-final-2/chat_template.jinja',\n"," 'models/qwen3-4b-grpo-final-2/vocab.json',\n"," 'models/qwen3-4b-grpo-final-2/merges.txt',\n"," 'models/qwen3-4b-grpo-final-2/added_tokens.json',\n"," 'models/qwen3-4b-grpo-final-2/tokenizer.json')"]},"metadata":{},"execution_count":71}]}]}