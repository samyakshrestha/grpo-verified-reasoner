{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"H100","machine_shape":"hm","authorship_tag":"ABX9TyMzn58z08birRVg+Ipp6yd1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"513c4c2ec3f94a19a436dff1eb3fe422":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_df9ee308bb2241af9f55d849129cd105","IPY_MODEL_a69cb63a96a94a699d300d69f483502b","IPY_MODEL_0bb164c01fd848e29118e7afc04f5c55"],"layout":"IPY_MODEL_c2079be8f1264e06aad38e9b562ddcee"}},"df9ee308bb2241af9f55d849129cd105":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_796481a77e4340cbb8b84e74d424be84","placeholder":"​","style":"IPY_MODEL_949360157cf04842a75e0dd43b8be549","value":"tokenizer_config.json: "}},"a69cb63a96a94a699d300d69f483502b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5a49b52fee542f4b263fa2f49344bd7","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b73d4a0a60ee4af68a8f72ca07ac28f5","value":1}},"0bb164c01fd848e29118e7afc04f5c55":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ab21dd075814d63a5b7c7dd4642a0a4","placeholder":"​","style":"IPY_MODEL_5840980400074fe3b40778ed5dab74d6","value":" 5.43k/? [00:00&lt;00:00, 744kB/s]"}},"c2079be8f1264e06aad38e9b562ddcee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"796481a77e4340cbb8b84e74d424be84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"949360157cf04842a75e0dd43b8be549":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5a49b52fee542f4b263fa2f49344bd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"b73d4a0a60ee4af68a8f72ca07ac28f5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ab21dd075814d63a5b7c7dd4642a0a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5840980400074fe3b40778ed5dab74d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18de49f9543746ee9307c53a18b35a5a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5821684f0a564b14b0b9b473762761b6","IPY_MODEL_fc3131dec2cf41aa91672b04a6d98d3c","IPY_MODEL_4c6e017fdefa44488ff94140c34e209c"],"layout":"IPY_MODEL_77818c8fddfb44928add2b83657de9cd"}},"5821684f0a564b14b0b9b473762761b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f2f038ca40e46fdb0d3a3528a84e91a","placeholder":"​","style":"IPY_MODEL_acb0d1f6a4434601a02b4812368839b1","value":"vocab.json: "}},"fc3131dec2cf41aa91672b04a6d98d3c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ea1c1f92b824fd2912f5ef2350a5d63","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3ddc7559bc2e411881f7270feba2731e","value":1}},"4c6e017fdefa44488ff94140c34e209c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d2a107ea83149a88a7c32a8cbbb7f0d","placeholder":"​","style":"IPY_MODEL_c0750ce542894de8ac27dec895776e70","value":" 2.78M/? [00:00&lt;00:00, 124MB/s]"}},"77818c8fddfb44928add2b83657de9cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f2f038ca40e46fdb0d3a3528a84e91a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acb0d1f6a4434601a02b4812368839b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ea1c1f92b824fd2912f5ef2350a5d63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"3ddc7559bc2e411881f7270feba2731e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6d2a107ea83149a88a7c32a8cbbb7f0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0750ce542894de8ac27dec895776e70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6adac0dd0e1447088fa785de9f92c1e9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_57bcf5d4796248c29bdabc3764813edc","IPY_MODEL_4ce1a84ecebf449c873833c9aa506cec","IPY_MODEL_b3916854d6ae4901815b94b9f804c0d0"],"layout":"IPY_MODEL_2d09e4cf76cd4ee6b8885b589b25fd02"}},"57bcf5d4796248c29bdabc3764813edc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_832a2dde74684dea96babc8e1e91b305","placeholder":"​","style":"IPY_MODEL_cb2f9d108a1c412f9f846d626e1897c6","value":"merges.txt: "}},"4ce1a84ecebf449c873833c9aa506cec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0eff82ba33064ae1b818d1461ecc4135","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_56303c6d739c428eb41cd3061caa57a1","value":1}},"b3916854d6ae4901815b94b9f804c0d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_caf156afe6da4ec387443f261ff44c0a","placeholder":"​","style":"IPY_MODEL_97b97eeab7b5454aadb7d8fa2a12415b","value":" 1.67M/? [00:00&lt;00:00, 109MB/s]"}},"2d09e4cf76cd4ee6b8885b589b25fd02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"832a2dde74684dea96babc8e1e91b305":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb2f9d108a1c412f9f846d626e1897c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0eff82ba33064ae1b818d1461ecc4135":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"56303c6d739c428eb41cd3061caa57a1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"caf156afe6da4ec387443f261ff44c0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97b97eeab7b5454aadb7d8fa2a12415b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a730d7a10434a1d899b717a9e4fec34":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_114e298abba14a08bed94bae22b01c88","IPY_MODEL_6b4d6091b61a40e3908f61dba7ae9fd0","IPY_MODEL_ec2a97c74646463a88565a2ab1790fb1"],"layout":"IPY_MODEL_6e586971befd43e6beaf3df04e3af27d"}},"114e298abba14a08bed94bae22b01c88":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ef86455586e42be8e1ff5501c13970e","placeholder":"​","style":"IPY_MODEL_5f6c9d41aff447e4b58c8079ac16fb37","value":"tokenizer.json: 100%"}},"6b4d6091b61a40e3908f61dba7ae9fd0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0582a63b9bc4485aea3f7b49ac58f8c","max":11422654,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2947fb858f9b4b679b8b2606afee0f38","value":11422654}},"ec2a97c74646463a88565a2ab1790fb1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a36c77f08374217a6032d8c925d9ca6","placeholder":"​","style":"IPY_MODEL_8658c5288f06403982e0159df01e7945","value":" 11.4M/11.4M [00:01&lt;00:00, 6.29MB/s]"}},"6e586971befd43e6beaf3df04e3af27d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ef86455586e42be8e1ff5501c13970e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f6c9d41aff447e4b58c8079ac16fb37":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0582a63b9bc4485aea3f7b49ac58f8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2947fb858f9b4b679b8b2606afee0f38":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1a36c77f08374217a6032d8c925d9ca6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8658c5288f06403982e0159df01e7945":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9055795800174ef594e1a1afdbfa018f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1a3b34330aa648cbb27325a5570b94b9","IPY_MODEL_5d9b8a3187e540499f9b81b22db234e4","IPY_MODEL_e56735f4077c42289a8e29052a87ddf5"],"layout":"IPY_MODEL_f81ed31125a6453b86e066bb70a85f8a"}},"1a3b34330aa648cbb27325a5570b94b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3e462ec1dad40a7b2abee14f62cf890","placeholder":"​","style":"IPY_MODEL_26d330570f4c4e07b4c6dfe60059b899","value":"added_tokens.json: 100%"}},"5d9b8a3187e540499f9b81b22db234e4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_35b99d8cce9d49bf86e0587f632d5612","max":707,"min":0,"orientation":"horizontal","style":"IPY_MODEL_30b8ba87a79846fba6d8fef587c69a06","value":707}},"e56735f4077c42289a8e29052a87ddf5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca84a885ff1f4e2e89a3a6bea1c45a82","placeholder":"​","style":"IPY_MODEL_4819e7eab4154798b10ba1f3fe1bf551","value":" 707/707 [00:00&lt;00:00, 142kB/s]"}},"f81ed31125a6453b86e066bb70a85f8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3e462ec1dad40a7b2abee14f62cf890":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26d330570f4c4e07b4c6dfe60059b899":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35b99d8cce9d49bf86e0587f632d5612":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30b8ba87a79846fba6d8fef587c69a06":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca84a885ff1f4e2e89a3a6bea1c45a82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4819e7eab4154798b10ba1f3fe1bf551":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09c976b9866745f4ad70efe287a0acaa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_58ed99f43bb44b678e0744bd2ffae177","IPY_MODEL_a16f261ba20a4e34a85e4b8ab36cb7f9","IPY_MODEL_de5b2a0ee5364fdfadeb82afc925bb79"],"layout":"IPY_MODEL_033a76c871234d678f787ef0e9591743"}},"58ed99f43bb44b678e0744bd2ffae177":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_661cde23f99e4ed09210cdb613cdeb0d","placeholder":"​","style":"IPY_MODEL_74eb90a089fa47b692cd6bb3d074561d","value":"special_tokens_map.json: 100%"}},"a16f261ba20a4e34a85e4b8ab36cb7f9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_44e7dbf9eaca41a2b51b2783af42bf68","max":617,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8718eacc54914290890a67fc70ac642c","value":617}},"de5b2a0ee5364fdfadeb82afc925bb79":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd917a0d54ae44b0b08f37c32974bc82","placeholder":"​","style":"IPY_MODEL_b11dbbdc941f445ebfd2e009520ec36b","value":" 617/617 [00:00&lt;00:00, 129kB/s]"}},"033a76c871234d678f787ef0e9591743":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"661cde23f99e4ed09210cdb613cdeb0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74eb90a089fa47b692cd6bb3d074561d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"44e7dbf9eaca41a2b51b2783af42bf68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8718eacc54914290890a67fc70ac642c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cd917a0d54ae44b0b08f37c32974bc82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b11dbbdc941f445ebfd2e009520ec36b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"471ac1ab25b544d8bcfbf26a5cb41f8e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_af17f312324e433fb9942f7ee33e4704","IPY_MODEL_ebfef543895646888a48e13c5f0bfba1","IPY_MODEL_8d468cbb7f264939a258ff11543ad5b2"],"layout":"IPY_MODEL_ae23858125fe4127a9a24b02ac4c0dbf"}},"af17f312324e433fb9942f7ee33e4704":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0424fb9bc91421399ed480ce26909e6","placeholder":"​","style":"IPY_MODEL_632f8d5b8c104d9db873238f4e9c5aaf","value":"generation_config.json: 100%"}},"ebfef543895646888a48e13c5f0bfba1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_02d8db5f5cd148beab999350d62f9124","max":166,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c190f2f439214d4b97547c4b9667b3ad","value":166}},"8d468cbb7f264939a258ff11543ad5b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7b371cb88904c46a555c02867cb7b14","placeholder":"​","style":"IPY_MODEL_dbdcce96269042ef83aed0903d88cb3b","value":" 166/166 [00:00&lt;00:00, 27.9kB/s]"}},"ae23858125fe4127a9a24b02ac4c0dbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0424fb9bc91421399ed480ce26909e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"632f8d5b8c104d9db873238f4e9c5aaf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02d8db5f5cd148beab999350d62f9124":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c190f2f439214d4b97547c4b9667b3ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f7b371cb88904c46a555c02867cb7b14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbdcce96269042ef83aed0903d88cb3b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4791451fc8bb432b8804adbad03e8e4f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3418e39ec02440c1b2d328f6dacb485c","IPY_MODEL_eb42950100034f6fba659ef80d191094","IPY_MODEL_c382ecafe15d4011a93bbefcb081659b"],"layout":"IPY_MODEL_d5c2741f5f9f46d9ba263a2de5412393"}},"3418e39ec02440c1b2d328f6dacb485c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25123eef76074c089df2ea9e9d1457c9","placeholder":"​","style":"IPY_MODEL_ab991ae40d804b14886ad743169a8ff0","value":"model-00002-of-00002.safetensors: 100%"}},"eb42950100034f6fba659ef80d191094":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_73388478a507489d8e02abb83c729418","max":3077766632,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2e8107aa010c4dee95cd0a7c424cebf6","value":3077766632}},"c382ecafe15d4011a93bbefcb081659b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a067186ab744c31be0a5f6e2b5397fd","placeholder":"​","style":"IPY_MODEL_3a1e6d158c7f49e6b978a69fa518582c","value":" 3.08G/3.08G [00:07&lt;00:00, 237MB/s]"}},"d5c2741f5f9f46d9ba263a2de5412393":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25123eef76074c089df2ea9e9d1457c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab991ae40d804b14886ad743169a8ff0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73388478a507489d8e02abb83c729418":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e8107aa010c4dee95cd0a7c424cebf6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a067186ab744c31be0a5f6e2b5397fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a1e6d158c7f49e6b978a69fa518582c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfc46c3db0ce4bc6b8fc194206ad464f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c1ba0a1a4be64a8bbca58dea00f31af4","IPY_MODEL_b392b73be7ad484aa619da51484a5d9b","IPY_MODEL_aa65374a579c4102bdf03d292fcbae4a"],"layout":"IPY_MODEL_514ba9a4e57e429795b71be907e51a61"}},"c1ba0a1a4be64a8bbca58dea00f31af4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_571b8b92c888415cae1517f38bd0b40b","placeholder":"​","style":"IPY_MODEL_b4e61da8730f4943b5db58eb6e0169ad","value":"model-00001-of-00002.safetensors: 100%"}},"b392b73be7ad484aa619da51484a5d9b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3afb435a85b424bbc89535da48210da","max":4967215360,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ba6356a458dc43dfb92a3fcb67deb220","value":4967215360}},"aa65374a579c4102bdf03d292fcbae4a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_186712db0c9140d99054e17974be14aa","placeholder":"​","style":"IPY_MODEL_1f1cbc291a394e18bb9deadf04d69867","value":" 4.97G/4.97G [00:13&lt;00:00, 702MB/s]"}},"514ba9a4e57e429795b71be907e51a61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"571b8b92c888415cae1517f38bd0b40b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4e61da8730f4943b5db58eb6e0169ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c3afb435a85b424bbc89535da48210da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba6356a458dc43dfb92a3fcb67deb220":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"186712db0c9140d99054e17974be14aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f1cbc291a394e18bb9deadf04d69867":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac4fa7e68b424bc48e5684f7405a5b20":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8189fc99e3234d738858895809c24348","IPY_MODEL_20bee10ff6c44ad5b9749e008801bb9c","IPY_MODEL_984c562a20fe40f88609736883c4bba6"],"layout":"IPY_MODEL_3421fbf3111c46a7bac7b770b6a76d9b"}},"8189fc99e3234d738858895809c24348":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df95a990c11c4f62acd2c9cf0c95e1fa","placeholder":"​","style":"IPY_MODEL_890acd7060b64b8dbbcfa66fead1b29c","value":"model.safetensors.index.json: "}},"20bee10ff6c44ad5b9749e008801bb9c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5a2c802343447a5bbde6862fd327d36","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_77dfe5ced6184e5abb549b4a52f9e31b","value":1}},"984c562a20fe40f88609736883c4bba6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa59be05c5a7404d93a555b77354463f","placeholder":"​","style":"IPY_MODEL_72d555c69d2c484f832dbb717bc60724","value":" 32.8k/? [00:00&lt;00:00, 4.94MB/s]"}},"3421fbf3111c46a7bac7b770b6a76d9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df95a990c11c4f62acd2c9cf0c95e1fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"890acd7060b64b8dbbcfa66fead1b29c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5a2c802343447a5bbde6862fd327d36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"77dfe5ced6184e5abb549b4a52f9e31b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aa59be05c5a7404d93a555b77354463f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72d555c69d2c484f832dbb717bc60724":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69da48d0d9f74755b2b9b5afe321bd14":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b52ef7d9993f4da6ba5b8751bc155f7a","IPY_MODEL_f4f85aab6e0b42a389ed411473466dc5","IPY_MODEL_9dd9e90f8004462b9498ce8935000891"],"layout":"IPY_MODEL_498694a004a2458d82fe9e4c2ab99838"}},"b52ef7d9993f4da6ba5b8751bc155f7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a58f6391cec48ac99a03e5dfc4e319a","placeholder":"​","style":"IPY_MODEL_f0a2388ebeaf49ee98f8f1890533fd1d","value":""}},"f4f85aab6e0b42a389ed411473466dc5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb4ceb463e93449ba84b2141024419e6","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2f7c5bb53be49dfb397d0681cafc60e","value":2}},"9dd9e90f8004462b9498ce8935000891":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f9105ef1ecc42e199c2a050f9cf80c5","placeholder":"​","style":"IPY_MODEL_dc8049de557c4a1480e46368614618e5","value":"Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01&lt;00:00,  1.41it/s]\n"}},"498694a004a2458d82fe9e4c2ab99838":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a58f6391cec48ac99a03e5dfc4e319a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0a2388ebeaf49ee98f8f1890533fd1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb4ceb463e93449ba84b2141024419e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2f7c5bb53be49dfb397d0681cafc60e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f9105ef1ecc42e199c2a050f9cf80c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc8049de557c4a1480e46368614618e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"122187d0ded7461f9d1f3c510e8f446b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7771d1c9a9b746ee85a0e6495de9ea83","IPY_MODEL_faca98b8db71425f960c019cf7e7012a","IPY_MODEL_930d2cadb7af43bb91a50c01997aab5c"],"layout":"IPY_MODEL_1df18ce864584edebdcbe7edcb139731"}},"7771d1c9a9b746ee85a0e6495de9ea83":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39f724872f4a44418f1405137b0e6bde","placeholder":"​","style":"IPY_MODEL_37b66792b90b44abafa1a84f02fc7140","value":"Loading checkpoint shards: 100%"}},"faca98b8db71425f960c019cf7e7012a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d776933b8ba7455da5ab66446b4dbab1","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5c957e6fee8041abaabe862ec049f53b","value":2}},"930d2cadb7af43bb91a50c01997aab5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ac8423dfa44435ba723fde9de1e5046","placeholder":"​","style":"IPY_MODEL_69f58c7862cc42469852c00ef942b6d6","value":" 2/2 [00:00&lt;00:00, 55.62it/s]"}},"1df18ce864584edebdcbe7edcb139731":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39f724872f4a44418f1405137b0e6bde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37b66792b90b44abafa1a84f02fc7140":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d776933b8ba7455da5ab66446b4dbab1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c957e6fee8041abaabe862ec049f53b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5ac8423dfa44435ba723fde9de1e5046":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69f58c7862cc42469852c00ef942b6d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f33ac576dd3c4def92cd617f11b597cc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a6d5bdb101f64f9d88b3758765b204ab","IPY_MODEL_397155bc35084141a17e3df71892f4cb","IPY_MODEL_948f12b2d6ef4b018df550b440fe6f4a"],"layout":"IPY_MODEL_42cfbb9483f749fa944734448e5c6bb1"}},"a6d5bdb101f64f9d88b3758765b204ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6427672d6644533a5fe22c71096e5af","placeholder":"​","style":"IPY_MODEL_ceade91e0755487ca4b627176e22a138","value":"Map: 100%"}},"397155bc35084141a17e3df71892f4cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e694633855d49b68f04ab38a4f97f6a","max":378,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5aefae798aaf45c5a1106957737b79d0","value":378}},"948f12b2d6ef4b018df550b440fe6f4a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64f5724aa595462d9773ad7d5f37e02d","placeholder":"​","style":"IPY_MODEL_cb50f78b3d134758a1d6da947ceb6c92","value":" 378/378 [00:00&lt;00:00, 11771.34 examples/s]"}},"42cfbb9483f749fa944734448e5c6bb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6427672d6644533a5fe22c71096e5af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ceade91e0755487ca4b627176e22a138":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e694633855d49b68f04ab38a4f97f6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5aefae798aaf45c5a1106957737b79d0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"64f5724aa595462d9773ad7d5f37e02d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb50f78b3d134758a1d6da947ceb6c92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Step 1: Mounting Google Drive and Importing Libraries\n"],"metadata":{"id":"L637dg8aVl1t"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qzxre_ImVbHp","executionInfo":{"status":"ok","timestamp":1767487852040,"user_tz":360,"elapsed":22938,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"1e52008e-9b41-4607-a065-643664c66de0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/grpo-verified-reasoner\n","data\t\t\t      LICENSE\t outputs    unsloth_compiled_cache\n","grpo_trainer_lora_model       models\t README.md  _unsloth_sentencepiece_temp\n","huggingface_tokenizers_cache  notebooks  src\t    wandb\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","%cd /content/drive/MyDrive/grpo-verified-reasoner\n","!ls"]},{"cell_type":"code","source":["# Install UV (Faster pip)\n","!pip install --upgrade -qqq uv"],"metadata":{"id":"P3IoN0USiBmR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767487878396,"user_tz":360,"elapsed":3973,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"178346b7-0fb7-4e76-fcba-ec35de8ae255"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/22.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/22.2 MB\u001b[0m \u001b[31m225.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m18.3/22.2 MB\u001b[0m \u001b[31m321.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m344.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m152.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["!pip -q install -U evalplus"],"metadata":{"id":"y8iXM_15a_mn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767487884327,"user_tz":360,"elapsed":5903,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"5531216e-f5d8-40db-9bb7-0481bc0d49f5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.2/388.2 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m635.4/635.4 kB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.1/108.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for stop-sequencer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for tempdir (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["import os\n","import subprocess"],"metadata":{"id":"Oq8Azhmyiu6E","executionInfo":{"status":"ok","timestamp":1767487884337,"user_tz":360,"elapsed":2,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["\n","os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:False\""],"metadata":{"id":"lv-Ki6Vcrntd","executionInfo":{"status":"ok","timestamp":1767487884347,"user_tz":360,"elapsed":9,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["os.environ[\"UNSLOTH_VLLM_STANDBY\"] = \"1\""],"metadata":{"id":"NeqIAhUsd5Dg","executionInfo":{"status":"ok","timestamp":1767487884350,"user_tz":360,"elapsed":1,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["os.environ[\"WANDB_PROJECT\"] = \"mbpp-rl-project\""],"metadata":{"id":"kTXAQ4pB0NsE","executionInfo":{"status":"ok","timestamp":1767487884351,"user_tz":360,"elapsed":0,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Environment Logic (Colab vs Local)\n","if \"COLAB_\" not in \"\".join(os.environ.keys()):\n","    !pip install unsloth vllm\n","else:\n","    # Version Matching\n","    try: import numpy, PIL; get_numpy = f\"numpy=={numpy.__version__}\"; get_pil = f\"pillow=={PIL.__version__}\"\n","    except: get_numpy = \"numpy\"; get_pil = \"pillow\"\n","    try: is_t4 = \"Tesla T4\" in str(subprocess.check_output([\"nvidia-smi\"]))\n","    except: is_t4 = False\n","\n","    # A100 gets vllm 0.10.2 (Fast), T4 gets 0.9.2 (Stable)\n","    get_vllm, get_triton = (\"vllm==0.9.2\", \"triton==3.2.0\") if is_t4 else (\"vllm==0.10.2\", \"triton\")\n","\n","    # Install Everything\n","    !uv pip install -qqq --upgrade \\\n","        unsloth {get_vllm} {get_numpy} {get_pil} torchvision bitsandbytes xformers\n","    !uv pip install -qqq {get_triton}\n","\n","# Install TRL\n","!uv pip install transformers==4.56.2\n","!uv pip install --no-deps trl==0.22.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZuucNkH5imSg","executionInfo":{"status":"ok","timestamp":1767487917345,"user_tz":360,"elapsed":32993,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"83514305-08af-488b-eae6-d22075207fc6"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n","\u001b[2K\u001b[2mResolved \u001b[1m18 packages\u001b[0m \u001b[2min 19ms\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 449ms\u001b[0m\u001b[0m\n","\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 204ms\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 36ms\u001b[0m\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.57.3\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.56.2\u001b[0m\n","\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n","\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 22ms\u001b[0m\u001b[0m\n","\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mtrl\u001b[0m\u001b[2m==0.24.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtrl\u001b[0m\u001b[2m==0.22.2\u001b[0m\n"]}]},{"cell_type":"code","source":["import re\n","import ast\n","import torch\n","import wandb\n","import random\n","import evalplus\n","import traceback\n","import numpy as np\n","import multiprocessing as mp\n","from datasets import Dataset\n","from unsloth import FastLanguageModel\n","from evalplus.data import get_mbpp_plus\n","from trl import GRPOConfig, GRPOTrainer\n","from vllm import SamplingParams"],"metadata":{"id":"HPDizgKUc3Fx","executionInfo":{"status":"ok","timestamp":1767487984561,"user_tz":360,"elapsed":67204,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7e672c99-8b06-46f6-c6fc-1c326b41a8ce"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","INFO 01-04 00:52:22 [__init__.py:216] Automatically detected platform cuda.\n","🦥 Unsloth Zoo will now patch everything to make training faster!\n"]}]},{"cell_type":"code","source":["wandb.login()"],"metadata":{"id":"wiKxGqbQx_r6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767488009474,"user_tz":360,"elapsed":24894,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"6d4cc6cd-162e-4f58-e7ab-5335adc2a3ff"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["wandb: (1) Create a W&B account\n","wandb: (2) Use an existing W&B account\n","wandb: (3) Don't visualize my results\n","wandb: Enter your choice:"]},{"name":"stdout","output_type":"stream","text":[" 2\n"]},{"output_type":"stream","name":"stderr","text":["wandb: You chose 'Use an existing W&B account'\n","wandb: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","wandb: Find your API key here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["wandb: No netrc file found, creating one.\n","wandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","wandb: Currently logged in as: samyakshrestha (samyakshrestha-university-of-texas-at-dallas) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["# Step 2: Verifying GPU and Environment"],"metadata":{"id":"0bFALRzXVpfD"}},{"cell_type":"code","source":["print(\"Torch version:\", torch.__version__)\n","print(\"CUDA available:\", torch.cuda.is_available())\n","if torch.cuda.is_available():\n","    print(\"GPU:\", torch.cuda.get_device_name(0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j6gsvZOiavZf","executionInfo":{"status":"ok","timestamp":1767488014437,"user_tz":360,"elapsed":6,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"99f76f2c-7d7e-4bd1-a0a5-36bc1f7cfe36"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Torch version: 2.8.0+cu128\n","CUDA available: True\n","GPU: NVIDIA H100 80GB HBM3\n"]}]},{"cell_type":"markdown","source":["# Step 3: Loading Base Model and LoRA Adapters"],"metadata":{"id":"l-PeyUR5dE0m"}},{"cell_type":"code","source":["MODEL_PATH = \"models/qwen3-4b-sft\""],"metadata":{"id":"OGf88PMBdN3B","executionInfo":{"status":"ok","timestamp":1767488040563,"user_tz":360,"elapsed":21,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Load the model\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = MODEL_PATH,\n","    max_seq_length = 3072,      # Aligned with GRPO + schema\n","    load_in_4bit = False,       # Full precision for RL stability\n","    fast_inference = True,      # Required for vLLM\n","    gpu_memory_utilization = 0.8,\n",")"],"metadata":{"id":"PLoe3PBmsHXz","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["513c4c2ec3f94a19a436dff1eb3fe422","df9ee308bb2241af9f55d849129cd105","a69cb63a96a94a699d300d69f483502b","0bb164c01fd848e29118e7afc04f5c55","c2079be8f1264e06aad38e9b562ddcee","796481a77e4340cbb8b84e74d424be84","949360157cf04842a75e0dd43b8be549","f5a49b52fee542f4b263fa2f49344bd7","b73d4a0a60ee4af68a8f72ca07ac28f5","1ab21dd075814d63a5b7c7dd4642a0a4","5840980400074fe3b40778ed5dab74d6","18de49f9543746ee9307c53a18b35a5a","5821684f0a564b14b0b9b473762761b6","fc3131dec2cf41aa91672b04a6d98d3c","4c6e017fdefa44488ff94140c34e209c","77818c8fddfb44928add2b83657de9cd","9f2f038ca40e46fdb0d3a3528a84e91a","acb0d1f6a4434601a02b4812368839b1","1ea1c1f92b824fd2912f5ef2350a5d63","3ddc7559bc2e411881f7270feba2731e","6d2a107ea83149a88a7c32a8cbbb7f0d","c0750ce542894de8ac27dec895776e70","6adac0dd0e1447088fa785de9f92c1e9","57bcf5d4796248c29bdabc3764813edc","4ce1a84ecebf449c873833c9aa506cec","b3916854d6ae4901815b94b9f804c0d0","2d09e4cf76cd4ee6b8885b589b25fd02","832a2dde74684dea96babc8e1e91b305","cb2f9d108a1c412f9f846d626e1897c6","0eff82ba33064ae1b818d1461ecc4135","56303c6d739c428eb41cd3061caa57a1","caf156afe6da4ec387443f261ff44c0a","97b97eeab7b5454aadb7d8fa2a12415b","9a730d7a10434a1d899b717a9e4fec34","114e298abba14a08bed94bae22b01c88","6b4d6091b61a40e3908f61dba7ae9fd0","ec2a97c74646463a88565a2ab1790fb1","6e586971befd43e6beaf3df04e3af27d","5ef86455586e42be8e1ff5501c13970e","5f6c9d41aff447e4b58c8079ac16fb37","d0582a63b9bc4485aea3f7b49ac58f8c","2947fb858f9b4b679b8b2606afee0f38","1a36c77f08374217a6032d8c925d9ca6","8658c5288f06403982e0159df01e7945","9055795800174ef594e1a1afdbfa018f","1a3b34330aa648cbb27325a5570b94b9","5d9b8a3187e540499f9b81b22db234e4","e56735f4077c42289a8e29052a87ddf5","f81ed31125a6453b86e066bb70a85f8a","d3e462ec1dad40a7b2abee14f62cf890","26d330570f4c4e07b4c6dfe60059b899","35b99d8cce9d49bf86e0587f632d5612","30b8ba87a79846fba6d8fef587c69a06","ca84a885ff1f4e2e89a3a6bea1c45a82","4819e7eab4154798b10ba1f3fe1bf551","09c976b9866745f4ad70efe287a0acaa","58ed99f43bb44b678e0744bd2ffae177","a16f261ba20a4e34a85e4b8ab36cb7f9","de5b2a0ee5364fdfadeb82afc925bb79","033a76c871234d678f787ef0e9591743","661cde23f99e4ed09210cdb613cdeb0d","74eb90a089fa47b692cd6bb3d074561d","44e7dbf9eaca41a2b51b2783af42bf68","8718eacc54914290890a67fc70ac642c","cd917a0d54ae44b0b08f37c32974bc82","b11dbbdc941f445ebfd2e009520ec36b","471ac1ab25b544d8bcfbf26a5cb41f8e","af17f312324e433fb9942f7ee33e4704","ebfef543895646888a48e13c5f0bfba1","8d468cbb7f264939a258ff11543ad5b2","ae23858125fe4127a9a24b02ac4c0dbf","e0424fb9bc91421399ed480ce26909e6","632f8d5b8c104d9db873238f4e9c5aaf","02d8db5f5cd148beab999350d62f9124","c190f2f439214d4b97547c4b9667b3ad","f7b371cb88904c46a555c02867cb7b14","dbdcce96269042ef83aed0903d88cb3b","4791451fc8bb432b8804adbad03e8e4f","3418e39ec02440c1b2d328f6dacb485c","eb42950100034f6fba659ef80d191094","c382ecafe15d4011a93bbefcb081659b","d5c2741f5f9f46d9ba263a2de5412393","25123eef76074c089df2ea9e9d1457c9","ab991ae40d804b14886ad743169a8ff0","73388478a507489d8e02abb83c729418","2e8107aa010c4dee95cd0a7c424cebf6","8a067186ab744c31be0a5f6e2b5397fd","3a1e6d158c7f49e6b978a69fa518582c","bfc46c3db0ce4bc6b8fc194206ad464f","c1ba0a1a4be64a8bbca58dea00f31af4","b392b73be7ad484aa619da51484a5d9b","aa65374a579c4102bdf03d292fcbae4a","514ba9a4e57e429795b71be907e51a61","571b8b92c888415cae1517f38bd0b40b","b4e61da8730f4943b5db58eb6e0169ad","c3afb435a85b424bbc89535da48210da","ba6356a458dc43dfb92a3fcb67deb220","186712db0c9140d99054e17974be14aa","1f1cbc291a394e18bb9deadf04d69867","ac4fa7e68b424bc48e5684f7405a5b20","8189fc99e3234d738858895809c24348","20bee10ff6c44ad5b9749e008801bb9c","984c562a20fe40f88609736883c4bba6","3421fbf3111c46a7bac7b770b6a76d9b","df95a990c11c4f62acd2c9cf0c95e1fa","890acd7060b64b8dbbcfa66fead1b29c","a5a2c802343447a5bbde6862fd327d36","77dfe5ced6184e5abb549b4a52f9e31b","aa59be05c5a7404d93a555b77354463f","72d555c69d2c484f832dbb717bc60724","69da48d0d9f74755b2b9b5afe321bd14","b52ef7d9993f4da6ba5b8751bc155f7a","f4f85aab6e0b42a389ed411473466dc5","9dd9e90f8004462b9498ce8935000891","498694a004a2458d82fe9e4c2ab99838","4a58f6391cec48ac99a03e5dfc4e319a","f0a2388ebeaf49ee98f8f1890533fd1d","eb4ceb463e93449ba84b2141024419e6","c2f7c5bb53be49dfb397d0681cafc60e","7f9105ef1ecc42e199c2a050f9cf80c5","dc8049de557c4a1480e46368614618e5","122187d0ded7461f9d1f3c510e8f446b","7771d1c9a9b746ee85a0e6495de9ea83","faca98b8db71425f960c019cf7e7012a","930d2cadb7af43bb91a50c01997aab5c","1df18ce864584edebdcbe7edcb139731","39f724872f4a44418f1405137b0e6bde","37b66792b90b44abafa1a84f02fc7140","d776933b8ba7455da5ab66446b4dbab1","5c957e6fee8041abaabe862ec049f53b","5ac8423dfa44435ba723fde9de1e5046","69f58c7862cc42469852c00ef942b6d6"]},"executionInfo":{"status":"ok","timestamp":1767488223173,"user_tz":360,"elapsed":169350,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"f58a1094-7d9f-46a7-9435-ede04f961b28"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO 01-04 00:54:16 [vllm_utils.py:702] Unsloth: Patching vLLM v1 graph capture\n","INFO 01-04 00:54:16 [vllm_utils.py:732] Unsloth: Patching vLLM v0 graph capture\n","==((====))==  Unsloth 2025.12.10: Fast Qwen3 patching. Transformers: 4.56.2. vLLM: 0.10.2.\n","   \\\\   /|    NVIDIA H100 80GB HBM3. Num GPUs = 1. Max memory: 79.32 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 9.0. CUDA Toolkit: 12.8. Triton: 3.4.0\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post1. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","Unsloth: Standby mode is enabled. Changing `gpu_memory_utilization` to 0.925.\n","Unsloth: vLLM loading unsloth/Qwen3-4B-Base with actual GPU utilization = 91.8%\n","Unsloth: Your GPU has CUDA compute capability 9.0 with VRAM = 79.32 GB.\n","Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 3072. Num Sequences = 128.\n","Unsloth: vLLM's KV Cache can use up to 65.75 GB. Also swap space = 6 GB.\n","Unsloth: Not an error, but `device` is not supported in vLLM. Skipping.\n","INFO 01-04 00:54:26 [utils.py:328] non-default args: {'dtype': torch.bfloat16, 'seed': 0, 'max_model_len': 3072, 'enable_prefix_caching': True, 'swap_space': 6, 'gpu_memory_utilization': 0.9180168293092066, 'max_num_batched_tokens': 8192, 'max_num_seqs': 128, 'max_logprobs': 0, 'disable_log_stats': True, 'enable_lora': True, 'max_lora_rank': 64, 'enable_chunked_prefill': True, 'compilation_config': {\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"inductor\",\"custom_ops\":[],\"splitting_ops\":null,\"use_inductor\":true,\"compile_sizes\":null,\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":false,\"trace.graph_diagram\":false,\"compile_threads\":26,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":false,\"triton.cooperative_reductions\":false,\"cuda.compile_opt_level\":\"-O2\",\"cuda.enable_cuda_lto\":true,\"combo_kernels\":false,\"benchmark_combo_kernel\":true,\"combo_kernel_foreach_dynamic_shapes\":true,\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":[2,1],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":null,\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"pass_config\":{},\"max_capture_size\":null,\"local_cache_dir\":null}, 'enable_sleep_mode': True, 'model': 'unsloth/Qwen3-4B-Base'}\n","INFO 01-04 00:54:38 [__init__.py:742] Resolved architecture: Qwen3ForCausalLM\n"]},{"output_type":"stream","name":"stderr","text":["`torch_dtype` is deprecated! Use `dtype` instead!\n"]},{"output_type":"stream","name":"stdout","text":["INFO 01-04 00:54:38 [__init__.py:1815] Using max model len 3072\n","INFO 01-04 00:54:39 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=8192.\n","WARNING 01-04 00:54:39 [lora.py:92] `lora_extra_vocab_size` is deprecated and will be removed in v0.12.0. Additional vocabulary support for LoRA adapters is being phased out.\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"513c4c2ec3f94a19a436dff1eb3fe422"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18de49f9543746ee9307c53a18b35a5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6adac0dd0e1447088fa785de9f92c1e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a730d7a10434a1d899b717a9e4fec34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["added_tokens.json:   0%|          | 0.00/707 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9055795800174ef594e1a1afdbfa018f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/617 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09c976b9866745f4ad70efe287a0acaa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/166 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"471ac1ab25b544d8bcfbf26a5cb41f8e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["INFO 01-04 00:54:45 [core.py:76] Initializing a V1 LLM engine (v0.10.2) with config: model='unsloth/Qwen3-4B-Base', speculative_config=None, tokenizer='unsloth/Qwen3-4B-Base', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=3072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=unsloth/Qwen3-4B-Base, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"inductor\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\",\"vllm.mamba_mixer\",\"vllm.short_conv\",\"vllm.linear_attention\",\"vllm.plamo2_mamba_mixer\",\"vllm.gdn_attention\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":false,\"trace.graph_diagram\":false,\"compile_threads\":26,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":false,\"triton.cooperative_reductions\":false,\"cuda.compile_opt_level\":\"-O2\",\"cuda.enable_cuda_lto\":true,\"combo_kernels\":false,\"benchmark_combo_kernel\":true,\"combo_kernel_foreach_dynamic_shapes\":true,\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":[2,1],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"pass_config\":{},\"max_capture_size\":256,\"local_cache_dir\":null}\n","INFO 01-04 00:54:46 [parallel_state.py:1165] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n","WARNING 01-04 00:54:46 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n","INFO 01-04 00:54:46 [gpu_model_runner.py:2338] Starting to load model unsloth/Qwen3-4B-Base...\n","INFO 01-04 00:54:46 [gpu_model_runner.py:2370] Loading model from scratch...\n","INFO 01-04 00:54:46 [cuda.py:362] Using Flash Attention backend on V1 engine.\n","INFO 01-04 00:54:47 [weight_utils.py:348] Using model weights format ['*.safetensors']\n"]},{"output_type":"display_data","data":{"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/3.08G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4791451fc8bb432b8804adbad03e8e4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfc46c3db0ce4bc6b8fc194206ad464f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["INFO 01-04 00:55:01 [weight_utils.py:369] Time spent downloading weights for unsloth/Qwen3-4B-Base: 13.993902 seconds\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors.index.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac4fa7e68b424bc48e5684f7405a5b20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69da48d0d9f74755b2b9b5afe321bd14"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["INFO 01-04 00:55:03 [default_loader.py:268] Loading weights took 1.45 seconds\n","INFO 01-04 00:55:03 [punica_selector.py:19] Using PunicaWrapperGPU.\n","INFO 01-04 00:55:04 [gpu_model_runner.py:2392] Model loading took 7.8053 GiB and 16.709786 seconds\n","INFO 01-04 00:55:13 [backends.py:539] Using cache directory: /root/.cache/vllm/torch_compile_cache/2c202bdbec/rank_0_0/backbone for vLLM's torch.compile\n","INFO 01-04 00:55:13 [backends.py:550] Dynamo bytecode transform time: 8.51 s\n"]},{"output_type":"stream","name":"stderr","text":["Unsloth: Compiling kernels: 100%|██████████| 7/7 [00:00<00:00, 15.08it/s, triton_poi_fused_view_6]\n"]},{"output_type":"stream","name":"stdout","text":["INFO 01-04 00:55:17 [backends.py:194] Cache the graph for dynamic shape for later use\n"]},{"output_type":"stream","name":"stderr","text":["Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 23.98it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 783.32it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 760.20it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 783.14it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 797.93it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 707.11it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 706.38it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 748.95it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 712.69it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 676.28it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 761.33it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 624.81it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 730.28it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 711.93it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 693.88it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 693.55it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 747.76it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 651.75it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 633.43it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 707.43it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 749.77it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 581.60it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 619.27it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 621.84it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 623.73it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 752.11it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 783.42it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 720.20it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 791.22it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 765.00it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 765.17it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 774.13it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 766.06it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 743.11it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 11/11 [00:00<00:00, 738.60it/s, triton_poi_fused_view_10]\n","Unsloth: Compiling kernels: 100%|██████████| 5/5 [00:00<00:00, 24.25it/s, triton_red_fused__to_copy_add_mean_mul_pow_rsqrt_4]\n"]},{"output_type":"stream","name":"stdout","text":["INFO 01-04 00:55:47 [backends.py:215] Compiling a graph for dynamic shape takes 33.19 s\n","INFO 01-04 00:56:02 [monitor.py:34] torch.compile takes 41.69 s in total\n","INFO 01-04 00:56:04 [gpu_worker.py:298] Available KV cache memory: 64.18 GiB\n","INFO 01-04 00:56:05 [kv_cache_utils.py:864] GPU KV cache size: 467,328 tokens\n","INFO 01-04 00:56:05 [kv_cache_utils.py:868] Maximum concurrency for 3,072 tokens per request: 152.12x\n","INFO 01-04 00:56:05 [vllm_utils.py:707] Unsloth: Running patched vLLM v1 `capture_model`.\n"]},{"output_type":"stream","name":"stderr","text":["Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:10<00:00,  3.41it/s]\n","Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:01<00:00, 10.81it/s]"]},{"output_type":"stream","name":"stdout","text":["INFO 01-04 00:56:17 [gpu_model_runner.py:3118] Graph capturing finished in 12 secs, took 0.78 GiB\n","INFO 01-04 00:56:17 [vllm_utils.py:714] Unsloth: Patched vLLM v1 graph capture finished in 12 secs.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["INFO 01-04 00:56:18 [gpu_worker.py:391] Free memory on device (78.64/79.32 GiB) on startup. Desired GPU memory utilization is (0.9180168293092066, 72.82 GiB). Actual usage is 7.81 GiB for weight, 0.76 GiB for peak activation, 0.07 GiB for non-torch memory, and 0.78 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=67914022297` to fit into requested memory, or `--kv-cache-memory=74161210368` to fully utilize gpu memory. Current kv cache memory in use is 68912266649 bytes.\n","INFO 01-04 00:56:18 [core.py:218] init engine (profile, create kv cache, warmup model) took 74.36 seconds\n","INFO 01-04 00:56:19 [llm.py:295] Supported_tasks: ('generate',)\n","INFO 01-04 00:56:19 [__init__.py:36] No IOProcessor plugins requested by the model\n","Unsloth: Standby mode is enabled. Pre-sleeping vLLM model to reduce OOMs.\n","Unsloth: Just some info: will skip parsing ['post_feedforward_layernorm', 'attention_norm', 'q_norm', 'layer_norm1', 'post_layernorm', 'norm', 'input_layernorm', 'norm2', 'ffn_norm', 'layer_norm2', 'post_attention_layernorm', 'k_norm', 'norm1', 'pre_feedforward_layernorm']\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"122187d0ded7461f9d1f3c510e8f446b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of Qwen3ForCausalLM were not initialized from the model checkpoint at unsloth/Qwen3-4B-Base and are newly initialized: ['lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Performing substitution for additional_keys=set()\n","Unsloth: Just some info: will skip parsing ['post_feedforward_layernorm', 'attention_norm', 'q_norm', 'layer_norm1', 'post_layernorm', 'norm', 'input_layernorm', 'norm2', 'ffn_norm', 'layer_norm2', 'post_attention_layernorm', 'k_norm', 'cross_attn_post_attention_layernorm', 'norm1', 'cross_attn_input_layernorm', 'pre_feedforward_layernorm']\n"]},{"output_type":"stream","name":"stderr","text":["Unsloth 2025.12.10 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"]}]},{"cell_type":"code","source":["trainable = 0\n","total = 0\n","trainable_names = []\n","for name, p in model.named_parameters():\n","    n = p.numel()\n","    total += n\n","    if p.requires_grad:\n","        trainable += n\n","        trainable_names.append(name)\n","\n","print(f\"Trainable params: {trainable:,} / {total:,} = {100*trainable/total:.4f}%\")\n","print(\"Example trainable params:\", trainable_names[:20])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o4dnSm0bIHz5","executionInfo":{"status":"ok","timestamp":1767488239654,"user_tz":360,"elapsed":16,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"0669423c-01eb-4f2c-9b98-8bc1e92c00ab"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Trainable params: 66,060,288 / 4,088,528,384 = 1.6157%\n","Example trainable params: ['base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight']\n"]}]},{"cell_type":"code","source":["print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3wgYFoDcv283","executionInfo":{"status":"ok","timestamp":1767488240390,"user_tz":360,"elapsed":15,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"888437b9-ac37-4a04-b154-17117cf40968"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): Qwen3ForCausalLM(\n","      (model): Qwen3Model(\n","        (embed_tokens): Embedding(151936, 2560, padding_idx=151654)\n","        (layers): ModuleList(\n","          (0-35): 36 x Qwen3DecoderLayer(\n","            (self_attn): Qwen3Attention(\n","              (q_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear(\n","                (base_layer): Linear(in_features=4096, out_features=2560, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): Qwen3MLP(\n","              (gate_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9728, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9728, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear(\n","                (base_layer): Linear(in_features=9728, out_features=2560, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=9728, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","          )\n","        )\n","        (norm): Qwen3RMSNorm((2560,), eps=1e-06)\n","        (rotary_emb): LlamaRotaryEmbedding()\n","      )\n","      (lm_head): Linear(in_features=2560, out_features=151936, bias=False)\n","    )\n","  )\n",")\n"]}]},{"cell_type":"markdown","source":["# Step 4: Sanity Check"],"metadata":{"id":"8AtswtDWt3T4"}},{"cell_type":"code","source":["# This is the same prompt that we used during SFT\n","system_prompt = \"\"\"You are a code-generation engine.\n","You must output your response in the following exact format:\n","<START_WORKING_OUT>\n","Concise reasoning steps required to solve the problem.\n","</END_WORKING_OUT>\n","<SOLUTION>\n","Valid Python code only.\n","</SOLUTION>\n","Do not output anything outside these tags.\"\"\""],"metadata":{"id":"pt0hmcEetnJ7","executionInfo":{"status":"ok","timestamp":1767488241235,"user_tz":360,"elapsed":2,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["user_prompt = \"Write a Python function that returns the factorial of a number.\"\n","\n","messages = [\n","    {\"role\": \"system\", \"content\": system_prompt},\n","    {\"role\": \"user\", \"content\": user_prompt},\n","]\n","inputs = tokenizer.apply_chat_template(\n","    messages,\n","    tokenize=True,\n","    add_generation_prompt=True,\n","    return_tensors=\"pt\",\n","    return_dict=True,\n",")"],"metadata":{"id":"FnsS5mubtnGM","executionInfo":{"status":"ok","timestamp":1767488241454,"user_tz":360,"elapsed":2,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Move the dictionary to GPU manually\n","inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}"],"metadata":{"id":"9buanb82vgtZ","executionInfo":{"status":"ok","timestamp":1767488241744,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["FastLanguageModel.for_inference(model) # Temporarily enable inference mode for the test\n","with torch.no_grad():\n","    output = model.generate(\n","        **inputs,\n","        max_new_tokens=256,\n","        temperature=0.0, # Deterministic check\n","    )"],"metadata":{"id":"m1gvTQsdtnEa","executionInfo":{"status":"ok","timestamp":1767488247094,"user_tz":360,"elapsed":5100,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["decoded = tokenizer.decode(output[0], skip_special_tokens=True)"],"metadata":{"id":"xglp4DortnCS","executionInfo":{"status":"ok","timestamp":1767488247116,"user_tz":360,"elapsed":5,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["print(\"\\n--- MODEL OUTPUT ---\")\n","input_len = inputs[\"input_ids\"].shape[1]\n","print(tokenizer.decode(output[0][input_len:], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zxb_myK-tnAO","executionInfo":{"status":"ok","timestamp":1767488247157,"user_tz":360,"elapsed":37,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"06abcaa0-5d23-4e76-fc99-292dc3c973dc"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- MODEL OUTPUT ---\n","<START_WORKING_OUT>\n","Define a function factorial(n) that calculates the product of all positive integers up to n.\n","Handle non-positive integers by returning 1 (factorial of 0 and negative is 1).\n","Implement iterative approach for efficiency.\n","Return the computed factorial.\n","</END_WORKING_OUT>\n","<SOLUTION>\n","def factorial(n):\n","    if n <= 0:\n","        return 1\n","    result = 1\n","    for i in range(2, n + 1):\n","        result *= i\n","    return result\n","</SOLUTION>\n"]}]},{"cell_type":"markdown","source":["Comment:  No schema check, extractor, or reward function ever sees the full decoded sequence. They only ever see generated_text."],"metadata":{"id":"Z8MkD65mYBx5"}},{"cell_type":"markdown","source":["# Step 6: Defining Output Schema"],"metadata":{"id":"z_hw6md1LSm3"}},{"cell_type":"code","source":["# Regular expressions for tag validation (case-insensitive)\n","RE_START = re.compile(r\"<START_WORKING_OUT>\", re.IGNORECASE)\n","RE_END   = re.compile(r\"</END_WORKING_OUT>\", re.IGNORECASE)\n","RE_SOL   = re.compile(r\"<SOLUTION>\", re.IGNORECASE)\n","RE_SOL_END = re.compile(r\"</SOLUTION>\", re.IGNORECASE)"],"metadata":{"id":"O3zR1mkFtm-N","executionInfo":{"status":"ok","timestamp":1767488296035,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def validate_schema(text: str) -> tuple[bool, str]:\n","    \"\"\"\n","    Checks whether the model output follows the exact required schema.\n","    Returns (is_valid, reason).\n","    \"\"\"\n","    if not RE_START.search(text):\n","        return False, \"Missing <START_WORKING_OUT>\"\n","    if not RE_END.search(text):\n","        return False, \"Missing </END_WORKING_OUT>\"\n","    if not RE_SOL.search(text):\n","        return False, \"Missing <SOLUTION>\"\n","    if not RE_SOL_END.search(text):\n","        return False, \"Missing </SOLUTION>\"\n","\n","    # Optional: check order consistency\n","    start_idx = RE_START.search(text).start()\n","    sol_idx   = RE_SOL.search(text).start()\n","    if sol_idx < start_idx:\n","        return False, \"Tag order incorrect (<SOLUTION> before reasoning block).\"\n","\n","    return True, \"Schema valid\""],"metadata":{"id":"5oxttpUDtm0G","executionInfo":{"status":"ok","timestamp":1767488296542,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# Run a sanity test using the previous decoded output\n","is_valid, reason = validate_schema(decoded)\n","print(\"Schema Check:\", is_valid, \"|\", reason)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YA_UNFQgLrF0","executionInfo":{"status":"ok","timestamp":1767488296932,"user_tz":360,"elapsed":5,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"67a25d3c-ee7e-479a-c082-aaa6a4d68e93"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Schema Check: True | Schema valid\n"]}]},{"cell_type":"markdown","source":["# Step 7: Solution Extraction"],"metadata":{"id":"_EN-nTksMUff"}},{"cell_type":"code","source":["# Regex to extract the code block between <SOLUTION> ... </SOLUTION>\n","RE_SOLUTION = re.compile(r\"<SOLUTION>\\s*(.*?)\\s*</SOLUTION>\", re.IGNORECASE | re.DOTALL)"],"metadata":{"id":"Iv-5aUVNL3aC","executionInfo":{"status":"ok","timestamp":1767488299221,"user_tz":360,"elapsed":1,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def extract_solution(text: str) -> tuple[str | None, str]:\n","    \"\"\"\n","    Extracts the Python code inside <SOLUTION> tags.\n","    Returns (code, status) where:\n","        code   -> the extracted string or None if failed\n","        status -> textual reason (for debugging)\n","    \"\"\"\n","    match = RE_SOLUTION.search(text)\n","    if not match:\n","        return None, \"No <SOLUTION> block found.\"\n","\n","    code = match.group(1).strip()\n","    if not code:\n","        return None, \"Empty <SOLUTION> block.\"\n","\n","    # Syntax check via Python's AST parser\n","    try:\n","        ast.parse(code)\n","    except SyntaxError as e:\n","        return None, f\"Syntax error in code: {e}\"\n","\n","    return code, \"Valid Python code extracted.\""],"metadata":{"id":"nlcNKSrIMjBy","executionInfo":{"status":"ok","timestamp":1767488300139,"user_tz":360,"elapsed":1,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["# Calculate where the prompt ends\n","input_len = inputs[\"input_ids\"].shape[1]"],"metadata":{"id":"hgaK_ceNV4Le","executionInfo":{"status":"ok","timestamp":1767488300824,"user_tz":360,"elapsed":2,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# Decode ONLY the new tokens (The Assistant's reply)\n","generated_text = tokenizer.decode(output[0][input_len:], skip_special_tokens=True)"],"metadata":{"id":"8hwepazlV-Ho","executionInfo":{"status":"ok","timestamp":1767488301047,"user_tz":360,"elapsed":4,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# Now run the check on ONLY the generated text\n","code, status = extract_solution(generated_text) # Use the new variable\n","print(\"Status:\", status)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CKKZsiDRMnKy","executionInfo":{"status":"ok","timestamp":1767488301244,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"4e7c0847-5acf-4398-dd59-c57a1bea56a8"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Status: Valid Python code extracted.\n"]}]},{"cell_type":"code","source":["\n","# Show snippet of the extracted code\n","if code:\n","    print(\"\\n--- Extracted Python Code ---\\n\")\n","    print(code)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G8DcMGzTMtQ0","executionInfo":{"status":"ok","timestamp":1767488302171,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"670307a1-e571-4d72-8ba7-ab9e2f43aacb"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Extracted Python Code ---\n","\n","def factorial(n):\n","    if n <= 0:\n","        return 1\n","    result = 1\n","    for i in range(2, n + 1):\n","        result *= i\n","    return result\n"]}]},{"cell_type":"markdown","source":["# Step 8: Verifier Integration (EvalPlus MBPP+)"],"metadata":{"id":"-1urFQMgaulu"}},{"cell_type":"code","source":["# Load MBPP+ tasks as a dict: {task_id: problem_dict}\n","MBPP_TASKS = get_mbpp_plus()\n","\n","print(f\"Loaded MBPP+ tasks: {len(MBPP_TASKS)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dYJ4b4wiN-PR","executionInfo":{"status":"ok","timestamp":1767488317052,"user_tz":360,"elapsed":749,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"b907cc86-bc5b-4514-ee26-abe8639da6db"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading dataset from https://github.com/evalplus/mbppplus_release/releases/download/v0.2.0/MbppPlus.jsonl.gz\n","Loaded MBPP+ tasks: 378\n"]}]},{"cell_type":"code","source":["# Quick peek at one task to confirm fields & shape\n","sample_task_id = next(iter(MBPP_TASKS.keys()))\n","sample_task = MBPP_TASKS[sample_task_id]\n","\n","print(\"\\nSample Task ID:\", sample_task_id)\n","print(\"Keys:\", list(sample_task.keys()))\n","print(\"\\nPrompt (first 400 chars):\\n\", sample_task[\"prompt\"][:400])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A3fpg80PbTlc","executionInfo":{"status":"ok","timestamp":1767488317057,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"988e1abf-f75e-4032-c666-0ed8b35d82bf"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Sample Task ID: Mbpp/2\n","Keys: ['task_id', 'prompt', 'entry_point', 'canonical_solution', 'base_input', 'atol', 'plus_input', 'contract', 'assertion']\n","\n","Prompt (first 400 chars):\n"," \"\"\"\n","Write a function to find the shared elements from the given two lists.\n","assert set(similar_elements((3, 4, 5, 6),(5, 7, 4, 10))) == set((4, 5))\n","\"\"\"\n","\n"]}]},{"cell_type":"code","source":["# Different EvalPlus versions may store tests under slightly different keys,\n","# so we normalize via a helper (used later in reward function).\n","def get_tests_from_task(task: dict) -> list[str]:\n","    \"\"\"\n","    Extracts MBPP test assertions from a task.\n","    Supports both list-based and string-based formats.\n","    \"\"\"\n","    # Case 1: already a list of assertions\n","    for k in (\"test_list\", \"tests\", \"plus_tests\", \"base_tests\"):\n","        if k in task and task[k]:\n","            return list(task[k])\n","\n","    # Case 2: single multiline assertion string (MBPP+ common case)\n","    if \"assertion\" in task and task[\"assertion\"]:\n","        lines = task[\"assertion\"].strip().splitlines()\n","        return [line for line in lines if line.strip()]\n","\n","    raise KeyError(f\"No tests found in task keys: {list(task.keys())}\")"],"metadata":{"id":"RZsHYa9wbdUH","executionInfo":{"status":"ok","timestamp":1767488317962,"user_tz":360,"elapsed":1,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["# Step 9: Defining Helper Functions"],"metadata":{"id":"O6wcAKaBfVwn"}},{"cell_type":"code","source":["def _exec_code_and_tests_worker(code: str, tests: list[str], queue: mp.Queue) -> None:\n","    \"\"\"\n","    Runs model code + tests.\n","    CRITICAL FEATURES:\n","    1. Runs ALL tests (Partial Credit).\n","    2. Catches ALL exceptions (Robustness).\n","    3. Truncates error logs (IPC Safety).\n","    \"\"\"\n","    try:\n","        # Create the \"Main Desk\" (Environment)\n","        env = {\"__builtins__\": __builtins__}\n","\n","        # Run the User's Code into 'env'\n","        exec(code, env, env)\n","\n","        passed_count = 0\n","        total_tests = len(tests)\n","        first_error = None\n","\n","        # Run ALL Test Cases\n","        for t in tests:\n","            try:\n","                exec(t, env, env)\n","                passed_count += 1\n","            except Exception:\n","                # Capture only the FIRST error to save bandwidth\n","                if first_error is None:\n","                    # Get the full traceback\n","                    tb = traceback.format_exc()\n","                    # SOPHIA'S FIX: Truncate to 500 chars to prevent IPC deadlock\n","                    first_error = tb[:500] + \"\\n...[TRUNCATED]...\" if len(tb) > 500 else tb\n","                # Continue to the next test!\n","                continue\n","\n","        # Mission Complete: Return the score\n","        queue.put((passed_count, total_tests, first_error))\n","\n","    except Exception:\n","        # Catch syntax errors or crashes in the main code body\n","        tb = traceback.format_exc()\n","        truncated_error = tb[:500] + \"\\n...[TRUNCATED]...\" if len(tb) > 500 else tb\n","        queue.put((0, len(tests), truncated_error))"],"metadata":{"id":"ugV0PZjq6WS0","executionInfo":{"status":"ok","timestamp":1767488322833,"user_tz":360,"elapsed":2,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["def run_mbpp_tests(code: str, task: dict, timeout_s: float = 2.0) -> tuple[int, int, str | None]:\n","    \"\"\"\n","    Executes tests and returns (passed_count, total_count, first_error).\n","    \"\"\"\n","    tests = get_tests_from_task(task)\n","    if not tests:\n","        return 0, 0, \"No tests found.\"\n","\n","    ctx = mp.get_context(\"fork\")\n","    q = ctx.Queue()\n","    p = ctx.Process(target=_exec_code_and_tests_worker, args=(code, tests, q))\n","    p.start()\n","    p.join(timeout_s)\n","\n","    if p.is_alive():\n","        p.terminate()\n","        p.join()\n","        return 0, len(tests), f\"Timeout after {timeout_s:.1f}s\"\n","\n","    if q.empty():\n","        return 0, len(tests), \"No result returned from worker.\"\n","\n","    passed_count, total_count, err = q.get()\n","    return passed_count, total_count, err"],"metadata":{"id":"7qvlGFIjfpRV","executionInfo":{"status":"ok","timestamp":1767488323173,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":["# Step 10: Defining Reward Functions"],"metadata":{"id":"nlE3bAZ3LjwO"}},{"cell_type":"code","source":["def format_reward_func(completions, **kwargs) -> list[float]:\n","    \"\"\"\n","    Rewards the model for strictly following the XML schema.\n","    Args:\n","        completions: List of generated strings from the model.\n","    Returns:\n","        List of rewards (0.1 for valid schema, 0.0 for invalid).\n","    \"\"\"\n","    rewards = []\n","    for completion in completions:\n","        # Uses your existing validator from Step 6\n","        is_valid, _ = validate_schema(completion)\n","        rewards.append(0.1 if is_valid else 0.0)\n","    return rewards"],"metadata":{"id":"q5SEd65CLneK","executionInfo":{"status":"ok","timestamp":1767488324212,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["def reasoning_reward_func(completions, **kwargs) -> list[float]:\n","    \"\"\"\n","    Rewards the model for reasoning, but PENALIZES rambling.\n","\n","    Structure:\n","    - Base Reward: Up to +0.15 for writing ~500 chars of thought.\n","    - Penalty 1: -0.05 if length > 700 chars.\n","    - Penalty 2: Additional -0.05 (Total -0.10) if length > 1000 chars.\n","    \"\"\"\n","    rewards = []\n","    for completion in completions:\n","        # Regex to find the reasoning block specifically\n","        match = re.search(r\"<START_WORKING_OUT>(.*?)</END_WORKING_OUT>\", completion, re.DOTALL | re.IGNORECASE)\n","\n","        if match:\n","            reasoning_content = match.group(1).strip()\n","            length = len(reasoning_content)\n","\n","            # 1. Base Positive Reward (Capped at 0.15 instead of 0.2)\n","            # We want it to think, but not think too much.\n","            score = min(0.15, (length / 500.0) * 0.15)\n","\n","            # 2. Apply Penalties (The \"Anti-Ramble\" Mechanism)\n","            if length > 700:\n","                score -= 0.05  # First warning shot\n","            if length > 1000:\n","                score -= 0.05  # Serious penalty (Total -0.10)\n","\n","            rewards.append(score)\n","        else:\n","            rewards.append(0.0)\n","\n","    return rewards"],"metadata":{"id":"bfVxKTg9L6cd","executionInfo":{"status":"ok","timestamp":1767488324660,"user_tz":360,"elapsed":1,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n","    \"\"\"\n","    Rewards the model based on the PERCENTAGE of tests passed.\n","    Includes a \"Clean Sweep Bonus\" for 100% completion.\n","    \"\"\"\n","    rewards = []\n","    for prompt, completion, task_data in zip(prompts, completions, answer):\n","        code, status = extract_solution(completion)\n","        if not code:\n","            rewards.append(0.0)\n","            continue\n","\n","        passed, total, err = run_mbpp_tests(code, task_data)\n","\n","        if total == 0:\n","            rewards.append(0.0)\n","            continue\n","\n","        # CALCULATE SCORE: Fraction of tests passed\n","        score = passed / total\n","\n","        # VICTORY BONUS: If 100% passed, add +0.1 bonus\n","        # This differentiates \"perfect\" from \"lucky\" and prevents settling\n","        if passed == total:\n","            score += 0.1\n","\n","        rewards.append(score)\n","\n","    return rewards"],"metadata":{"id":"hLNU6pML0gqN","executionInfo":{"status":"ok","timestamp":1767488325241,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["# Step 11: Dataset Formatting and Unit Testing"],"metadata":{"id":"OI6Eut_JXUZW"}},{"cell_type":"code","source":["# Clean the Data\n","# The raw MBPP+ dataset has inconsistent schemas (some fields are lists, some are None).\n","# We fix this by extracting ONLY what we need: the test cases.\n","dict_data = []"],"metadata":{"id":"jJF74XFesHNc","executionInfo":{"status":"ok","timestamp":1767488326669,"user_tz":360,"elapsed":2,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["for task_id, task_data in MBPP_TASKS.items():\n","    # Extract the test cases using our helper from Step 8\n","    # This handles the \"messy\" parsing right now, so the Dataset is clean.\n","    try:\n","        tests = get_tests_from_task(task_data)\n","    except KeyError:\n","        # If a task is broken/empty, skip it to prevent crashes\n","        print(f\"Skipping task {task_id}: No tests found.\")\n","        continue\n","\n","    # Create a CLEAN 'answer' dictionary\n","    # This guarantees every row has the exact same structure.\n","    # This prevents the \"ArrowInvalid\" error.\n","    clean_answer = {\n","        \"task_id\": str(task_id),\n","        \"test_list\": tests  # Always a List of Strings\n","    }\n","\n","    # Append to our list\n","    dict_data.append({\n","        \"prompt\": task_data[\"prompt\"],\n","        \"answer\": clean_answer\n","    })"],"metadata":{"id":"Fx2h97Kfp9sf","executionInfo":{"status":"ok","timestamp":1767488327056,"user_tz":360,"elapsed":2,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["# Creating a Hugging Face compatible dataset\n","dataset = Dataset.from_list(dict_data)"],"metadata":{"id":"O3VW7urjp9qi","executionInfo":{"status":"ok","timestamp":1767488327758,"user_tz":360,"elapsed":24,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["print(\"Dataset Features:\", dataset.features)\n","print(\"Sample Row Answer Keys:\", dataset[0][\"answer\"].keys())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IZsJGtmHp9oL","executionInfo":{"status":"ok","timestamp":1767488328102,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"3fd69fa1-ae06-45ab-b544-9e21d35da78b"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset Features: {'prompt': Value('string'), 'answer': {'task_id': Value('string'), 'test_list': List(Value('string'))}}\n","Sample Row Answer Keys: dict_keys(['task_id', 'test_list'])\n"]}]},{"cell_type":"code","source":["# Pick the 2nd task again for consistency\n","task = dataset[2][\"answer\"] # We grab it from our NEW dataset column\n","prompt = dataset[2][\"prompt\"]"],"metadata":{"id":"pv2zGhEauI7Y","executionInfo":{"status":"ok","timestamp":1767488328322,"user_tz":360,"elapsed":1,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["prompt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":42},"id":"THY3eewTxW9T","executionInfo":{"status":"ok","timestamp":1767488329344,"user_tz":360,"elapsed":4,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"ee05b751-ca7e-4f96-f993-7a5869d51861"},"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\"\"\"\\nWrite a function to find the n largest integers from a given list of numbers, returned in descending order.\\nassert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],3)==[85, 75, 65]\\n\"\"\"\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["# Build the prompt structure\n","messages = [\n","    {\"role\": \"system\", \"content\": system_prompt},\n","    {\"role\": \"user\", \"content\": prompt},\n","]"],"metadata":{"id":"J5qx7l6duI5A","executionInfo":{"status":"ok","timestamp":1767488329559,"user_tz":360,"elapsed":1,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["inputs = tokenizer.apply_chat_template(\n","    messages,\n","    tokenize=True,\n","    add_generation_prompt=True,\n","    return_tensors=\"pt\",\n","    return_dict=True,\n",")\n","inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}"],"metadata":{"id":"zp95CUQouI25","executionInfo":{"status":"ok","timestamp":1767488329675,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["# Generate\n","FastLanguageModel.for_inference(model)\n","with torch.no_grad():\n","    output = model.generate(\n","        **inputs,\n","        max_new_tokens=512,\n","        temperature=0.0,\n","    )"],"metadata":{"id":"zB24zGc3uI0m","executionInfo":{"status":"ok","timestamp":1767488338103,"user_tz":360,"elapsed":6465,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["# Slice to get only the generated text\n","input_len = inputs[\"input_ids\"].shape[1]\n","generated_text = tokenizer.decode(output[0][input_len:], skip_special_tokens=True)"],"metadata":{"id":"yEa1OUdJuIxm","executionInfo":{"status":"ok","timestamp":1767488338382,"user_tz":360,"elapsed":42,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["print(generated_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1-hJ_d1-p9j3","executionInfo":{"status":"ok","timestamp":1767488338748,"user_tz":360,"elapsed":14,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"0b9e1114-d1e4-411c-d945-5b761612519b"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["<START_WORKING_OUT>\n","Problem: Find n largest integers from a list, return in descending order.\n","Approach: Use heapq.nlargest which returns n largest elements in order from largest to smallest.\n","Parameters: List of numbers, integer n.\n","Return: List of n largest numbers in descending order.\n","</END_WORKING_OUT>\n","<SOLUTION>\n","import heapq\n","\n","def heap_queue_largest(nums, n):\n","    \"\"\"\n","    Return the n largest numbers from nums in descending order.\n","    \n","    Args:\n","        nums: List of numbers (integers or floats)\n","        n: Number of largest elements to return\n","        \n","    Returns:\n","        List of n largest numbers in descending order\n","    \"\"\"\n","    if n <= 0:\n","        return []\n","    if n >= len(nums):\n","        nums_sorted = sorted(nums, reverse=True)\n","        return nums_sorted[:n]\n","    return heapq.nlargest(n, nums)\n","</SOLUTION>\n"]}]},{"cell_type":"code","source":["# CRITICAL PART: Testing the Reward Functions\n","# The Reward Functions expect LISTS (Batches), so we wrap our single item in a list.\n","# This simulates a batch size of 1.\n","batch_prompts = [prompt]\n","batch_completions = [generated_text]\n","batch_answers = [task] # This is the \"answer\" column data"],"metadata":{"id":"mGvSjCOcun8N","executionInfo":{"status":"ok","timestamp":1767488339525,"user_tz":360,"elapsed":1,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["# 1. Test Format Reward\n","r_format = format_reward_func(completions=batch_completions)\n","print(f\"Format Reward (Expect 0.1): {r_format[0]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QKcwBYWcun5J","executionInfo":{"status":"ok","timestamp":1767488339733,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"f2d88b5c-079c-4a54-eca4-77f34792f335"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Format Reward (Expect 0.1): 0.1\n"]}]},{"cell_type":"code","source":["# 2. Test Reasoning Reward\n","r_reason = reasoning_reward_func(completions=batch_completions)\n","print(f\"Reasoning Reward (Expect 0.0-0.15): {r_reason[0]:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h8Mo1AnZun3L","executionInfo":{"status":"ok","timestamp":1767488339959,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"09fc7e3c-1e7e-4ebd-ee3e-3f7d4ae64b83"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Reasoning Reward (Expect 0.0-0.15): 0.0795\n"]}]},{"cell_type":"code","source":["\n","# 3. Test Correctness Reward (The complex one)\n","# Note: We pass 'answer' explicitly, just like the Trainer will.\n","r_correct = correctness_reward_func(\n","    prompts=batch_prompts,\n","    completions=batch_completions,\n","    answer=batch_answers\n",")\n","print(f\"Correctness Reward (Expect 1.0 or 0.0): {r_correct[0]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"07ZCMGfIun08","executionInfo":{"status":"ok","timestamp":1767488340318,"user_tz":360,"elapsed":150,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"0f979244-5e75-4656-f63a-ce6da4a1f470"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["Correctness Reward (Expect 1.0 or 0.0): 1.1\n"]}]},{"cell_type":"code","source":["if r_format[0] > 0 and (r_correct[0] == 0.0 or r_correct[0] == 1.1):\n","    print(\" SUCCESS: All reward functions accepted the inputs and returned scores.\")\n","    print(\" The plumbing is connected correctly.\")\n","else:\n","    print(\" FAIL: Something returned an unexpected format.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fADybjDeunyh","executionInfo":{"status":"ok","timestamp":1767488341369,"user_tz":360,"elapsed":7,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"b00d8be6-ece9-4bf5-fe4b-437bb3646204"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":[" SUCCESS: All reward functions accepted the inputs and returned scores.\n"," The plumbing is connected correctly.\n"]}]},{"cell_type":"markdown","source":["# Step 12: Apply Chat Template"],"metadata":{"id":"24UBloc4drcX"}},{"cell_type":"code","source":["def apply_chat_template(row):\n","    messages = [\n","        {\"role\": \"system\", \"content\": system_prompt},\n","        {\"role\": \"user\", \"content\": row[\"prompt\"]}\n","    ]\n","\n","    # \"tokenize=False\" gives us the raw text string (e.g. \"<|system|>...<|user|>...\")\n","    # This is exactly what the GRPOTrainer expects in the 'prompt' column.\n","    row[\"prompt\"] = tokenizer.apply_chat_template(\n","        messages,\n","        tokenize=False,\n","        add_generation_prompt=True\n","    )\n","    return row"],"metadata":{"id":"RO2L3cPMdG0H","executionInfo":{"status":"ok","timestamp":1767488353599,"user_tz":360,"elapsed":6,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["# Apply it to the whole dataset\n","original_prompt = dataset[0][\"prompt\"]\n","dataset = dataset.map(apply_chat_template)\n","\n","print(\"\\n--- BEFORE ---\")\n","print(original_prompt)\n","print(\"\\n--- AFTER (What the Model Sees) ---\")\n","print(dataset[0][\"prompt\"])"],"metadata":{"id":"VBJ_nPqWdzC-","colab":{"base_uri":"https://localhost:8080/","height":644,"referenced_widgets":["f33ac576dd3c4def92cd617f11b597cc","a6d5bdb101f64f9d88b3758765b204ab","397155bc35084141a17e3df71892f4cb","948f12b2d6ef4b018df550b440fe6f4a","42cfbb9483f749fa944734448e5c6bb1","f6427672d6644533a5fe22c71096e5af","ceade91e0755487ca4b627176e22a138","4e694633855d49b68f04ab38a4f97f6a","5aefae798aaf45c5a1106957737b79d0","64f5724aa595462d9773ad7d5f37e02d","cb50f78b3d134758a1d6da947ceb6c92"]},"executionInfo":{"status":"ok","timestamp":1767488353921,"user_tz":360,"elapsed":209,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"ee8381b7-f862-4d15-d0f5-e4956ffded31"},"execution_count":56,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/378 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f33ac576dd3c4def92cd617f11b597cc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","--- BEFORE ---\n","\"\"\"\n","Write a function to find the shared elements from the given two lists.\n","assert set(similar_elements((3, 4, 5, 6),(5, 7, 4, 10))) == set((4, 5))\n","\"\"\"\n","\n","\n","--- AFTER (What the Model Sees) ---\n","<|im_start|>system\n","You are a code-generation engine.\n","You must output your response in the following exact format:\n","<START_WORKING_OUT>\n","Concise reasoning steps required to solve the problem.\n","</END_WORKING_OUT>\n","<SOLUTION>\n","Valid Python code only.\n","</SOLUTION>\n","Do not output anything outside these tags.<|im_end|>\n","<|im_start|>user\n","\"\"\"\n","Write a function to find the shared elements from the given two lists.\n","assert set(similar_elements((3, 4, 5, 6),(5, 7, 4, 10))) == set((4, 5))\n","\"\"\"\n","<|im_end|>\n","<|im_start|>assistant\n","\n"]}]},{"cell_type":"markdown","source":["# Step 13: Setting up GRPO Configurations"],"metadata":{"id":"SX_1Z2XBgGJk"}},{"cell_type":"code","source":["# We give the model ample room so it never gets cut off\n","max_prompt_length = 512\n","max_completion_length = 2048  # doubled from T4 config"],"metadata":{"id":"HArFazRbd3w5","executionInfo":{"status":"ok","timestamp":1767488396025,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["vllm_sampling_params = SamplingParams(\n","    min_p = 0.1,\n","    top_p = 0.95,\n","    top_k = -1,\n","    seed = 3407,\n","    temperature = 0.8, # High enough to get diverse answers for GRPO\n","    stop = [\"</SOLUTION>\"],\n","    include_stop_str_in_output = True,\n",")"],"metadata":{"id":"s3bSpC1ngg_K","executionInfo":{"status":"ok","timestamp":1767488409715,"user_tz":360,"elapsed":5,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["# 3. The Trainer Config\n","training_args = GRPOConfig(\n","    # Integration\n","    vllm_sampling_params = vllm_sampling_params, # We use vLLM for speed\n","    output_dir = \"outputs\",\n","    report_to = \"wandb\",\n","    run_name = \"mbpp-grpo-a100-run3-full\",\n","\n","    # Optimization\n","    learning_rate = 1e-5,        # Aggressive for short horizon\n","    beta = 0.005,\n","    weight_decay = 0.1,\n","    warmup_ratio = 0.1,\n","    lr_scheduler_type = \"cosine\",\n","    optim = \"adamw_8bit\",\n","\n","    # A100 POWER SETTINGS\n","    per_device_train_batch_size = 1,\n","    gradient_accumulation_steps = 4,\n","    num_generations = 16,             # G=8: Much better stability than G=4\n","\n","    # Lengths\n","    max_prompt_length = max_prompt_length,\n","    max_completion_length = max_completion_length,\n","\n","    # Duration\n","    num_train_epochs = 2,            # 1 Epoch is safest for RL on small data\n","    #max_steps = 5,\n","\n","    # Logging\n","    logging_steps = 5,\n","    save_steps = 20,                 # Save more frequently\n","    use_vllm = True,                 # Explicitly enable vLLM\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IfEtXGoIgrEV","executionInfo":{"status":"ok","timestamp":1767488410577,"user_tz":360,"elapsed":9,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"64b42ad6-c39f-45ae-e42f-6b6b9229a872"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Unsloth: We now expect `per_device_train_batch_size` * `gradient_accumulation_steps` * `world_size` to be a multiple of `num_generations`.\n","We will change the batch size of 1 to the `num_generations` of 16\n"]}]},{"cell_type":"markdown","source":["# Step 14: Initialize and Run GRPO Trainer"],"metadata":{"id":"Cz18F7NsrHPI"}},{"cell_type":"code","source":["# Select the Reward Functions we defined in Step 10\n","# These are the \"Judges\" that will score the model's outputs.\n","reward_functions = [\n","    format_reward_func,       # Did it use <START_WORKING_OUT> and <SOLUTION>? (0.1)\n","    reasoning_reward_func,    # Did it write ~500 chars of thought? (0.2)\n","    correctness_reward_func   # Did the code actually pass the tests? (1.0)\n","]"],"metadata":{"id":"bDJjRr2srGn1","executionInfo":{"status":"ok","timestamp":1767488412589,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["# Initialize the Trainer\n","trainer = GRPOTrainer(\n","    model = model,\n","    processing_class = tokenizer,\n","    reward_funcs = reward_functions,\n","    args = training_args,         # The A100 Config we just built\n","    train_dataset = dataset,      # The dataset with the Chat Template applied\n",")"],"metadata":{"id":"cpXKD9MYhJaI","executionInfo":{"status":"ok","timestamp":1767488412946,"user_tz":360,"elapsed":147,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"TRNxA8IKraoK","outputId":"5ba67548-ae26-4257-bb86-0b7601832998","executionInfo":{"status":"error","timestamp":1767489933104,"user_tz":360,"elapsed":1519794,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":62,"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n","   \\\\   /|    Num examples = 378 | Num Epochs = 2 | Total steps = 188\n","O^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 4\n","\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 4 x 1) = 64\n"," \"-____-\"     Trainable parameters = 66,060,288 of 4,088,528,384 (1.62% trained)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/grpo-verified-reasoner/wandb/run-20260104_010017-x8u76fok</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/samyakshrestha-university-of-texas-at-dallas/mbpp-rl-project/runs/x8u76fok' target=\"_blank\">mbpp-grpo-a100-run3-full</a></strong> to <a href='https://wandb.ai/samyakshrestha-university-of-texas-at-dallas/mbpp-rl-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/samyakshrestha-university-of-texas-at-dallas/mbpp-rl-project' target=\"_blank\">https://wandb.ai/samyakshrestha-university-of-texas-at-dallas/mbpp-rl-project</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/samyakshrestha-university-of-texas-at-dallas/mbpp-rl-project/runs/x8u76fok' target=\"_blank\">https://wandb.ai/samyakshrestha-university-of-texas-at-dallas/mbpp-rl-project/runs/x8u76fok</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["wandb: Detected [huggingface_hub.inference, openai] in use.\n","wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n","wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Will smartly offload gradients to save VRAM!\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='60' max='188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 60/188 23:42 < 52:20, 0.04 it/s, Epoch 0.63/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>reward</th>\n","      <th>reward_std</th>\n","      <th>completions / mean_length</th>\n","      <th>completions / min_length</th>\n","      <th>completions / max_length</th>\n","      <th>completions / clipped_ratio</th>\n","      <th>completions / mean_terminated_length</th>\n","      <th>completions / min_terminated_length</th>\n","      <th>completions / max_terminated_length</th>\n","      <th>kl</th>\n","      <th>rewards / format_reward_func / mean</th>\n","      <th>rewards / format_reward_func / std</th>\n","      <th>rewards / reasoning_reward_func / mean</th>\n","      <th>rewards / reasoning_reward_func / std</th>\n","      <th>rewards / correctness_reward_func / mean</th>\n","      <th>rewards / correctness_reward_func / std</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>5</td>\n","      <td>0.003200</td>\n","      <td>0.995726</td>\n","      <td>0.188900</td>\n","      <td>693.800000</td>\n","      <td>693.800000</td>\n","      <td>693.800000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.649213</td>\n","      <td>0.099688</td>\n","      <td>0.002500</td>\n","      <td>0.076663</td>\n","      <td>0.032918</td>\n","      <td>0.819375</td>\n","      <td>0.417288</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.002700</td>\n","      <td>1.093298</td>\n","      <td>0.242669</td>\n","      <td>776.400000</td>\n","      <td>776.400000</td>\n","      <td>776.400000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.536763</td>\n","      <td>0.099375</td>\n","      <td>0.003507</td>\n","      <td>0.080381</td>\n","      <td>0.031195</td>\n","      <td>0.913542</td>\n","      <td>0.372759</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.003300</td>\n","      <td>1.008403</td>\n","      <td>0.310461</td>\n","      <td>359.400000</td>\n","      <td>359.400000</td>\n","      <td>359.400000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.661359</td>\n","      <td>0.099688</td>\n","      <td>0.002500</td>\n","      <td>0.088403</td>\n","      <td>0.034427</td>\n","      <td>0.820313</td>\n","      <td>0.434723</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.002300</td>\n","      <td>0.989610</td>\n","      <td>0.263610</td>\n","      <td>1478.200000</td>\n","      <td>1478.200000</td>\n","      <td>1478.200000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.454509</td>\n","      <td>0.098750</td>\n","      <td>0.008507</td>\n","      <td>0.093152</td>\n","      <td>0.033721</td>\n","      <td>0.797708</td>\n","      <td>0.457775</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.002300</td>\n","      <td>1.127841</td>\n","      <td>0.242982</td>\n","      <td>455.400000</td>\n","      <td>455.400000</td>\n","      <td>455.400000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.458946</td>\n","      <td>0.099375</td>\n","      <td>0.005000</td>\n","      <td>0.098362</td>\n","      <td>0.034652</td>\n","      <td>0.930104</td>\n","      <td>0.344904</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.004600</td>\n","      <td>0.854438</td>\n","      <td>0.266999</td>\n","      <td>1175.987500</td>\n","      <td>822.400000</td>\n","      <td>1181.600000</td>\n","      <td>0.996875</td>\n","      <td>50.400000</td>\n","      <td>50.400000</td>\n","      <td>50.400000</td>\n","      <td>0.923881</td>\n","      <td>0.098438</td>\n","      <td>0.007768</td>\n","      <td>0.101833</td>\n","      <td>0.033994</td>\n","      <td>0.654167</td>\n","      <td>0.490555</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.002100</td>\n","      <td>1.015911</td>\n","      <td>0.275771</td>\n","      <td>837.200000</td>\n","      <td>837.200000</td>\n","      <td>837.200000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.414263</td>\n","      <td>0.099688</td>\n","      <td>0.002500</td>\n","      <td>0.105858</td>\n","      <td>0.033936</td>\n","      <td>0.810365</td>\n","      <td>0.442271</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.004700</td>\n","      <td>0.887793</td>\n","      <td>0.307196</td>\n","      <td>1790.600000</td>\n","      <td>1790.600000</td>\n","      <td>1790.600000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.930803</td>\n","      <td>0.096875</td>\n","      <td>0.015148</td>\n","      <td>0.106543</td>\n","      <td>0.036287</td>\n","      <td>0.684375</td>\n","      <td>0.466817</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.002000</td>\n","      <td>1.001083</td>\n","      <td>0.246510</td>\n","      <td>1411.000000</td>\n","      <td>1411.000000</td>\n","      <td>1411.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.397159</td>\n","      <td>0.098437</td>\n","      <td>0.007768</td>\n","      <td>0.107958</td>\n","      <td>0.035586</td>\n","      <td>0.794688</td>\n","      <td>0.471774</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.002000</td>\n","      <td>1.093301</td>\n","      <td>0.345522</td>\n","      <td>1736.600000</td>\n","      <td>1736.600000</td>\n","      <td>1736.600000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.392302</td>\n","      <td>0.097500</td>\n","      <td>0.015268</td>\n","      <td>0.114625</td>\n","      <td>0.036817</td>\n","      <td>0.881176</td>\n","      <td>0.386312</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.002800</td>\n","      <td>1.169581</td>\n","      <td>0.217234</td>\n","      <td>868.753125</td>\n","      <td>765.000000</td>\n","      <td>870.400000</td>\n","      <td>0.996875</td>\n","      <td>29.200000</td>\n","      <td>29.200000</td>\n","      <td>29.200000</td>\n","      <td>0.552684</td>\n","      <td>0.099375</td>\n","      <td>0.005000</td>\n","      <td>0.114425</td>\n","      <td>0.033909</td>\n","      <td>0.955781</td>\n","      <td>0.319878</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["1.5707963267948966\n","((3.0, -2.2831853071795867), (-1.960930862590836-2.2704074859237844j))\n","26\n","8\n","2\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4032920361.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/drive/MyDrive/grpo-verified-reasoner/unsloth_compiled_cache/UnslothGRPOTrainer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"for_training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Return inference mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"for_inference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2326\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2328\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2329\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2330\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/_utils.py\u001b[0m in \u001b[0;36m_unsloth_training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/grpo-verified-reasoner/unsloth_compiled_cache/UnslothGRPOTrainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   2915\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loss_type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2916\u001b[0m                 loss, completion_length, mean_kl, delta, flat_is_ratio = (\n\u001b[0;32m-> 2917\u001b[0;31m                     grpo_accumulated_loss(\n\u001b[0m\u001b[1;32m   2918\u001b[0m                         \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2919\u001b[0m                         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/grpo-verified-reasoner/unsloth_compiled_cache/UnslothGRPOTrainer.py\u001b[0m in \u001b[0;36mgrpo_accumulated_loss\u001b[0;34m(trainer, input_ids, attention_mask, logits_to_keep, completion_mask, advantages, old_hidden_states, ref_hidden_states, n_chunks, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0mleft_pad_tokens_per_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_pad_tokens_in_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_to_keep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessing_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mmax_left_pad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_pad_tokens_per_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft_pack_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessing_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["# Step 15: Sanity Check\n","\n","Let us now check the model that we just trained!"],"metadata":{"id":"pbb39NqiB9E8"}},{"cell_type":"code","source":["# Switch to Inference Mode\n","FastLanguageModel.for_inference(model)"],"metadata":{"id":"6rXx16M4-i8j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766903294789,"user_tz":360,"elapsed":55,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"d22fd3b2-fe65-4725-d215-b92e85ea4293"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): Qwen3ForCausalLM(\n","      (model): Qwen3Model(\n","        (embed_tokens): Embedding(151936, 2560, padding_idx=151654)\n","        (layers): ModuleList(\n","          (0-35): 36 x Qwen3DecoderLayer(\n","            (self_attn): Qwen3Attention(\n","              (q_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear(\n","                (base_layer): Linear(in_features=4096, out_features=2560, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): Qwen3MLP(\n","              (gate_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9728, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9728, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear(\n","                (base_layer): Linear(in_features=9728, out_features=2560, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=9728, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","            (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","          )\n","        )\n","        (norm): Qwen3RMSNorm((2560,), eps=1e-06)\n","        (rotary_emb): LlamaRotaryEmbedding()\n","      )\n","      (lm_head): Linear(in_features=2560, out_features=151936, bias=False)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["test_question = \"Write a function to find the volume of a sphere given its radius.\""],"metadata":{"id":"KDUXcF5WCVAQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["messages = [\n","    {\"role\": \"system\", \"content\": system_prompt},\n","    {\"role\": \"user\", \"content\": test_question},\n","]"],"metadata":{"id":"pheP84NQCZ0U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tokenize (Exactly as before)\n","inputs = tokenizer.apply_chat_template(\n","    messages,\n","    tokenize=True,\n","    add_generation_prompt=True,\n","    return_tensors=\"pt\",\n","    return_dict=True,\n",")\n","inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}"],"metadata":{"id":"yzUBfniDCdY2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generate\n","with torch.no_grad():\n","    output = model.generate(\n","        **inputs,\n","        max_new_tokens=512,\n","        temperature=0.8, # Slight creativity to encourage reasoning\n","    )"],"metadata":{"id":"Ypr3vQCmCevo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 5. Decode (Slicing input_len just like before)\n","input_len = inputs[\"input_ids\"].shape[1]\n","generated_text = tokenizer.decode(output[0][input_len:], skip_special_tokens=True)\n","\n","print(\"\\n=== FINAL MODEL OUTPUT ===\")\n","print(generated_text)"],"metadata":{"id":"TkVWR8DUCkV2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766903318820,"user_tz":360,"elapsed":6,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"2b571abe-1f2e-44a0-ec69-a489b4f447f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== FINAL MODEL OUTPUT ===\n","<START_WORKING_OUT>\n","The formula for the volume of a sphere is V = (4/3) * π * r³.\n","We need a function that takes the radius r as input and returns the volume.\n","The function should handle floating-point numbers for the radius.\n","We'll use Python's math module for the value of π (math.pi).\n","The calculation involves cubing the radius (r**3) and then multiplying by (4/3) * π.\n","We'll return the result as a float.\n","</END_WORKING_OUT>\n","<SOLUTION>\n","import math\n","\n","def sphere_volume(radius):\n","    \"\"\"\n","    Calculate the volume of a sphere given its radius.\n","    \n","    Parameters:\n","    radius (float): The radius of the sphere.\n","    \n","    Returns:\n","    float: The volume of the sphere.\n","    \"\"\"\n","    if radius < 0:\n","        raise ValueError(\"Radius cannot be negative\")\n","    return (4/3) * math.pi * (radius ** 3)\n","</SOLUTION>\n"]}]},{"cell_type":"markdown","source":["# Step 16: Saving the Model"],"metadata":{"id":"KycC-7u-DdY9"}},{"cell_type":"code","source":["MODEL_OUT = \"models/qwen3-4b-grpo-final\""],"metadata":{"id":"AwIpGowdDfgG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.save_lora(MODEL_OUT)"],"metadata":{"id":"Hxf16u_-DtKQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.save_pretrained(MODEL_OUT)"],"metadata":{"id":"HKiRos6BDych","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766903703507,"user_tz":360,"elapsed":280,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"baeb5a7d-c7d8-4340-86b8-635129bbac89"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('models/qwen3-4b-grpo-final/tokenizer_config.json',\n"," 'models/qwen3-4b-grpo-final/special_tokens_map.json',\n"," 'models/qwen3-4b-grpo-final/chat_template.jinja',\n"," 'models/qwen3-4b-grpo-final/vocab.json',\n"," 'models/qwen3-4b-grpo-final/merges.txt',\n"," 'models/qwen3-4b-grpo-final/added_tokens.json',\n"," 'models/qwen3-4b-grpo-final/tokenizer.json')"]},"metadata":{},"execution_count":71}]}]}