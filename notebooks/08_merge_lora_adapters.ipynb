{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyOSbUiRxrjnzCvUIjNDRmp0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"73629c9edc1c4187a152d29bfc5d31a5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b8c2d56929024e42a6d8b18f081517fa","IPY_MODEL_4dbae2ac932a465c96ae39737c129836","IPY_MODEL_5e0c9cff9ba04ac38772d7b35f0ebd07"],"layout":"IPY_MODEL_f6b5504183a14c199da0bafe6cce0102"}},"b8c2d56929024e42a6d8b18f081517fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d6ada13f9734e4cbf9835d92fd16a56","placeholder":"â€‹","style":"IPY_MODEL_f739398b6b34469c857e647b4194b5ab","value":"Loadingâ€‡checkpointâ€‡shards:â€‡100%"}},"4dbae2ac932a465c96ae39737c129836":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b9abea5ef4d44b6bd8f14c9df4bd78d","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_750d2dd6f5a845e5a8b7de450c19d54f","value":2}},"5e0c9cff9ba04ac38772d7b35f0ebd07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58ccee6ff81c4300b66f736b616ed74f","placeholder":"â€‹","style":"IPY_MODEL_df34aee6d13646b898901587f2c0bbab","value":"â€‡2/2â€‡[00:02&lt;00:00,â€‡â€‡1.27s/it]"}},"f6b5504183a14c199da0bafe6cce0102":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d6ada13f9734e4cbf9835d92fd16a56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f739398b6b34469c857e647b4194b5ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b9abea5ef4d44b6bd8f14c9df4bd78d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"750d2dd6f5a845e5a8b7de450c19d54f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"58ccee6ff81c4300b66f736b616ed74f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df34aee6d13646b898901587f2c0bbab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Step 1: Mounting Google Drive and Importing Libraries\n"],"metadata":{"id":"JYGkPqOQyjCb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"XezTJj3VyV3I"},"outputs":[],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","%cd /content/drive/MyDrive/grpo-verified-reasoner\n","!ls"]},{"cell_type":"code","source":["# Install UV (Faster pip)\n","!pip install --upgrade -qqq uv"],"metadata":{"id":"1nzcSLWdyoL6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -q unsloth"],"metadata":{"id":"7zEhja-B9duL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch\n","import safetensors.torch\n","from unsloth import FastLanguageModel"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"axrWYx3W9hc-","executionInfo":{"status":"ok","timestamp":1767785229548,"user_tz":360,"elapsed":18730,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"81218f4a-10c8-4574-9376-61bcc21fabab"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"]}]},{"cell_type":"markdown","source":["# Step 2: Loading the Base Model and the LoRA Adapter"],"metadata":{"id":"w3UklbRj9rLb"}},{"cell_type":"code","source":["BASE_MODEL_PATH = \"unsloth/Qwen3-4B-Base\"\n","CHECKPOINT_PATH = \"outputs/checkpoint-188\"\n","MERGED_PATH = \"models/qwen3-4b-grpo-final-2-merged\""],"metadata":{"id":"ZLj3K84i9wev","executionInfo":{"status":"ok","timestamp":1767785241157,"user_tz":360,"elapsed":2,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = CHECKPOINT_PATH,\n","    max_seq_length = 3072,\n","    load_in_4bit = False,    # Must be False for merging\n","    dtype = torch.float16,   # Standard 16-bit precision\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":168,"referenced_widgets":["73629c9edc1c4187a152d29bfc5d31a5","b8c2d56929024e42a6d8b18f081517fa","4dbae2ac932a465c96ae39737c129836","5e0c9cff9ba04ac38772d7b35f0ebd07","f6b5504183a14c199da0bafe6cce0102","2d6ada13f9734e4cbf9835d92fd16a56","f739398b6b34469c857e647b4194b5ab","2b9abea5ef4d44b6bd8f14c9df4bd78d","750d2dd6f5a845e5a8b7de450c19d54f","58ccee6ff81c4300b66f736b616ed74f","df34aee6d13646b898901587f2c0bbab"]},"id":"j9RotUbF95JX","executionInfo":{"status":"ok","timestamp":1767785269070,"user_tz":360,"elapsed":25983,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"9639f7bb-0d9d-403a-b88a-501cde329c42"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2026.1.2: Fast Qwen3 patching. Transformers: 4.57.3.\n","   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.1\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73629c9edc1c4187a152d29bfc5d31a5"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Unsloth 2026.1.2 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"]}]},{"cell_type":"code","source":["# This physically modifies the weights: W_new = W_base + (A * B)\n","model.merge_and_unload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wsr9yIBJ-LVa","executionInfo":{"status":"ok","timestamp":1767785385537,"user_tz":360,"elapsed":149,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"61c00103-e019-4a2d-a29d-2b9988a6ba4e"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Qwen3ForCausalLM(\n","  (model): Qwen3Model(\n","    (embed_tokens): Embedding(151936, 2560, padding_idx=151654)\n","    (layers): ModuleList(\n","      (0-35): 36 x Qwen3DecoderLayer(\n","        (self_attn): Qwen3Attention(\n","          (q_proj): Linear(in_features=2560, out_features=4096, bias=False)\n","          (k_proj): Linear(in_features=2560, out_features=1024, bias=False)\n","          (v_proj): Linear(in_features=2560, out_features=1024, bias=False)\n","          (o_proj): Linear(in_features=4096, out_features=2560, bias=False)\n","          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","          (rotary_emb): LlamaRotaryEmbedding()\n","        )\n","        (mlp): Qwen3MLP(\n","          (gate_proj): Linear(in_features=2560, out_features=9728, bias=False)\n","          (up_proj): Linear(in_features=2560, out_features=9728, bias=False)\n","          (down_proj): Linear(in_features=9728, out_features=2560, bias=False)\n","          (act_fn): SiLUActivation()\n","        )\n","        (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","        (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","      )\n","    )\n","    (norm): Qwen3RMSNorm((2560,), eps=1e-06)\n","    (rotary_emb): LlamaRotaryEmbedding()\n","  )\n","  (lm_head): Linear(in_features=2560, out_features=151936, bias=False)\n",")"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# Saves as a standard model (no adapters folder, just model.safetensors)\n","model.save_pretrained_merged(\n","    MERGED_PATH,\n","    tokenizer,\n","    save_method = \"merged_16bit\",\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qDIF8Sic-OH2","executionInfo":{"status":"ok","timestamp":1767785490187,"user_tz":360,"elapsed":72512,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"82523488-b9c3-4cdd-a212-c1da8f5626b6"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Found HuggingFace hub cache directory: /root/.cache/huggingface/hub\n","Checking cache directory for required files...\n"]},{"output_type":"stream","name":"stderr","text":["Unsloth: Copying 2 files from cache to `models/qwen3-4b-grpo-final-2-merged`: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:22<00:00, 11.33s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Successfully copied all 2 files from cache to `models/qwen3-4b-grpo-final-2-merged`\n","Checking cache directory for required files...\n","Cache check failed: tokenizer.model not found in local cache.\n","Not all required files found in cache. Will proceed with downloading.\n"]},{"output_type":"stream","name":"stderr","text":["Unsloth: Preparing safetensor model files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 20410.24it/s]\n","Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:46<00:00, 23.37s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Merge process complete. Saved to `/content/drive/MyDrive/grpo-verified-reasoner/models/qwen3-4b-grpo-final-2-merged`\n"]}]},{"cell_type":"code","source":["sft = safetensors.torch.load_file(\"models/qwen3-4b-sft/adapter_model.safetensors\")\n","grpo = safetensors.torch.load_file(\"outputs/checkpoint-188/adapter_model.safetensors\")\n","\n","# Pick any key\n","k = list(sft.keys())[0]\n","torch.norm(sft[k] - grpo[k])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CXSnbFawOMq2","executionInfo":{"status":"ok","timestamp":1767785956854,"user_tz":360,"elapsed":12659,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"c621fa7f-72a4-425c-e644-8207c2daa141"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.0285)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["sum(torch.norm(sft[k] - grpo[k]) for k in sft.keys()) / sum(torch.norm(sft[k]) for k in sft.keys())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"09bjZwBjPm3t","executionInfo":{"status":"ok","timestamp":1767786908317,"user_tz":360,"elapsed":337,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"9f5183f1-5b5c-4946-ac59-af4353381e7f"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.0100)"]},"metadata":{},"execution_count":11}]}]}