{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyNq+SagK61bJqAhU7Ie5QIc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Step 1: Mounting Google Drive and Importing Libraries\n"],"metadata":{"id":"JYGkPqOQyjCb"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XezTJj3VyV3I","executionInfo":{"status":"ok","timestamp":1767829706637,"user_tz":360,"elapsed":641,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"fce3a1d7-0756-46dc-dd20-287c8b0d4dee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/grpo-verified-reasoner\n","data\t\t\t      LICENSE\t outputs    unsloth_compiled_cache\n","grpo_trainer_lora_model       models\t README.md  _unsloth_sentencepiece_temp\n","huggingface_tokenizers_cache  notebooks  src\t    wandb\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","%cd /content/drive/MyDrive/grpo-verified-reasoner\n","!ls"]},{"cell_type":"code","source":["# Install UV (Faster pip)\n","!pip install --upgrade -qqq uv"],"metadata":{"id":"1nzcSLWdyoL6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -q unsloth"],"metadata":{"id":"7zEhja-B9duL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch\n","import safetensors.torch\n","from unsloth import FastLanguageModel"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"axrWYx3W9hc-","executionInfo":{"status":"ok","timestamp":1767829728152,"user_tz":360,"elapsed":21514,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"bc733c5c-ca03-480b-cb9f-ddcf8124656e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"]}]},{"cell_type":"markdown","source":["# Step 2: Loading the Base Model and the LoRA Adapter"],"metadata":{"id":"w3UklbRj9rLb"}},{"cell_type":"code","source":["BASE_MODEL_PATH = \"unsloth/Qwen3-4B-Base\"\n","SFT_MODEL_PATH  = \"models/qwen3-4b-sft\"\n","CHECKPOINT_PATH = \"outputs/checkpoint-188\"\n","MERGED_PATH = \"models/qwen3-4b-grpo-final-2-merged\""],"metadata":{"id":"ZLj3K84i9wev","executionInfo":{"status":"ok","timestamp":1767829728160,"user_tz":360,"elapsed":3,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = CHECKPOINT_PATH,\n","    max_seq_length = 3072,\n","    load_in_4bit = False,    # Must be False for merging\n","    dtype = torch.float16,   # Standard 16-bit precision\n",")"],"metadata":{"id":"j9RotUbF95JX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# This physically modifies the weights: W_new = W_base + (A * B)\n","model.merge_and_unload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wsr9yIBJ-LVa","executionInfo":{"status":"ok","timestamp":1767785385537,"user_tz":360,"elapsed":149,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"61c00103-e019-4a2d-a29d-2b9988a6ba4e"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Qwen3ForCausalLM(\n","  (model): Qwen3Model(\n","    (embed_tokens): Embedding(151936, 2560, padding_idx=151654)\n","    (layers): ModuleList(\n","      (0-35): 36 x Qwen3DecoderLayer(\n","        (self_attn): Qwen3Attention(\n","          (q_proj): Linear(in_features=2560, out_features=4096, bias=False)\n","          (k_proj): Linear(in_features=2560, out_features=1024, bias=False)\n","          (v_proj): Linear(in_features=2560, out_features=1024, bias=False)\n","          (o_proj): Linear(in_features=4096, out_features=2560, bias=False)\n","          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","          (rotary_emb): LlamaRotaryEmbedding()\n","        )\n","        (mlp): Qwen3MLP(\n","          (gate_proj): Linear(in_features=2560, out_features=9728, bias=False)\n","          (up_proj): Linear(in_features=2560, out_features=9728, bias=False)\n","          (down_proj): Linear(in_features=9728, out_features=2560, bias=False)\n","          (act_fn): SiLUActivation()\n","        )\n","        (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","        (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","      )\n","    )\n","    (norm): Qwen3RMSNorm((2560,), eps=1e-06)\n","    (rotary_emb): LlamaRotaryEmbedding()\n","  )\n","  (lm_head): Linear(in_features=2560, out_features=151936, bias=False)\n",")"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# Saves as a standard model (no adapters folder, just model.safetensors)\n","model.save_pretrained_merged(\n","    MERGED_PATH,\n","    tokenizer,\n","    save_method = \"merged_16bit\",\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qDIF8Sic-OH2","executionInfo":{"status":"ok","timestamp":1767785490187,"user_tz":360,"elapsed":72512,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"82523488-b9c3-4cdd-a212-c1da8f5626b6"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Found HuggingFace hub cache directory: /root/.cache/huggingface/hub\n","Checking cache directory for required files...\n"]},{"output_type":"stream","name":"stderr","text":["Unsloth: Copying 2 files from cache to `models/qwen3-4b-grpo-final-2-merged`: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:22<00:00, 11.33s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Successfully copied all 2 files from cache to `models/qwen3-4b-grpo-final-2-merged`\n","Checking cache directory for required files...\n","Cache check failed: tokenizer.model not found in local cache.\n","Not all required files found in cache. Will proceed with downloading.\n"]},{"output_type":"stream","name":"stderr","text":["Unsloth: Preparing safetensor model files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 20410.24it/s]\n","Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:46<00:00, 23.37s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Merge process complete. Saved to `/content/drive/MyDrive/grpo-verified-reasoner/models/qwen3-4b-grpo-final-2-merged`\n"]}]},{"cell_type":"code","source":["sft = safetensors.torch.load_file(\"models/qwen3-4b-sft/adapter_model.safetensors\")\n","grpo = safetensors.torch.load_file(\"outputs/checkpoint-188/adapter_model.safetensors\")\n","\n","# Pick any key\n","k = list(sft.keys())[0]\n","torch.norm(sft[k] - grpo[k])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CXSnbFawOMq2","executionInfo":{"status":"ok","timestamp":1767785956854,"user_tz":360,"elapsed":12659,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"c621fa7f-72a4-425c-e644-8207c2daa141"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.0285)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["sum(torch.norm(sft[k] - grpo[k]) for k in sft.keys()) / sum(torch.norm(sft[k]) for k in sft.keys())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"09bjZwBjPm3t","executionInfo":{"status":"ok","timestamp":1767786908317,"user_tz":360,"elapsed":337,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"9f5183f1-5b5c-4946-ac59-af4353381e7f"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.0100)"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["# Step 3: Merging SFT Model"],"metadata":{"id":"UepT38P60vxg"}},{"cell_type":"code","source":["MERGED_PATH = \"models/qwen3-4b-sft-merged\""],"metadata":{"id":"ARF0DVCK1Fz4","executionInfo":{"status":"ok","timestamp":1767829208464,"user_tz":360,"elapsed":2,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = SFT_MODEL_PATH,\n","    max_seq_length = 3072,\n","    load_in_4bit = False,    # Must be False for merging\n","    dtype = torch.float16,   # Standard 16-bit precision\n",")"],"metadata":{"id":"R6UJTSch0vW2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# This physically modifies the weights: W_new = W_base + (A * B)\n","model.merge_and_unload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fdGpZcjl05ur","executionInfo":{"status":"ok","timestamp":1767829343612,"user_tz":360,"elapsed":147,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"3a78a87d-f125-4a72-f6ef-74f93a1d0c78"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Qwen3ForCausalLM(\n","  (model): Qwen3Model(\n","    (embed_tokens): Embedding(151936, 2560, padding_idx=151654)\n","    (layers): ModuleList(\n","      (0-35): 36 x Qwen3DecoderLayer(\n","        (self_attn): Qwen3Attention(\n","          (q_proj): Linear(in_features=2560, out_features=4096, bias=False)\n","          (k_proj): Linear(in_features=2560, out_features=1024, bias=False)\n","          (v_proj): Linear(in_features=2560, out_features=1024, bias=False)\n","          (o_proj): Linear(in_features=4096, out_features=2560, bias=False)\n","          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","          (rotary_emb): LlamaRotaryEmbedding()\n","        )\n","        (mlp): Qwen3MLP(\n","          (gate_proj): Linear(in_features=2560, out_features=9728, bias=False)\n","          (up_proj): Linear(in_features=2560, out_features=9728, bias=False)\n","          (down_proj): Linear(in_features=9728, out_features=2560, bias=False)\n","          (act_fn): SiLUActivation()\n","        )\n","        (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","        (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","      )\n","    )\n","    (norm): Qwen3RMSNorm((2560,), eps=1e-06)\n","    (rotary_emb): LlamaRotaryEmbedding()\n","  )\n","  (lm_head): Linear(in_features=2560, out_features=151936, bias=False)\n",")"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# Saves as a standard model (no adapters folder, just model.safetensors)\n","model.save_pretrained_merged(\n","    MERGED_PATH,\n","    tokenizer,\n","    save_method = \"merged_16bit\",\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I_ncifke0_v5","executionInfo":{"status":"ok","timestamp":1767829426457,"user_tz":360,"elapsed":75989,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"e2391590-d2d2-4b75-ef8d-52da039796c8"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Found HuggingFace hub cache directory: /root/.cache/huggingface/hub\n","Checking cache directory for required files...\n"]},{"output_type":"stream","name":"stderr","text":["Unsloth: Copying 2 files from cache to `models/qwen3-4b-sft-merged`: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:22<00:00, 11.06s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Successfully copied all 2 files from cache to `models/qwen3-4b-sft-merged`\n","Checking cache directory for required files...\n","Cache check failed: tokenizer.model not found in local cache.\n","Not all required files found in cache. Will proceed with downloading.\n"]},{"output_type":"stream","name":"stderr","text":["Unsloth: Preparing safetensor model files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 16980.99it/s]\n","Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:50<00:00, 25.35s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Merge process complete. Saved to `/content/drive/MyDrive/grpo-verified-reasoner/models/qwen3-4b-sft-merged`\n"]}]},{"cell_type":"markdown","source":["# Step 3: Merging Model at Checkpoint 90"],"metadata":{"id":"BRfYgDu72iCM"}},{"cell_type":"code","source":["CHECKPOINT_PATH = \"outputs/checkpoint-90\"\n","MERGED_PATH = \"models/qwen3-4b-grpo-checkpoint90-merged\""],"metadata":{"id":"zbZP2sPz1yc4","executionInfo":{"status":"ok","timestamp":1767829728164,"user_tz":360,"elapsed":2,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = CHECKPOINT_PATH,\n","    max_seq_length = 3072,\n","    load_in_4bit = False,    # Must be False for merging\n","    dtype = torch.float16,   # Standard 16-bit precision\n",")"],"metadata":{"id":"Y5boh7xu2zFl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# This physically modifies the weights: W_new = W_base + (A * B)\n","model.merge_and_unload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YProXQh224yx","executionInfo":{"status":"ok","timestamp":1767829751279,"user_tz":360,"elapsed":142,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"e37fe693-e4e4-4425-e540-5bf038af400d"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Qwen3ForCausalLM(\n","  (model): Qwen3Model(\n","    (embed_tokens): Embedding(151936, 2560, padding_idx=151654)\n","    (layers): ModuleList(\n","      (0-35): 36 x Qwen3DecoderLayer(\n","        (self_attn): Qwen3Attention(\n","          (q_proj): Linear(in_features=2560, out_features=4096, bias=False)\n","          (k_proj): Linear(in_features=2560, out_features=1024, bias=False)\n","          (v_proj): Linear(in_features=2560, out_features=1024, bias=False)\n","          (o_proj): Linear(in_features=4096, out_features=2560, bias=False)\n","          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n","          (rotary_emb): LlamaRotaryEmbedding()\n","        )\n","        (mlp): Qwen3MLP(\n","          (gate_proj): Linear(in_features=2560, out_features=9728, bias=False)\n","          (up_proj): Linear(in_features=2560, out_features=9728, bias=False)\n","          (down_proj): Linear(in_features=9728, out_features=2560, bias=False)\n","          (act_fn): SiLUActivation()\n","        )\n","        (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","        (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n","      )\n","    )\n","    (norm): Qwen3RMSNorm((2560,), eps=1e-06)\n","    (rotary_emb): LlamaRotaryEmbedding()\n","  )\n","  (lm_head): Linear(in_features=2560, out_features=151936, bias=False)\n",")"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Saves as a standard model (no adapters folder, just model.safetensors)\n","model.save_pretrained_merged(\n","    MERGED_PATH,\n","    tokenizer,\n","    save_method = \"merged_16bit\",\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ym085f2n2-Bh","executionInfo":{"status":"ok","timestamp":1767829920858,"user_tz":360,"elapsed":131346,"user":{"displayName":"Samyak Shrestha","userId":"13083503381857072620"}},"outputId":"503865d1-99a0-4d63-c5f4-91742a1d1cc9"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Found HuggingFace hub cache directory: /root/.cache/huggingface/hub\n","Checking cache directory for required files...\n"]},{"output_type":"stream","name":"stderr","text":["Unsloth: Copying 2 files from cache to `models/qwen3-4b-grpo-checkpoint90-merged`: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:23<00:00, 11.81s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Successfully copied all 2 files from cache to `models/qwen3-4b-grpo-checkpoint90-merged`\n","Checking cache directory for required files...\n","Cache check failed: tokenizer.model not found in local cache.\n","Not all required files found in cache. Will proceed with downloading.\n"]},{"output_type":"stream","name":"stderr","text":["Unsloth: Preparing safetensor model files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 3818.21it/s]\n","Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:44<00:00, 52.33s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Merge process complete. Saved to `/content/drive/MyDrive/grpo-verified-reasoner/models/qwen3-4b-grpo-checkpoint90-merged`\n"]}]}]}